<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>EdgeML Made Easy - Image Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../raspi/object_detection/object_detection.html" rel="next">
<link href="../../raspi/setup/setup.html" rel="prev">
<link href="../../images/cover.jpg" rel="icon" type="image/jpeg">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">EdgeML Made Easy</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto tools-wide">
    <a href="https://github.com/Mjrovai/TinyML_Made_Easy_XIAO_ESP32S3_eBook" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="../../EdgeML-Made-Easy.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="../../EdgeML-Made-Easy.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../raspi/image_classification/image_classification.html">Image Classification</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgments</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about_book.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../raspi/image_classification/image_classification.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../raspi/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../raspi/counting_objects_yolo/counting_objects_yolo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Counting objects with YOLO</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../raspi/llm/llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../about_the_author.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the author</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#applications-in-real-world-scenarios" id="toc-applications-in-real-world-scenarios" class="nav-link" data-scroll-target="#applications-in-real-world-scenarios">Applications in Real-World Scenarios</a></li>
  <li><a href="#advantages-of-running-classification-on-edge-devices-like-raspberry-pi" id="toc-advantages-of-running-classification-on-edge-devices-like-raspberry-pi" class="nav-link" data-scroll-target="#advantages-of-running-classification-on-edge-devices-like-raspberry-pi">Advantages of Running Classification on Edge Devices like Raspberry Pi</a></li>
  </ul></li>
  <li><a href="#setting-up-the-environment" id="toc-setting-up-the-environment" class="nav-link" data-scroll-target="#setting-up-the-environment">Setting Up the Environment</a>
  <ul class="collapse">
  <li><a href="#updating-the-raspberry-pi" id="toc-updating-the-raspberry-pi" class="nav-link" data-scroll-target="#updating-the-raspberry-pi">Updating the Raspberry Pi</a></li>
  <li><a href="#installing-required-libraries" id="toc-installing-required-libraries" class="nav-link" data-scroll-target="#installing-required-libraries">Installing Required Libraries</a></li>
  <li><a href="#setting-up-a-virtual-environment-optional-but-recommended" id="toc-setting-up-a-virtual-environment-optional-but-recommended" class="nav-link" data-scroll-target="#setting-up-a-virtual-environment-optional-but-recommended">Setting up a Virtual Environment (Optional but Recommended)</a></li>
  <li><a href="#installing-tensorflow-lite" id="toc-installing-tensorflow-lite" class="nav-link" data-scroll-target="#installing-tensorflow-lite">Installing TensorFlow Lite</a></li>
  <li><a href="#installing-additional-python-libraries" id="toc-installing-additional-python-libraries" class="nav-link" data-scroll-target="#installing-additional-python-libraries">Installing Additional Python Libraries</a></li>
  <li><a href="#creating-a-working-directory" id="toc-creating-a-working-directory" class="nav-link" data-scroll-target="#creating-a-working-directory">Creating a working directory:</a></li>
  <li><a href="#setting-up-jupyter-notebook-optional" id="toc-setting-up-jupyter-notebook-optional" class="nav-link" data-scroll-target="#setting-up-jupyter-notebook-optional">Setting up Jupyter Notebook (Optional)</a></li>
  <li><a href="#verifying-the-setup" id="toc-verifying-the-setup" class="nav-link" data-scroll-target="#verifying-the-setup">Verifying the Setup</a></li>
  </ul></li>
  <li><a href="#making-inferences-with-mobilenet-v2" id="toc-making-inferences-with-mobilenet-v2" class="nav-link" data-scroll-target="#making-inferences-with-mobilenet-v2">Making inferences with Mobilenet V2</a>
  <ul class="collapse">
  <li><a href="#define-a-general-image-classification-function" id="toc-define-a-general-image-classification-function" class="nav-link" data-scroll-target="#define-a-general-image-classification-function">Define a general Image Classification function</a></li>
  <li><a href="#testing-with-a-model-trained-from-scratch" id="toc-testing-with-a-model-trained-from-scratch" class="nav-link" data-scroll-target="#testing-with-a-model-trained-from-scratch">Testing with a model trained from scratch</a></li>
  <li><a href="#installing-picamera2" id="toc-installing-picamera2" class="nav-link" data-scroll-target="#installing-picamera2">Installing Picamera2</a></li>
  </ul></li>
  <li><a href="#image-classification-project" id="toc-image-classification-project" class="nav-link" data-scroll-target="#image-classification-project">Image Classification Project</a>
  <ul class="collapse">
  <li><a href="#the-goal" id="toc-the-goal" class="nav-link" data-scroll-target="#the-goal">The Goal</a></li>
  <li><a href="#data-collection" id="toc-data-collection" class="nav-link" data-scroll-target="#data-collection">Data Collection</a></li>
  </ul></li>
  <li><a href="#training-the-model-with-edge-impulse-studio" id="toc-training-the-model-with-edge-impulse-studio" class="nav-link" data-scroll-target="#training-the-model-with-edge-impulse-studio">Training the model with Edge Impulse Studio</a>
  <ul class="collapse">
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset">Dataset</a></li>
  </ul></li>
  <li><a href="#the-impulse-design" id="toc-the-impulse-design" class="nav-link" data-scroll-target="#the-impulse-design">The Impulse Design</a>
  <ul class="collapse">
  <li><a href="#image-pre-processing" id="toc-image-pre-processing" class="nav-link" data-scroll-target="#image-pre-processing">Image Pre-Processing</a></li>
  <li><a href="#model-design" id="toc-model-design" class="nav-link" data-scroll-target="#model-design">Model Design</a></li>
  <li><a href="#model-training" id="toc-model-training" class="nav-link" data-scroll-target="#model-training">Model Training</a></li>
  <li><a href="#trading-off-accuracy-versus-speed" id="toc-trading-off-accuracy-versus-speed" class="nav-link" data-scroll-target="#trading-off-accuracy-versus-speed">Trading off: Accuracy versus speed</a></li>
  <li><a href="#model-testing" id="toc-model-testing" class="nav-link" data-scroll-target="#model-testing">Model Testing</a></li>
  <li><a href="#deploying-the-model" id="toc-deploying-the-model" class="nav-link" data-scroll-target="#deploying-the-model">Deploying the model</a></li>
  </ul></li>
  <li><a href="#live-image-classification" id="toc-live-image-classification" class="nav-link" data-scroll-target="#live-image-classification">Live Image Classification</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion:</a></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">Resources</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/Mjrovai/TinyML_Made_Easy_XIAO_ESP32S3_eBook/edit/main/raspi/image_classification/image_classification.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/Mjrovai/TinyML_Made_Easy_XIAO_ESP32S3_eBook/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/Mjrovai/TinyML_Made_Easy_XIAO_ESP32S3_eBook/blob/main/raspi/image_classification/image_classification.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Image Classification</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/jpeg/img_class_cover.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption"><em>DALL·E prompt - A cover image for an ‘Image Classification’ chapter in a Raspberry Pi tutorial, designed in the same vintage 1950s electronics lab style as previous covers. The scene should feature a Raspberry Pi connected to a camera module, with the camera capturing a photo of the small blue robot provided by the user. The robot should be placed on a workbench, surrounded by classic lab tools like soldering irons, resistors, and wires. The lab background should include vintage equipment like oscilloscopes and tube radios, maintaining the detailed and nostalgic feel of the era. No text or logos should be included.</em></figcaption>
</figure>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Image classification is a fundamental task in computer vision that involves categorizing an image into one of several predefined classes. It’s a cornerstone of artificial intelligence, enabling machines to interpret and understand visual information in a way that mimics human perception.</p>
<p>Image classification refers to assigning a label or category to an entire image based on its visual content. This task is crucial in computer vision and has numerous applications across various industries. Image classification’s importance lies in its ability to automate visual understanding tasks that would otherwise require human intervention.</p>
<section id="applications-in-real-world-scenarios" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-real-world-scenarios">Applications in Real-World Scenarios</h3>
<p>Image classification has found its way into numerous real-world applications, revolutionizing various sectors:</p>
<ul>
<li>Healthcare: Assisting in medical image analysis, such as identifying abnormalities in X-rays or MRIs.</li>
<li>Agriculture: Monitoring crop health and detecting plant diseases through aerial imagery.</li>
<li>Automotive: Enabling advanced driver assistance systems and autonomous vehicles to recognize road signs, pedestrians, and other vehicles.</li>
<li>Retail: Powering visual search capabilities and automated inventory management systems.</li>
<li>Security and Surveillance: Enhancing threat detection and facial recognition systems.</li>
<li>Environmental Monitoring: Analyzing satellite imagery for deforestation, urban planning, and climate change studies.</li>
</ul>
</section>
<section id="advantages-of-running-classification-on-edge-devices-like-raspberry-pi" class="level3">
<h3 class="anchored" data-anchor-id="advantages-of-running-classification-on-edge-devices-like-raspberry-pi">Advantages of Running Classification on Edge Devices like Raspberry Pi</h3>
<p>Implementing image classification on edge devices such as the Raspberry Pi offers several compelling advantages:</p>
<ol type="1">
<li><p>Low Latency: Processing images locally eliminates the need to send data to cloud servers, significantly reducing response times.</p></li>
<li><p>Offline Functionality: Classification can be performed without an internet connection, making it suitable for remote or connectivity-challenged environments.</p></li>
<li><p>Privacy and Security: Sensitive image data remains on the local device, addressing data privacy concerns and compliance requirements.</p></li>
<li><p>Cost-Effectiveness: Eliminates the need for expensive cloud computing resources, especially for continuous or high-volume classification tasks.</p></li>
<li><p>Scalability: Enables distributed computing architectures where multiple devices can work independently or in a network.</p></li>
<li><p>Energy Efficiency: Optimized models on dedicated hardware can be more energy-efficient than cloud-based solutions, which is crucial for battery-powered or remote applications.</p></li>
<li><p>Customization: Deploying specialized or frequently updated models tailored to specific use cases is more manageable.</p></li>
</ol>
<p>We can create more responsive, secure, and efficient computer vision solutions by leveraging the power of edge devices like Raspberry Pi for image classification. This approach opens up new possibilities for integrating intelligent visual processing into various applications and environments.</p>
<p>In the following sections, we’ll explore how to implement and optimize image classification on the Raspberry Pi, harnessing these advantages to create powerful and efficient computer vision systems.</p>
</section>
</section>
<section id="setting-up-the-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-the-environment">Setting Up the Environment</h2>
<section id="updating-the-raspberry-pi" class="level3">
<h3 class="anchored" data-anchor-id="updating-the-raspberry-pi">Updating the Raspberry Pi</h3>
<p>First, ensure your Raspberry Pi is up to date:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt upgrade <span class="at">-y</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="installing-required-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-required-libraries">Installing Required Libraries</h3>
<p>Install the necessary libraries for image processing and machine learning:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install python3-pip</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> rm /usr/lib/python3.11/EXTERNALLY-MANAGED</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install <span class="at">--upgrade</span> pip</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="setting-up-a-virtual-environment-optional-but-recommended" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-a-virtual-environment-optional-but-recommended">Setting up a Virtual Environment (Optional but Recommended)</h3>
<p>Create a virtual environment to manage dependencies:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">-m</span> venv ~/tflite</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ~/tflite/bin/activate</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="installing-tensorflow-lite" class="level3">
<h3 class="anchored" data-anchor-id="installing-tensorflow-lite">Installing TensorFlow Lite</h3>
<p>We are interested in performing <strong>inference</strong>, which refers to executing a TensorFlow Lite model on a device to make predictions based on input data. To perform an inference with a TensorFlow Lite model, we must run it through an <strong>interpreter</strong>. The TensorFlow Lite interpreter is designed to be lean and fast. The interpreter uses a static graph ordering and a custom (less-dynamic) memory allocator to ensure minimal load, initialization, and execution latency.</p>
<p>We’ll use the <a href="https://pypi.org/project/tflite-runtime/">TensorFlow Lite runtime</a> for Raspberry Pi, a simplified library for running machine learning models on mobile and embedded devices, without including all TensorFlow packages.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install tflite_runtime <span class="at">--no-deps</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>The wheel installed: <code>tflite_runtime-2.14.0-cp311-cp311-manylinux_2_34_aarch64.whl</code></p>
</blockquote>
</section>
<section id="installing-additional-python-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-additional-python-libraries">Installing Additional Python Libraries</h3>
<p>Install required Python libraries for use with Image Classification:</p>
<p>If you have another version of Numpy installed, first uninstall it.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> uninstall numpy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Install <code>version 1.23.2</code>, which is compatible with the tflite_runtime.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a> <span class="ex">pip3</span> install numpy==1.23.2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install Pillow matplotlib</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="creating-a-working-directory" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-working-directory">Creating a working directory:</h3>
<p>If you are working on the Raspi-Zero with the minimum OS (No Desktop), you may not have a user-pre-defined directory tree (you can check it with <code>ls</code>. So, let’s create one:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> Documents</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> Documents/</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> TFLITE</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> TFLITE/</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> IMG_CLASS</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> IMG_CLASS</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> models</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> models</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>On the Raspi-5, the /Documents should be there.</p>
</blockquote>
<p><strong>Get a pre-trained Image Classification model</strong>:</p>
<p>An appropriate pre-trained model is crucial for successful image classification on resource-constrained devices like the Raspberry Pi. <strong>MobileNet</strong> is designed for mobile and embedded vision applications with a good balance between accuracy and speed. Versions: MobileNetV1, MobileNetV2, MobileNetV3. Let’s download the V2:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://storage.googleapis.com/download.tensorflow.org/models/</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="ex">tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tar</span> xzf mobilenet_v2_1.0_224_quant.tgz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Get its labels:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="ex">lite/java/demo/app/src/main/assets/labels_mobilenet_quant_v1_224.txt</span> <span class="at">-O</span> labels.txt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In the end, you should have the models in its directory:</p>
<p><img src="images/png/models_dir.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>We will only need the <code>mobilenet_v2_1.0_224_quant.tflite</code> model and the <code>labels.txt</code>. You can delete the other files.</p>
</blockquote>
</section>
<section id="setting-up-jupyter-notebook-optional" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-jupyter-notebook-optional">Setting up Jupyter Notebook (Optional)</h3>
<p>If you prefer using Jupyter Notebook for development:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install jupyter</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--generate-config</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To run Jupyter Notebook, run the command (change the IP address for yours):</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--ip</span><span class="op">=</span>192.168.4.210 <span class="at">--no-browser</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>On the terminal, you can see the local URL address to open the notebook:</p>
<p><img src="images/png/notebook_token.png" class="img-fluid"></p>
<p>You can access it from another device by entering the Raspberry Pi’s IP address and the provided token in a web browser (you can copy the token from the terminal).</p>
<p><img src="images/png/image-20240823145059675.png" class="img-fluid"></p>
<p>Define your working directory in the Raspi and create a new Python 3 notebook.</p>
</section>
<section id="verifying-the-setup" class="level3">
<h3 class="anchored" data-anchor-id="verifying-the-setup">Verifying the Setup</h3>
<p>Test your setup by running a simple Python script:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NumPy:"</span>, np.__version__)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pillow:"</span>, Image.__version__)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Try to create a TFLite Interpreter</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/mobilenet_v2_1.0_224_quant.tflite"</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TFLite Interpreter created successfully!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can create the Python script using nano on the terminal, saving it with <code>CTRL+0</code> + <code>ENTER</code> + <code>CTRL+X</code></p>
<p><img src="images/png/nano.png" class="img-fluid"></p>
<p>And run it with the command:</p>
<p><img src="images/png/test_result.png" class="img-fluid"></p>
<p>Or you can run it directly on the <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/setup_test.ipynb">Notebook</a>:</p>
<p><img src="images/png/notebook_test.png" class="img-fluid"></p>
</section>
</section>
<section id="making-inferences-with-mobilenet-v2" class="level2">
<h2 class="anchored" data-anchor-id="making-inferences-with-mobilenet-v2">Making inferences with Mobilenet V2</h2>
<p>In the last section, we set up the environment, including downloading a popular pre-trained model, Mobilenet V2, trained on ImageNet’s 224x224 images (1.2 million) for 1,001 classes (1,000 object categories plus 1 background). The model was converted to a compact 3.5MB TensorFlow Lite format, making it suitable for the limited storage and memory of a Raspberry Pi.</p>
<p><img src="images/png/mobilinet_zero.png" class="img-fluid"></p>
<p>Let’s start a new <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/10_Image_Classification.ipynb">notebook</a> to follow all the steps to classify one image:</p>
<p>Import the needed libraries:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Load the TFLite model and allocate tensors:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/mobilenet_v2_1.0_224_quant.tflite"</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Get input and output tensors.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>output_details <span class="op">=</span> interpreter.get_output_details()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Input details</strong> will give us information about how the model should be fed with an image. The shape of (1, 224, 224, 3) informs us that an image with dimensions (224x224x3) should be input one by one (Batch Dimension: 1).</p>
<p><img src="images/png/input_details.png" class="img-fluid"></p>
<p>The <strong>output details</strong> show that the inference will result in an array of 1,001 integer values. Those values result from the image classification, where each value is the probability of that specific label being related to the image.</p>
<p><img src="images/png/output_details.png" class="img-fluid"></p>
<p>Let’s also inspect the dtype of input details of the model</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>input_dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>dtype('uint8')</code></pre>
<p>This shows that the input image should be raw pixels (0 - 255).</p>
<p>Let’s get a test image. You can transfer it from your computer or download one for testing. Let’s first create a folder under our working directory:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> images</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> images</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s load and display the image:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load he image</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"./images/Cat03.jpg"</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the image</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Original Image"</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/cat_original.png" class="img-fluid"></p>
<p>We can see the image size running the command:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>width, height <span class="op">=</span> img.size</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>That shows us that the image is an RGB image with a width of 1600 and a height of 1600 pixels. So, to use our model, we should reshape it to (224, 224, 3) and add a batch dimension of 1, as defined in input details: (1, 224, 224, 3). The inference result, as shown in output details, will be an array with a 1001 size, as shown below:</p>
<p><img src="images/png/process_img.png" class="img-fluid"></p>
<p>So, let’s reshape the image, add the batch dimension, and see the result:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>input_data.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The input_data shape is as expected: (1, 224, 224, 3)</p>
<p>Let’s confirm the dtype of the input data:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>input_data.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>dtype('uint8')</code></pre>
<p>The input data dtype is ‘uint8’, which is compatible with the dtype expected for the model.</p>
<p>Using the input_data, let’s run the interpreter and get the predictions (output):</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>interpreter.invoke()</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The prediction is an array with 1001 elements. Let’s get the Top-5 indices where their elements have high values:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>top_k_results <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>top_k_indices </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The top_k_indices is an array with 5 elements: <code>array([283, 286, 282])</code></p>
<p>So, 283, 286, 282, 288, and 479 are the image’s most probable classes. Having the index, we must find to what class it appoints (such as car, cat, or dog). The text file downloaded with the model has a label associated with each index from 0 to 1,000. Let’s use a function to load the .txt file as a list:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_labels(filename):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(filename, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [line.strip() <span class="cf">for</span> line <span class="kw">in</span> f.readlines()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And get the list, printing the labels associated with the indexes:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>labels_path <span class="op">=</span> <span class="st">"./models/labels.txt"</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> load_labels(labels_path)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">286</span>])</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">283</span>])</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">282</span>])</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">288</span>])</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">479</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As a result, we have:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="ex">Egyptian</span> cat</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="ex">tiger</span> cat</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="ex">tabby</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lynx</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="ex">carton</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>At least the four top indices are related to felines. The <strong>prediction</strong> content is the probability associated with each one of the labels. As we saw on output details, those values are quantized and should be dequantized and apply softmax.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>exp_output <span class="op">=</span> np.exp(dequantized_output <span class="op">-</span> np.<span class="bu">max</span>(dequantized_output))</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> exp_output <span class="op">/</span> np.<span class="bu">sum</span>(exp_output)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s print the top-5 probabilities:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">286</span>])</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">283</span>])</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">282</span>])</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">288</span>])</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">479</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="ex">0.27741462</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="ex">0.3732285</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="ex">0.16919471</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0.10319158</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="ex">0.023410844</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>For clarity, let’s create a function to relate the labels with the probabilities:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>        labels[top_k_indices[i]],</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>        (<span class="bu">int</span>(probabilities[top_k_indices[i]]<span class="op">*</span><span class="dv">100</span>))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="ex">tiger</span> cat           : 37%</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Egyptian</span> cat        : 27%</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="ex">tabby</span>               : 16%</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lynx</span>                : 10%</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="ex">carton</span>              : 2%</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="define-a-general-image-classification-function" class="level3">
<h3 class="anchored" data-anchor-id="define-a-general-image-classification-function">Define a general Image Classification function</h3>
Let’s create a general function to give an image as input, and we get the Top-5 possible classes:
<div class="scroll-code-block">
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_classification(img_path, model_path, labels, top_k_results<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the TFLite model</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    interpreter.allocate_tensors()</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get input and output tensors</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain results and map them to the classes</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of the top k results</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get quantization parameters</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dequantize the output and apply softmax</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>    dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>    exp_output <span class="op">=</span> np.exp(dequantized_output <span class="op">-</span> np.<span class="bu">max</span>(dequantized_output))</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> exp_output <span class="op">/</span> np.<span class="bu">sum</span>(exp_output)</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>            labels[top_k_indices[i]],</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>            (<span class="bu">int</span>(probabilities[top_k_indices[i]]<span class="op">*</span><span class="dv">100</span>))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And loading some images for testing, we have:</p>
<p><img src="images/jpeg/img_class_func.jpg" class="img-fluid"></p>
</section>
<section id="testing-with-a-model-trained-from-scratch" class="level3">
<h3 class="anchored" data-anchor-id="testing-with-a-model-trained-from-scratch">Testing with a model trained from scratch</h3>
<p>Let’s get a TFLite model trained from scratch. For that, you can follow the Notebook:</p>
<p><a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/2_Applications_Deploy/Class_16/cifar_10/CNN_Cifar_10_TFLite.ipynb#scrollTo=iiVBUpuHXEtw">CNN to classify Cifar-10 dataset</a></p>
<p>In the notebook, we trained a model using the CIFAR10 dataset, which contains 60,000 images from 10 classes of CIFAR (<em>airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck</em>). CIFAR has 32x32 color images (3 color channels) where the objects are not centered and can have the object with a background, such as airplanes that might have a cloudy sky behind them! In short, small but real images.</p>
<p>The CNN trained model (<em>cifar10_model.keras</em>) had a size of 2.0MB. Using the <em>TFLite Converter</em>, the model <em>cifar10.tflite</em> became with 674MB (around 1/3 of the original size).</p>
<p><img src="images/png/cifar10_model.png" class="img-fluid"></p>
<p>On the notebook <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/20_Cifar_10_Image_Classification.ipynb">Cifar 10 - Image Classification on a Raspi with TFLite</a> (which can be run over the Raspi), we can follow the same steps we did with the <code>mobilenet_v2_1.0_224_quant.tflite</code>. Below are examples of images using the <em>General Function for Image Classification</em> on a Raspi-Zero, as shown in the last section.</p>
<p><img src="images/png/infer-cifar10.png" class="img-fluid"></p>
</section>
<section id="installing-picamera2" class="level3">
<h3 class="anchored" data-anchor-id="installing-picamera2">Installing Picamera2</h3>
<p><a href="https://github.com/raspberrypi/picamera2">Picamera2</a>, a Python library for interacting with Raspberry Pi’s camera, is based on the <em>libcamera</em> camera stack, and the Raspberry Pi foundation maintains it. The Picamera2 library is supported on all Raspberry Pi models, from the Pi Zero to the RPi 5. It is already installed system-wide on the Raspi, but we should make it accessible within the virtual environment.</p>
<ol type="1">
<li><p>First, activate the virtual environment if it’s not already activated:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ~/tflite/bin/activate</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Now, let’s create a .pth file in your virtual environment to add the system site-packages path:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"/usr/lib/python3/dist-packages"</span> <span class="op">&gt;</span> <span class="va">$VIRTUAL_ENV</span>/lib/python3.11/</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="ex">site-packages/system_site_packages.pth</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Note: If your Python version differs, replace <code>python3.11</code> with the appropriate version.</p>
</blockquote></li>
<li><p>After creating this file, try importing picamera2 in Python:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> import <span class="ex">picamera2</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> print<span class="kw">(</span><span class="ex">picamera2.__file__</span><span class="kw">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
<p>The above code will show the file location of the <code>picamera2</code> module itself, proving that the library can be accessed from the environment.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="op">/</span>home<span class="op">/</span>mjrovai<span class="op">/</span>tflite<span class="op">/</span>lib<span class="op">/</span>python3<span class="fl">.11</span><span class="op">/</span>site<span class="op">-</span>packages<span class="op">/</span>picamera2<span class="op">/</span><span class="fu">__init__</span>.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also list the available cameras in the system:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(Picamera2.global_camera_info())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In my case, with a USB installed, I got:</p>
<p><img src="images/png/cam_installed.png" class="img-fluid"></p>
<p>Now that we’ve confirmed picamera2 is working in the environment with an <code>index 0</code>, let’s try a simple Python script to capture an image from your USB camera:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the camera</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> Picamera2() <span class="co"># default is index 0</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure the camera</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> picam2.create_still_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">640</span>, <span class="dv">480</span>)})</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>picam2.configure(config)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Start the camera</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>picam2.start()</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Wait for the camera to warm up</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">2</span>)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Capture an image</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>picam2.capture_file(<span class="st">"usb_camera_image.jpg"</span>)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Image captured and saved as 'usb_camera_image.jpg'"</span>)</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Stop the camera</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>picam2.stop()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Use the Nano text editor, the Jupyter Notebook, or any other editor. Save this as a Python script (e.g., <code>capture_image.py</code>) and run it. This should capture an image from your camera and save it as “usb_camera_image.jpg” in the same directory as your script.</p>
<p><img src="images/png/capture_test.png" class="img-fluid"></p>
<p>If the Jupyter is open, you can see the captured image on your computer. Otherwise, transfer the file from the Raspi to your computer.</p>
<p><img src="images/png/img_test_result.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>If you are working with a Raspi-5 with a whole desktop, you can open the file directly on the device.</p>
</blockquote>
</section>
</section>
<section id="image-classification-project" class="level2">
<h2 class="anchored" data-anchor-id="image-classification-project">Image Classification Project</h2>
<p>Now, we will develop a complete Image Classification project using the Edge Impulse Studio. As we did with the Movilinet V2, the trained and converted TFLite model will be used for inference.</p>
<section id="the-goal" class="level3">
<h3 class="anchored" data-anchor-id="the-goal">The Goal</h3>
<p>The first step in any ML project is to define its goal. In this case, it is to detect and classify two specific objects present in one image. For this project, we will use two small toys: a robot and a small Brazilian parrot (named Periquito). We will also collect images of a <em>background</em> where those two objects are absent.</p>
<p><img src="images/jpeg/project_goal.jpg" class="img-fluid"></p>
</section>
<section id="data-collection" class="level3">
<h3 class="anchored" data-anchor-id="data-collection">Data Collection</h3>
<p>Once we have defined our Machine Learning project goal, the next and most crucial step is collecting the dataset. We can use a phone for the image capture, but we will use the Raspi here. Let’s set up a simple web server on our Raspberry Pi to view the <code>QVGA (320 x 240)</code> captured images in a browser.</p>
<ol type="1">
<li><p>First, let’s install Flask, a lightweight web framework for Python:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install flask</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Let’s create a new Python script combining image capture with a web server. We’ll call it <code>get_img_data.py</code>:</p></li>
</ol>
<div class="scroll-code-block">
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask, Response, render_template_string, request, redirect, url_for</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> signal</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> Flask(<span class="va">__name__</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>base_dir <span class="op">=</span> <span class="st">"dataset"</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>frame_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>capture_counts <span class="op">=</span> {}</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>current_label <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>shutdown_event <span class="op">=</span> threading.Event()</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_camera():</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> picam2</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>    picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>    config <span class="op">=</span> picam2.create_preview_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">320</span>, <span class="dv">240</span>)})</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>    picam2.configure(config)</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>    picam2.start()</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Wait for camera to warm up</span></span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_frame():</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> frame</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>        stream <span class="op">=</span> io.BytesIO()</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(stream, <span class="bu">format</span><span class="op">=</span><span class="st">'jpeg'</span>)</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>            frame <span class="op">=</span> stream.getvalue()</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust as needed for smooth preview</span></span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_frames():</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (<span class="st">b'--frame</span><span class="ch">\r\n</span><span class="st">'</span></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>                       <span class="st">b'Content-Type: image/jpeg</span><span class="ch">\r\n\r\n</span><span class="st">'</span> <span class="op">+</span> frame <span class="op">+</span> <span class="st">b'</span><span class="ch">\r\n</span><span class="st">'</span>)</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust as needed for smooth streaming</span></span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> shutdown_server():</span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>    shutdown_event.<span class="bu">set</span>()</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> picam2:</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a>        picam2.stop()</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Give some time for other threads to finish</span></span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Send SIGINT to the main process</span></span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a>    os.kill(os.getpid(), signal.SIGINT)</span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/'</span>, methods<span class="op">=</span>[<span class="st">'GET'</span>, <span class="st">'POST'</span>])</span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> index():</span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> current_label</span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> request.method <span class="op">==</span> <span class="st">'POST'</span>:</span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a>        current_label <span class="op">=</span> request.form[<span class="st">'label'</span>]</span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_label <span class="kw">not</span> <span class="kw">in</span> capture_counts:</span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a>            capture_counts[current_label] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a>        os.makedirs(os.path.join(base_dir, current_label), exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb43-62"><a href="#cb43-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> redirect(url_for(<span class="st">'capture_page'</span>))</span>
<span id="cb43-63"><a href="#cb43-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-65"><a href="#cb43-65" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb43-66"><a href="#cb43-66" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb43-67"><a href="#cb43-67" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture - Label Entry&lt;/title&gt;</span></span>
<span id="cb43-68"><a href="#cb43-68" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb43-69"><a href="#cb43-69" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb43-70"><a href="#cb43-70" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Enter Label for Dataset&lt;/h1&gt;</span></span>
<span id="cb43-71"><a href="#cb43-71" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form method="post"&gt;</span></span>
<span id="cb43-72"><a href="#cb43-72" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="text" name="label" required&gt;</span></span>
<span id="cb43-73"><a href="#cb43-73" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Start Capture"&gt;</span></span>
<span id="cb43-74"><a href="#cb43-74" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb43-75"><a href="#cb43-75" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb43-76"><a href="#cb43-76" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb43-77"><a href="#cb43-77" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>)</span>
<span id="cb43-78"><a href="#cb43-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-79"><a href="#cb43-79" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/capture'</span>)</span>
<span id="cb43-80"><a href="#cb43-80" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> capture_page():</span>
<span id="cb43-81"><a href="#cb43-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb43-82"><a href="#cb43-82" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-83"><a href="#cb43-83" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb43-84"><a href="#cb43-84" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb43-85"><a href="#cb43-85" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture&lt;/title&gt;</span></span>
<span id="cb43-86"><a href="#cb43-86" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script&gt;</span></span>
<span id="cb43-87"><a href="#cb43-87" aria-hidden="true" tabindex="-1"></a><span class="st">                var shutdownInitiated = false;</span></span>
<span id="cb43-88"><a href="#cb43-88" aria-hidden="true" tabindex="-1"></a><span class="st">                function checkShutdown() {</span></span>
<span id="cb43-89"><a href="#cb43-89" aria-hidden="true" tabindex="-1"></a><span class="st">                    if (!shutdownInitiated) {</span></span>
<span id="cb43-90"><a href="#cb43-90" aria-hidden="true" tabindex="-1"></a><span class="st">                        fetch('/check_shutdown')</span></span>
<span id="cb43-91"><a href="#cb43-91" aria-hidden="true" tabindex="-1"></a><span class="st">                            .then(response =&gt; response.json())</span></span>
<span id="cb43-92"><a href="#cb43-92" aria-hidden="true" tabindex="-1"></a><span class="st">                            .then(data =&gt; {</span></span>
<span id="cb43-93"><a href="#cb43-93" aria-hidden="true" tabindex="-1"></a><span class="st">                                if (data.shutdown) {</span></span>
<span id="cb43-94"><a href="#cb43-94" aria-hidden="true" tabindex="-1"></a><span class="st">                                    shutdownInitiated = true;</span></span>
<span id="cb43-95"><a href="#cb43-95" aria-hidden="true" tabindex="-1"></a><span class="st">                                    document.getElementById('video-feed').src = '';</span></span>
<span id="cb43-96"><a href="#cb43-96" aria-hidden="true" tabindex="-1"></a><span class="st">                                    document.getElementById('shutdown-message')</span></span>
<span id="cb43-97"><a href="#cb43-97" aria-hidden="true" tabindex="-1"></a><span class="st">                                    .style.display = 'block';</span></span>
<span id="cb43-98"><a href="#cb43-98" aria-hidden="true" tabindex="-1"></a><span class="st">                                }</span></span>
<span id="cb43-99"><a href="#cb43-99" aria-hidden="true" tabindex="-1"></a><span class="st">                            });</span></span>
<span id="cb43-100"><a href="#cb43-100" aria-hidden="true" tabindex="-1"></a><span class="st">                    }</span></span>
<span id="cb43-101"><a href="#cb43-101" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb43-102"><a href="#cb43-102" aria-hidden="true" tabindex="-1"></a><span class="st">                setInterval(checkShutdown, 1000);  // Check every second</span></span>
<span id="cb43-103"><a href="#cb43-103" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb43-104"><a href="#cb43-104" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb43-105"><a href="#cb43-105" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb43-106"><a href="#cb43-106" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Dataset Capture&lt;/h1&gt;</span></span>
<span id="cb43-107"><a href="#cb43-107" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Current Label: </span><span class="sc">{{</span><span class="st"> label </span><span class="sc">}}</span><span class="st">&lt;/p&gt;</span></span>
<span id="cb43-108"><a href="#cb43-108" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Images captured for this label: </span><span class="sc">{{</span><span class="st"> capture_count </span><span class="sc">}}</span><span class="st">&lt;/p&gt;</span></span>
<span id="cb43-109"><a href="#cb43-109" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;img id="video-feed" src="</span><span class="sc">{{</span><span class="st"> url_for('video_feed') </span><span class="sc">}}</span><span class="st">" width="640" </span></span>
<span id="cb43-110"><a href="#cb43-110" aria-hidden="true" tabindex="-1"></a><span class="st">            height="480" /&gt;</span></span>
<span id="cb43-111"><a href="#cb43-111" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;div id="shutdown-message" style="display: none; color: red;"&gt;</span></span>
<span id="cb43-112"><a href="#cb43-112" aria-hidden="true" tabindex="-1"></a><span class="st">                Capture process has been stopped. You can close this window.</span></span>
<span id="cb43-113"><a href="#cb43-113" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/div&gt;</span></span>
<span id="cb43-114"><a href="#cb43-114" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/capture_image" method="post"&gt;</span></span>
<span id="cb43-115"><a href="#cb43-115" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Capture Image"&gt;</span></span>
<span id="cb43-116"><a href="#cb43-116" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb43-117"><a href="#cb43-117" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/stop" method="post"&gt;</span></span>
<span id="cb43-118"><a href="#cb43-118" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Stop Capture" </span></span>
<span id="cb43-119"><a href="#cb43-119" aria-hidden="true" tabindex="-1"></a><span class="st">                style="background-color: #ff6666;"&gt;</span></span>
<span id="cb43-120"><a href="#cb43-120" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb43-121"><a href="#cb43-121" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/" method="get"&gt;</span></span>
<span id="cb43-122"><a href="#cb43-122" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Change Label" </span></span>
<span id="cb43-123"><a href="#cb43-123" aria-hidden="true" tabindex="-1"></a><span class="st">                style="background-color: #ffff66;"&gt;</span></span>
<span id="cb43-124"><a href="#cb43-124" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb43-125"><a href="#cb43-125" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb43-126"><a href="#cb43-126" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb43-127"><a href="#cb43-127" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>, label<span class="op">=</span>current_label, capture_count<span class="op">=</span>capture_counts.get(current_label, <span class="dv">0</span>))</span>
<span id="cb43-128"><a href="#cb43-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-129"><a href="#cb43-129" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/video_feed'</span>)</span>
<span id="cb43-130"><a href="#cb43-130" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> video_feed():</span>
<span id="cb43-131"><a href="#cb43-131" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Response(generate_frames(),</span>
<span id="cb43-132"><a href="#cb43-132" aria-hidden="true" tabindex="-1"></a>                    mimetype<span class="op">=</span><span class="st">'multipart/x-mixed-replace; boundary=frame'</span>)</span>
<span id="cb43-133"><a href="#cb43-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-134"><a href="#cb43-134" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/capture_image'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb43-135"><a href="#cb43-135" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> capture_image():</span>
<span id="cb43-136"><a href="#cb43-136" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> capture_counts</span>
<span id="cb43-137"><a href="#cb43-137" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_label <span class="kw">and</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-138"><a href="#cb43-138" aria-hidden="true" tabindex="-1"></a>        capture_counts[current_label] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb43-139"><a href="#cb43-139" aria-hidden="true" tabindex="-1"></a>        timestamp <span class="op">=</span> time.strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">-%H%M%S"</span>)</span>
<span id="cb43-140"><a href="#cb43-140" aria-hidden="true" tabindex="-1"></a>        filename <span class="op">=</span> <span class="ss">f"image_</span><span class="sc">{</span>timestamp<span class="sc">}</span><span class="ss">.jpg"</span></span>
<span id="cb43-141"><a href="#cb43-141" aria-hidden="true" tabindex="-1"></a>        full_path <span class="op">=</span> os.path.join(base_dir, current_label, filename)</span>
<span id="cb43-142"><a href="#cb43-142" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-143"><a href="#cb43-143" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(full_path)</span>
<span id="cb43-144"><a href="#cb43-144" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-145"><a href="#cb43-145" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> redirect(url_for(<span class="st">'capture_page'</span>))</span>
<span id="cb43-146"><a href="#cb43-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-147"><a href="#cb43-147" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/stop'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb43-148"><a href="#cb43-148" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stop():</span>
<span id="cb43-149"><a href="#cb43-149" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> render_template_string(<span class="st">'''</span></span>
<span id="cb43-150"><a href="#cb43-150" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-151"><a href="#cb43-151" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb43-152"><a href="#cb43-152" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb43-153"><a href="#cb43-153" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture - Stopped&lt;/title&gt;</span></span>
<span id="cb43-154"><a href="#cb43-154" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb43-155"><a href="#cb43-155" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb43-156"><a href="#cb43-156" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Dataset Capture Stopped&lt;/h1&gt;</span></span>
<span id="cb43-157"><a href="#cb43-157" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;The capture process has been stopped. You can close this window.&lt;/p&gt;</span></span>
<span id="cb43-158"><a href="#cb43-158" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Summary of captures:&lt;/p&gt;</span></span>
<span id="cb43-159"><a href="#cb43-159" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;ul&gt;</span></span>
<span id="cb43-160"><a href="#cb43-160" aria-hidden="true" tabindex="-1"></a><span class="st">            {</span><span class="sc">% f</span><span class="st">or label, count in capture_counts.items() %}</span></span>
<span id="cb43-161"><a href="#cb43-161" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;li&gt;</span><span class="sc">{{</span><span class="st"> label </span><span class="sc">}}</span><span class="st">: </span><span class="sc">{{</span><span class="st"> count </span><span class="sc">}}</span><span class="st"> images&lt;/li&gt;</span></span>
<span id="cb43-162"><a href="#cb43-162" aria-hidden="true" tabindex="-1"></a><span class="st">            {</span><span class="sc">% e</span><span class="st">ndfor %}</span></span>
<span id="cb43-163"><a href="#cb43-163" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/ul&gt;</span></span>
<span id="cb43-164"><a href="#cb43-164" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb43-165"><a href="#cb43-165" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb43-166"><a href="#cb43-166" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>, capture_counts<span class="op">=</span>capture_counts)</span>
<span id="cb43-167"><a href="#cb43-167" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-168"><a href="#cb43-168" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start a new thread to shutdown the server</span></span>
<span id="cb43-169"><a href="#cb43-169" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>shutdown_server).start()</span>
<span id="cb43-170"><a href="#cb43-170" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-171"><a href="#cb43-171" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> summary</span>
<span id="cb43-172"><a href="#cb43-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-173"><a href="#cb43-173" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/check_shutdown'</span>)</span>
<span id="cb43-174"><a href="#cb43-174" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_shutdown():</span>
<span id="cb43-175"><a href="#cb43-175" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'shutdown'</span>: shutdown_event.is_set()}</span>
<span id="cb43-176"><a href="#cb43-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-177"><a href="#cb43-177" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb43-178"><a href="#cb43-178" aria-hidden="true" tabindex="-1"></a>    initialize_camera()</span>
<span id="cb43-179"><a href="#cb43-179" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>get_frame, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb43-180"><a href="#cb43-180" aria-hidden="true" tabindex="-1"></a>    app.run(host<span class="op">=</span><span class="st">'0.0.0.0'</span>, port<span class="op">=</span><span class="dv">5000</span>, threaded<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="4" type="1">
<li><p>Run this script:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> get_img_data.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Access the web interface:</p>
<ul>
<li>On the Raspberry Pi itself (if you have a GUI): Open a web browser and go to <code>http://localhost:5000</code></li>
<li>From another device on the same network: Open a web browser and go to <code>http://&lt;raspberry_pi_ip&gt;:5000</code> (Replace <code>&lt;raspberry_pi_ip&gt;</code> with your Raspberry Pi’s IP address). For example: <code>http://192.168.4.210:5000/</code></li>
</ul></li>
</ol>
<p>This Python script creates a web-based interface for capturing and organizing image datasets using a Raspberry Pi and its camera. It’s handy for machine learning projects that require labeled image data.</p>
<section id="key-features" class="level4">
<h4 class="anchored" data-anchor-id="key-features">Key Features:</h4>
<ol type="1">
<li><strong>Web Interface</strong>: Accessible from any device on the same network as the Raspberry Pi.</li>
<li><strong>Live Camera Preview</strong>: This shows a real-time feed from the camera.</li>
<li><strong>Labeling System</strong>: Allows users to input labels for different categories of images.</li>
<li><strong>Organized Storage</strong>: Automatically saves images in label-specific subdirectories.</li>
<li><strong>Per-Label Counters</strong>: Keeps track of how many images are captured for each label.</li>
<li><strong>Summary Statistics</strong>: Provides a summary of captured images when stopping the capture process.</li>
</ol>
</section>
<section id="main-components" class="level4">
<h4 class="anchored" data-anchor-id="main-components">Main Components:</h4>
<ol type="1">
<li><strong>Flask Web Application</strong>: Handles routing and serves the web interface.</li>
<li><strong>Picamera2 Integration</strong>: Controls the Raspberry Pi camera.</li>
<li><strong>Threaded Frame Capture</strong>: Ensures smooth live preview.</li>
<li><strong>File Management</strong>: Organizes captured images into labeled directories.</li>
</ol>
</section>
<section id="key-functions" class="level4">
<h4 class="anchored" data-anchor-id="key-functions">Key Functions:</h4>
<ul>
<li><code>initialize_camera()</code>: Sets up the Picamera2 instance.</li>
<li><code>get_frame()</code>: Continuously captures frames for the live preview.</li>
<li><code>generate_frames()</code>: Yields frames for the live video feed.</li>
<li><code>shutdown_server()</code>: Sets the shutdown event, stops the camera, and shuts down the Flask server</li>
<li><code>index()</code>: Handles the label input page.</li>
<li><code>capture_page()</code>: Displays the main capture interface.</li>
<li><code>video_feed()</code>: Shows a live preview to position the camera</li>
<li><code>capture_image()</code>: Saves an image with the current label.</li>
<li><code>stop()</code>: Stops the capture process and displays a summary.</li>
</ul>
</section>
<section id="usage-flow" class="level4">
<h4 class="anchored" data-anchor-id="usage-flow">Usage Flow:</h4>
<ol type="1">
<li>Start the script on your Raspberry Pi.</li>
<li>Access the web interface from a browser.</li>
<li>Enter a label for the images you want to capture and press <code>Start Capture</code>.</li>
</ol>
<p><img src="images/png/enter_label.png" class="img-fluid"></p>
<ol start="4" type="1">
<li>Use the live preview to position the camera.</li>
<li>Click <code>Capture Image</code> to save images under the current label.</li>
</ol>
<p><img src="images/png/capture.png" class="img-fluid"></p>
<ol start="6" type="1">
<li>Change labels as needed for different categories, selecting <code>Change Label</code>.</li>
<li>Click <code>Stop Capture</code> when finished to see a summary.</li>
</ol>
<p><img src="images/png/stop.png" class="img-fluid"></p>
</section>
<section id="technical-notes" class="level4">
<h4 class="anchored" data-anchor-id="technical-notes">Technical Notes:</h4>
<ul>
<li>The script uses threading to handle concurrent frame capture and web serving.</li>
<li>Images are saved with timestamps in their filenames for uniqueness.</li>
<li>The web interface is responsive and can be accessed from mobile devices.</li>
</ul>
</section>
<section id="customization-possibilities" class="level4">
<h4 class="anchored" data-anchor-id="customization-possibilities">Customization Possibilities:</h4>
<ul>
<li>Adjust image resolution in the <code>initialize_camera()</code> function. Here we used QVGA (320X240).</li>
<li>Modify the HTML templates for a different look and feel.</li>
<li>Add additional image processing or analysis steps in the <code>capture_image()</code> function.</li>
</ul>
</section>
<section id="number-of-samples-on-dataset" class="level4">
<h4 class="anchored" data-anchor-id="number-of-samples-on-dataset">Number of samples on Dataset:</h4>
<p>Get around 60 images from each category (<code>periquito</code>, <code>robot</code> and <code>background</code>). Try to capture different angles, backgrounds, and light conditions. On the Raspi, we will end with a folder named <code>dataset</code>, witch contains 3 sub-folders <em>periquito,</em> <em>robot</em>, and <em>background</em>. one for each class of images.</p>
<p>You can use <code>Filezilla</code> to transfer the created dataset to your main computer.</p>
</section>
</section>
</section>
<section id="training-the-model-with-edge-impulse-studio" class="level2">
<h2 class="anchored" data-anchor-id="training-the-model-with-edge-impulse-studio">Training the model with Edge Impulse Studio</h2>
<p>We will use the Edge Impulse Studio to train our model. Go to the <a href="https://edgeimpulse.com/">Edge Impulse Page</a>, enter your account credentials, and create a new project:</p>
<p><img src="images/png/new-proj-ei.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Here, you can clone a similar project: <a href="https://studio.edgeimpulse.com/public/510251/live">Raspi - Img Class</a>.</p>
</blockquote>
<section id="dataset" class="level3">
<h3 class="anchored" data-anchor-id="dataset">Dataset</h3>
<p>We will walk through four main steps using the EI Studio (or Studio). These steps are crucial in preparing our model for use on the Raspi: Dataset, Impulse, Tests, and Deploy (on the Edge Device, in this case, the Raspi).</p>
<blockquote class="blockquote">
<p>Regarding the Dataset, it is essential to point out that our Original Dataset, captured with the Raspi, will be split into <em>Training</em>, <em>Validation</em>, and <em>Test</em>. The Test Set will be separated from the beginning and reserved for use only in the Test phase after training. The Validation Set will be used during training.</p>
</blockquote>
<p>On Studio, follow the steps to upload the captured data:</p>
<ol type="1">
<li>Go to the <code>Data acquisition</code> tab, and in the <code>UPLOAD DATA</code> section, upload the files from your computer in the chosen categories.</li>
<li>Leave to the Studio the splitting of the original dataset into <em>train and test</em> and choose the label about</li>
<li>Repeat the procedure for all three classes. At the end, you should see your “raw data” in the Studio:</li>
</ol>
<p><img src="images/png/data-Aquisition.png" class="img-fluid"></p>
<p>The Studio allows you to explore your data, showing a complete view of all the data in your project. You can clear, inspect, or change labels by clicking on individual data items. In our case, a straightforward project, the data seems OK.</p>
<p><img src="images/png/data-esplorer.png" class="img-fluid"></p>
</section>
</section>
<section id="the-impulse-design" class="level2">
<h2 class="anchored" data-anchor-id="the-impulse-design">The Impulse Design</h2>
<p>In this phase, we should define how to:</p>
<ul>
<li><p>Pre-process our data, which consists of resizing the individual images and determining the <code>color depth</code> to use (be it RGB or Grayscale) and</p></li>
<li><p>Specify a Model. In this case, it will be the <code>Transfer Learning (Images)</code> to fine-tune a pre-trained MobileNet V2 image classification model on our data. This method performs well even with relatively small image datasets (around 180 images in our case).</p></li>
</ul>
<p>Transfer Learning with MobileNet offers a streamlined approach to model training, which is especially beneficial for resource-constrained environments and projects with limited labeled data. MobileNet, known for its lightweight architecture, is a pre-trained model that has already learned valuable features from a large dataset (ImageNet).</p>
<p><img src="images/jpeg/model_1.jpg" class="img-fluid"></p>
<p>By leveraging these learned features, we can train a new model for your specific task with fewer data and computational resources and achieve competitive accuracy.</p>
<p><img src="images/jpeg/model_2.jpg" class="img-fluid"></p>
<p>This approach significantly reduces training time and computational cost, making it ideal for quick prototyping and deployment on embedded devices where efficiency is paramount.</p>
<p>Go to the Impulse Design Tab and create the <em>impulse</em>, defining an image size of 160x160 and squashing them (squared form, without cropping). Select Image and Transfer Learning blocks. Save the Impulse.</p>
<p><img src="images/png/impulse.png" class="img-fluid"></p>
<section id="image-pre-processing" class="level3">
<h3 class="anchored" data-anchor-id="image-pre-processing">Image Pre-Processing</h3>
<p>All the input QVGA/RGB565 images will be converted to 76,800 features (160x160x3).</p>
<p><img src="images/png/preproc.png" class="img-fluid"></p>
<p>Press <code>Save parameters</code> and select <code>Generate features</code> in the next tab.</p>
</section>
<section id="model-design" class="level3">
<h3 class="anchored" data-anchor-id="model-design">Model Design</h3>
<p>MobileNet is a family of efficient convolutional neural networks designed for mobile and embedded vision applications. The key features of MobileNet are:</p>
<ol type="1">
<li>Lightweight: Optimized for mobile devices and embedded systems with limited computational resources.</li>
<li>Speed: Fast inference times, suitable for real-time applications.</li>
<li>Accuracy: Maintains good accuracy despite its compact size.</li>
</ol>
<p><a href="https://arxiv.org/abs/1801.04381">MobileNetV2</a>, introduced in 2018, improves the original MobileNet architecture. Key features include:</p>
<ol type="1">
<li>Inverted Residuals: Inverted residual structures are used where shortcut connections are made between thin bottleneck layers.</li>
<li>Linear Bottlenecks: Removes non-linearities in the narrow layers to prevent the destruction of information.</li>
<li>Depth-wise Separable Convolutions: Continues to use this efficient operation from MobileNetV1.</li>
</ol>
<p>In our project, we will do a <code>Transfer Learning</code> with the <code>MobileNetV2 160x160 1.0</code>, which means that the images used for training (and future inference) should have an <em>input Size</em> of 160x160 pixels and a <em>Width Multiplier</em> of 1.0 (full width, not reduced). This configuration balances between model size, speed, and accuracy.</p>
</section>
<section id="model-training" class="level3">
<h3 class="anchored" data-anchor-id="model-training">Model Training</h3>
<p>Another valuable deep learning technique is <strong>Data Augmentation</strong>. Data augmentation improves the accuracy of machine learning models by creating additional artificial data. A data augmentation system makes small, random changes to the training data during the training process (such as flipping, cropping, or rotating the images).</p>
<p>Looking under the hood, here you can see how Edge Impulse implements a data Augmentation policy on your data:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Implements the data augmentation policy</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> augment_image(image, label):</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flips the image randomly</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_flip_left_right(image)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Increase the image size, then randomly crop it down to</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the original dimensions</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    resize_factor <span class="op">=</span> random.uniform(<span class="dv">1</span>, <span class="fl">1.2</span>)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    new_height <span class="op">=</span> math.floor(resize_factor <span class="op">*</span> INPUT_SHAPE[<span class="dv">0</span>])</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    new_width <span class="op">=</span> math.floor(resize_factor <span class="op">*</span> INPUT_SHAPE[<span class="dv">1</span>])</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.resize_with_crop_or_pad(image, new_height, new_width)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_crop(image, size<span class="op">=</span>INPUT_SHAPE)</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vary the brightness of the image</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_brightness(image, max_delta<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> image, label</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Exposure to these variations during training can help prevent your model from taking shortcuts by “memorizing” superficial clues in your training data, meaning it may better reflect the deep underlying patterns in your dataset.</p>
<p>The final dense layer of our model will have 0 neurons with a 10% dropout for overfitting prevention. Here is the Training result:</p>
<p><img src="images/png/result-train.png" class="img-fluid"></p>
<p>The result is excellent, with a reasonable 35ms of latency (for a Rasp-4), which should result in around 30 fps (frames per second) during inference. A Raspi-Zero should be slower, and the Rasp-5, faster.</p>
</section>
<section id="trading-off-accuracy-versus-speed" class="level3">
<h3 class="anchored" data-anchor-id="trading-off-accuracy-versus-speed">Trading off: Accuracy versus speed</h3>
<p>If faster inference is needed, we should train the model using smaller alphas (0.35, 0.5, and 0.75) or even reduce the image input size, trading with accuracy. However, reducing the input image size and decreasing the alpha (width multiplier) can speed up inference for MobileNet V2, but they have different trade-offs. Let’s compare:</p>
<ol type="1">
<li>Reducing Image Input Size:</li>
</ol>
<p>Pros:</p>
<ul>
<li>Significantly reduces the computational cost across all layers.</li>
<li>Decreases memory usage.</li>
<li>It often provides a substantial speed boost.</li>
</ul>
<p>Cons:</p>
<ul>
<li>It may reduce the model’s ability to detect small features or fine details.</li>
<li>It can significantly impact accuracy, especially for tasks requiring fine-grained recognition.</li>
</ul>
<ol start="2" type="1">
<li>Reducing Alpha (Width Multiplier):</li>
</ol>
<p>Pros:</p>
<ul>
<li>Reduces the number of parameters and computations in the model.</li>
<li>Maintains the original input resolution, potentially preserving more detail.</li>
<li>It can provide a good balance between speed and accuracy.</li>
</ul>
<p>Cons:</p>
<ul>
<li>It may not speed up inference as dramatically as reducing input size.</li>
<li>It can reduce the model’s capacity to learn complex features.</li>
</ul>
<p>Comparison:</p>
<ol type="1">
<li>Speed Impact:
<ul>
<li>Reducing input size often provides a more substantial speed boost because it reduces computations quadratically (halving both width and height reduces computations by about 75%).</li>
<li>Reducing alpha provides a more linear reduction in computations.</li>
</ul></li>
<li>Accuracy Impact:
<ul>
<li>Reducing input size can severely impact accuracy, especially when detecting small objects or fine details.</li>
<li>Reducing alpha tends to have a more gradual impact on accuracy.</li>
</ul></li>
<li>Model Architecture:
<ul>
<li>Changing input size doesn’t alter the model’s architecture.</li>
<li>Changing alpha modifies the model’s structure by reducing the number of channels in each layer.</li>
</ul></li>
</ol>
<p>Recommendation:</p>
<ol type="1">
<li>If our application doesn’t require detecting tiny details and can tolerate some loss in accuracy, reducing the input size is often the most effective way to speed up inference.</li>
<li>Reducing alpha might be preferable if maintaining the ability to detect fine details is crucial or if you need a more balanced trade-off between speed and accuracy.</li>
<li>For best results, you might want to experiment with both:
<ul>
<li>Try MobileNet V2 with input sizes like 160x160 or 92x92</li>
<li>Experiment with alpha values like 1.0, 0.75, 0.5 or 0.35.</li>
</ul></li>
<li>Always benchmark the different configurations on your specific hardware and with your particular dataset to find the optimal balance for your use case.</li>
</ol>
<blockquote class="blockquote">
<p>Remember, the best choice depends on your specific requirements for accuracy, speed, and the nature of the images you’re working with. It’s often worth experimenting with combinations to find the optimal configuration for your particular use case.</p>
</blockquote>
</section>
<section id="model-testing" class="level3">
<h3 class="anchored" data-anchor-id="model-testing">Model Testing</h3>
<p>Now, you should take the data set aside at the start of the project and run the trained model using it as input. Again, the result is excellent (92.22%).</p>
</section>
<section id="deploying-the-model" class="level3">
<h3 class="anchored" data-anchor-id="deploying-the-model">Deploying the model</h3>
<p>As we did in the previous section, we can deploy the trained model as .tflite and use Raspi to run it using Python.</p>
<p>On the <code>Dashboard</code> tab, go to Transfer learning model (int8 quantized) and click on the download icon:</p>
<p><img src="images/png/model.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Let’s also download the float32 version for comparasion</p>
</blockquote>
<p>Transfer the model from your computer to the Raspi (./models), for example, using FileZilla. Also, capture some images for inference (./images).</p>
<p>Import the needed libraries:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Define the paths and labels:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"./images/robot.jpg"</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/ei-raspi-img-class-int8-quantized-model.tflite"</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'background'</span>, <span class="st">'periquito'</span>, <span class="st">'robot'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Note that the models trained on the Edge Impulse Studio will output values with index 0, 1, 2, etc., where the actual labels will follow an alphabetic order.</p>
</blockquote>
<p>Load the model, allocate the tensors, and get the input and output tensor details:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the TFLite model</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get input and output tensors</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>output_details <span class="op">=</span> interpreter.get_output_details()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>One important difference to note is that the <code>dtype</code> of the input details of the model is now <code>int8</code>, which means that the input values go from -128 to +127, while each pixel of our image goes from 0 to 256. This means that we should pre-process the image to match it. We can check here:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>input_dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>numpy.int8</code></pre>
<p>So, let’s open the image and show it:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/infer_robot.png" class="img-fluid"></p>
<p>And perform the pre-processing:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>                  input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> np.array(img, dtype<span class="op">=</span>np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> (img_array <span class="op">/</span> scale <span class="op">+</span> zero_point).clip(<span class="op">-</span><span class="dv">128</span>, <span class="dv">127</span>).astype(np.int8)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> np.expand_dims(img_array, axis<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Checking the input data, we can verify that the input tensor is compatible with what is expected by the model:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>input_data.shape, input_data.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>((1, 160, 160, 3), dtype('int8'))</code></pre>
<p>Now, it is time to perform the inference. Let’s also calculate the latency of the model:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>interpreter.invoke()</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>inference_time <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to milliseconds</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"Inference time: </span><span class="sc">{:.1f}</span><span class="st">ms"</span>.<span class="bu">format</span>(inference_time))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The model will take around 125ms to perform the inference in the Raspi-Zero, which is 3 to 4 times longer than a Raspi-5.</p>
<p>Now, we can get the output labels and probabilities. It is also important to note that the model trained on the Edge Impulse Studio has a softmax in its output (different from the original Movilenet V2), and we should use the model’s raw output as the “probabilities.”</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain results and map them to the classes</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get indices of the top k results</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>top_k_results<span class="op">=</span><span class="dv">3</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get quantization parameters</span></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Dequantize the output</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> dequantized_output</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>        labels[top_k_indices[i]],</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>        probabilities[top_k_indices[i]] <span class="op">*</span> <span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/infer-result.png" class="img-fluid"></p>
<p>Let’s modify the function created before so that we can handle different type of models:</p>
<div class="scroll-code-block">
<div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_classification(img_path, model_path, labels, top_k_results<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>                         apply_softmax<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the image</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the TFLite model</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>    interpreter.allocate_tensors()</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get input and output tensors</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess</span></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>    input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> input_dtype <span class="op">==</span> np.uint8:</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(np.array(img), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> input_dtype <span class="op">==</span> np.int8:</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> np.array(img, dtype<span class="op">=</span>np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> (img_array <span class="op">/</span> scale <span class="op">+</span> zero_point).clip(<span class="op">-</span><span class="dv">128</span>, <span class="dv">127</span>).astype(np.int8)</span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(img_array, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  <span class="co"># float32</span></span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(np.array(img, dtype<span class="op">=</span>np.float32), axis<span class="op">=</span><span class="dv">0</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb57-36"><a href="#cb57-36" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb57-37"><a href="#cb57-37" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb57-38"><a href="#cb57-38" aria-hidden="true" tabindex="-1"></a>    inference_time <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to milliseconds</span></span>
<span id="cb57-39"><a href="#cb57-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-40"><a href="#cb57-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain results</span></span>
<span id="cb57-41"><a href="#cb57-41" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb57-42"><a href="#cb57-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-43"><a href="#cb57-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of the top k results</span></span>
<span id="cb57-44"><a href="#cb57-44" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb57-45"><a href="#cb57-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-46"><a href="#cb57-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle output based on type</span></span>
<span id="cb57-47"><a href="#cb57-47" aria-hidden="true" tabindex="-1"></a>    output_dtype <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb57-48"><a href="#cb57-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_dtype <span class="kw">in</span> [np.int8, np.uint8]:</span>
<span id="cb57-49"><a href="#cb57-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dequantize the output</span></span>
<span id="cb57-50"><a href="#cb57-50" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb57-51"><a href="#cb57-51" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb57-52"><a href="#cb57-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-53"><a href="#cb57-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> apply_softmax:</span>
<span id="cb57-54"><a href="#cb57-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply softmax</span></span>
<span id="cb57-55"><a href="#cb57-55" aria-hidden="true" tabindex="-1"></a>        exp_preds <span class="op">=</span> np.exp(predictions <span class="op">-</span> np.<span class="bu">max</span>(predictions))</span>
<span id="cb57-56"><a href="#cb57-56" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> exp_preds <span class="op">/</span> np.<span class="bu">sum</span>(exp_preds)</span>
<span id="cb57-57"><a href="#cb57-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb57-58"><a href="#cb57-58" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> predictions</span>
<span id="cb57-59"><a href="#cb57-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-60"><a href="#cb57-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb57-61"><a href="#cb57-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb57-62"><a href="#cb57-62" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb57-63"><a href="#cb57-63" aria-hidden="true" tabindex="-1"></a>            labels[top_k_indices[i]],</span>
<span id="cb57-64"><a href="#cb57-64" aria-hidden="true" tabindex="-1"></a>            probabilities[top_k_indices[i]] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb57-65"><a href="#cb57-65" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (<span class="st">"</span><span class="ch">\n\t</span><span class="st">Inference time: </span><span class="sc">{:.1f}</span><span class="st">ms"</span>.<span class="bu">format</span>(inference_time))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And test it with different images and the int8 quantized model (<strong>160x160 alpha =1.0</strong>).</p>
<p><img src="images/png/infer-int8-160.png" class="img-fluid"></p>
<p>Let’s download a smaller model, such as the one trained for the <a href="https://studio.edgeimpulse.com/public/353482/live">Nicla Vision Lab</a> (int8 quantized model (96x96 alpha = 0.1), as a test. We can use the same function:</p>
<p><img src="images/png/infer-int8-96.png" class="img-fluid"></p>
<p>The model lost some accuracy, but it is still OK once our model does not look for many details. Regarding latency, we are around <strong>ten times faster</strong> on the Rasp-Zero.</p>
</section>
</section>
<section id="live-image-classification" class="level2">
<h2 class="anchored" data-anchor-id="live-image-classification">Live Image Classification</h2>
<p>Let’s develop an app to capture images with the USB camera in real time, showing its classification.</p>
Using the nano on the terminal, save the code below, such as <code>img_class_live_infer.py</code>.
<div class="scroll-code-block">
<div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask, Response, render_template_string, request, jsonify</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> queue <span class="im">import</span> Queue</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> Flask(<span class="va">__name__</span>)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> <span class="va">None</span></span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>frame_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>is_classifying <span class="op">=</span> <span class="va">False</span></span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>confidence_threshold <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/ei-raspi-img-class-int8-quantized-model.tflite"</span></span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'background'</span>, <span class="st">'periquito'</span>, <span class="st">'robot'</span>]</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> <span class="va">None</span></span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>classification_queue <span class="op">=</span> Queue(maxsize<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_camera():</span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> picam2</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>    picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a>    config <span class="op">=</span> picam2.create_preview_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">320</span>, <span class="dv">240</span>)})</span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a>    picam2.configure(config)</span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a>    picam2.start()</span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Wait for camera to warm up</span></span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-32"><a href="#cb58-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_frame():</span>
<span id="cb58-33"><a href="#cb58-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> frame</span>
<span id="cb58-34"><a href="#cb58-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb58-35"><a href="#cb58-35" aria-hidden="true" tabindex="-1"></a>        stream <span class="op">=</span> io.BytesIO()</span>
<span id="cb58-36"><a href="#cb58-36" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(stream, <span class="bu">format</span><span class="op">=</span><span class="st">'jpeg'</span>)</span>
<span id="cb58-37"><a href="#cb58-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb58-38"><a href="#cb58-38" aria-hidden="true" tabindex="-1"></a>            frame <span class="op">=</span> stream.getvalue()</span>
<span id="cb58-39"><a href="#cb58-39" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Capture frames more frequently</span></span>
<span id="cb58-40"><a href="#cb58-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-41"><a href="#cb58-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_frames():</span>
<span id="cb58-42"><a href="#cb58-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb58-43"><a href="#cb58-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb58-44"><a href="#cb58-44" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb58-45"><a href="#cb58-45" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (<span class="st">b'--frame</span><span class="ch">\r\n</span><span class="st">'</span></span>
<span id="cb58-46"><a href="#cb58-46" aria-hidden="true" tabindex="-1"></a>                       <span class="st">b'Content-Type: image/jpeg</span><span class="ch">\r\n\r\n</span><span class="st">'</span> <span class="op">+</span> frame <span class="op">+</span> <span class="st">b'</span><span class="ch">\r\n</span><span class="st">'</span>)</span>
<span id="cb58-47"><a href="#cb58-47" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)</span>
<span id="cb58-48"><a href="#cb58-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-49"><a href="#cb58-49" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_model():</span>
<span id="cb58-50"><a href="#cb58-50" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> interpreter</span>
<span id="cb58-51"><a href="#cb58-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> interpreter <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb58-52"><a href="#cb58-52" aria-hidden="true" tabindex="-1"></a>        interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb58-53"><a href="#cb58-53" aria-hidden="true" tabindex="-1"></a>        interpreter.allocate_tensors()</span>
<span id="cb58-54"><a href="#cb58-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> interpreter</span>
<span id="cb58-55"><a href="#cb58-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-56"><a href="#cb58-56" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_image(img, interpreter):</span>
<span id="cb58-57"><a href="#cb58-57" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb58-58"><a href="#cb58-58" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb58-59"><a href="#cb58-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-60"><a href="#cb58-60" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb58-61"><a href="#cb58-61" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb58-62"><a href="#cb58-62" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> np.expand_dims(np.array(img), axis<span class="op">=</span><span class="dv">0</span>)<span class="op">\</span></span>
<span id="cb58-63"><a href="#cb58-63" aria-hidden="true" tabindex="-1"></a>                             .astype(input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>])</span>
<span id="cb58-64"><a href="#cb58-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-65"><a href="#cb58-65" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb58-66"><a href="#cb58-66" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb58-67"><a href="#cb58-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-68"><a href="#cb58-68" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb58-69"><a href="#cb58-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle output based on type</span></span>
<span id="cb58-70"><a href="#cb58-70" aria-hidden="true" tabindex="-1"></a>    output_dtype <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb58-71"><a href="#cb58-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_dtype <span class="kw">in</span> [np.int8, np.uint8]:</span>
<span id="cb58-72"><a href="#cb58-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dequantize the output</span></span>
<span id="cb58-73"><a href="#cb58-73" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb58-74"><a href="#cb58-74" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb58-75"><a href="#cb58-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions</span>
<span id="cb58-76"><a href="#cb58-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-77"><a href="#cb58-77" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classification_worker():</span>
<span id="cb58-78"><a href="#cb58-78" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> load_model()</span>
<span id="cb58-79"><a href="#cb58-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb58-80"><a href="#cb58-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> is_classifying:</span>
<span id="cb58-81"><a href="#cb58-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> frame_lock:</span>
<span id="cb58-82"><a href="#cb58-82" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb58-83"><a href="#cb58-83" aria-hidden="true" tabindex="-1"></a>                    img <span class="op">=</span> Image.<span class="bu">open</span>(io.BytesIO(frame))</span>
<span id="cb58-84"><a href="#cb58-84" aria-hidden="true" tabindex="-1"></a>            predictions <span class="op">=</span> classify_image(img, interpreter)</span>
<span id="cb58-85"><a href="#cb58-85" aria-hidden="true" tabindex="-1"></a>            max_prob <span class="op">=</span> np.<span class="bu">max</span>(predictions)</span>
<span id="cb58-86"><a href="#cb58-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> max_prob <span class="op">&gt;=</span> confidence_threshold:</span>
<span id="cb58-87"><a href="#cb58-87" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> labels[np.argmax(predictions)]</span>
<span id="cb58-88"><a href="#cb58-88" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb58-89"><a href="#cb58-89" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> <span class="st">'Uncertain'</span></span>
<span id="cb58-90"><a href="#cb58-90" aria-hidden="true" tabindex="-1"></a>            classification_queue.put({<span class="st">'label'</span>: label, </span>
<span id="cb58-91"><a href="#cb58-91" aria-hidden="true" tabindex="-1"></a>                                      <span class="st">'probability'</span>: <span class="bu">float</span>(max_prob)})</span>
<span id="cb58-92"><a href="#cb58-92" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust based on your needs</span></span>
<span id="cb58-93"><a href="#cb58-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-94"><a href="#cb58-94" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/'</span>)</span>
<span id="cb58-95"><a href="#cb58-95" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> index():</span>
<span id="cb58-96"><a href="#cb58-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb58-97"><a href="#cb58-97" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb58-98"><a href="#cb58-98" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb58-99"><a href="#cb58-99" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb58-100"><a href="#cb58-100" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Image Classification&lt;/title&gt;</span></span>
<span id="cb58-101"><a href="#cb58-101" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script </span></span>
<span id="cb58-102"><a href="#cb58-102" aria-hidden="true" tabindex="-1"></a><span class="st">                src="https://code.jquery.com/jquery-3.6.0.min.js"&gt;</span></span>
<span id="cb58-103"><a href="#cb58-103" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb58-104"><a href="#cb58-104" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script&gt;</span></span>
<span id="cb58-105"><a href="#cb58-105" aria-hidden="true" tabindex="-1"></a><span class="st">                function startClassification() {</span></span>
<span id="cb58-106"><a href="#cb58-106" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/start');</span></span>
<span id="cb58-107"><a href="#cb58-107" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#startBtn').prop('disabled', true);</span></span>
<span id="cb58-108"><a href="#cb58-108" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#stopBtn').prop('disabled', false);</span></span>
<span id="cb58-109"><a href="#cb58-109" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb58-110"><a href="#cb58-110" aria-hidden="true" tabindex="-1"></a><span class="st">                function stopClassification() {</span></span>
<span id="cb58-111"><a href="#cb58-111" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/stop');</span></span>
<span id="cb58-112"><a href="#cb58-112" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#startBtn').prop('disabled', false);</span></span>
<span id="cb58-113"><a href="#cb58-113" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#stopBtn').prop('disabled', true);</span></span>
<span id="cb58-114"><a href="#cb58-114" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb58-115"><a href="#cb58-115" aria-hidden="true" tabindex="-1"></a><span class="st">                function updateConfidence() {</span></span>
<span id="cb58-116"><a href="#cb58-116" aria-hidden="true" tabindex="-1"></a><span class="st">                    var confidence = $('#confidence').val();</span></span>
<span id="cb58-117"><a href="#cb58-117" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/update_confidence', {confidence: confidence});</span></span>
<span id="cb58-118"><a href="#cb58-118" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb58-119"><a href="#cb58-119" aria-hidden="true" tabindex="-1"></a><span class="st">                function updateClassification() {</span></span>
<span id="cb58-120"><a href="#cb58-120" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.get('/get_classification', function(data) {</span></span>
<span id="cb58-121"><a href="#cb58-121" aria-hidden="true" tabindex="-1"></a><span class="st">                        $('#classification').text(data.label + ': ' </span></span>
<span id="cb58-122"><a href="#cb58-122" aria-hidden="true" tabindex="-1"></a><span class="st">                        + data.probability.toFixed(2));</span></span>
<span id="cb58-123"><a href="#cb58-123" aria-hidden="true" tabindex="-1"></a><span class="st">                    });</span></span>
<span id="cb58-124"><a href="#cb58-124" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb58-125"><a href="#cb58-125" aria-hidden="true" tabindex="-1"></a><span class="st">                $(document).ready(function() {</span></span>
<span id="cb58-126"><a href="#cb58-126" aria-hidden="true" tabindex="-1"></a><span class="st">                    setInterval(updateClassification, 100);  </span></span>
<span id="cb58-127"><a href="#cb58-127" aria-hidden="true" tabindex="-1"></a><span class="st">                    // Update every 100ms</span></span>
<span id="cb58-128"><a href="#cb58-128" aria-hidden="true" tabindex="-1"></a><span class="st">                });</span></span>
<span id="cb58-129"><a href="#cb58-129" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb58-130"><a href="#cb58-130" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb58-131"><a href="#cb58-131" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb58-132"><a href="#cb58-132" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Image Classification&lt;/h1&gt;</span></span>
<span id="cb58-133"><a href="#cb58-133" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;img src="</span><span class="sc">{{</span><span class="st"> url_for('video_feed') </span><span class="sc">}}</span><span class="st">" width="640" height="480" /&gt;</span></span>
<span id="cb58-134"><a href="#cb58-134" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb58-135"><a href="#cb58-135" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;button id="startBtn" onclick="startClassification()"&gt;</span></span>
<span id="cb58-136"><a href="#cb58-136" aria-hidden="true" tabindex="-1"></a><span class="st">            Start Classification&lt;/button&gt;</span></span>
<span id="cb58-137"><a href="#cb58-137" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;button id="stopBtn" onclick="stopClassification()" disabled&gt;</span></span>
<span id="cb58-138"><a href="#cb58-138" aria-hidden="true" tabindex="-1"></a><span class="st">            Stop Classification&lt;/button&gt;</span></span>
<span id="cb58-139"><a href="#cb58-139" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb58-140"><a href="#cb58-140" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;label for="confidence"&gt;Confidence Threshold:&lt;/label&gt;</span></span>
<span id="cb58-141"><a href="#cb58-141" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;input type="number" id="confidence" name="confidence" min="0" </span></span>
<span id="cb58-142"><a href="#cb58-142" aria-hidden="true" tabindex="-1"></a><span class="st">            max="1" step="0.1" value="0.8" onchange="updateConfidence()"&gt;</span></span>
<span id="cb58-143"><a href="#cb58-143" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb58-144"><a href="#cb58-144" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;div id="classification"&gt;Waiting for classification...&lt;/div&gt;</span></span>
<span id="cb58-145"><a href="#cb58-145" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb58-146"><a href="#cb58-146" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb58-147"><a href="#cb58-147" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>)</span>
<span id="cb58-148"><a href="#cb58-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-149"><a href="#cb58-149" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/video_feed'</span>)</span>
<span id="cb58-150"><a href="#cb58-150" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> video_feed():</span>
<span id="cb58-151"><a href="#cb58-151" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Response(generate_frames(),</span>
<span id="cb58-152"><a href="#cb58-152" aria-hidden="true" tabindex="-1"></a>                    mimetype<span class="op">=</span><span class="st">'multipart/x-mixed-replace; boundary=frame'</span>)</span>
<span id="cb58-153"><a href="#cb58-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-154"><a href="#cb58-154" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/start'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb58-155"><a href="#cb58-155" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> start_classification():</span>
<span id="cb58-156"><a href="#cb58-156" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> is_classifying</span>
<span id="cb58-157"><a href="#cb58-157" aria-hidden="true" tabindex="-1"></a>    is_classifying <span class="op">=</span> <span class="va">True</span></span>
<span id="cb58-158"><a href="#cb58-158" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb58-159"><a href="#cb58-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-160"><a href="#cb58-160" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/stop'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb58-161"><a href="#cb58-161" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stop_classification():</span>
<span id="cb58-162"><a href="#cb58-162" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> is_classifying</span>
<span id="cb58-163"><a href="#cb58-163" aria-hidden="true" tabindex="-1"></a>    is_classifying <span class="op">=</span> <span class="va">False</span></span>
<span id="cb58-164"><a href="#cb58-164" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb58-165"><a href="#cb58-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-166"><a href="#cb58-166" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/update_confidence'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb58-167"><a href="#cb58-167" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_confidence():</span>
<span id="cb58-168"><a href="#cb58-168" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> confidence_threshold</span>
<span id="cb58-169"><a href="#cb58-169" aria-hidden="true" tabindex="-1"></a>    confidence_threshold <span class="op">=</span> <span class="bu">float</span>(request.form[<span class="st">'confidence'</span>])</span>
<span id="cb58-170"><a href="#cb58-170" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb58-171"><a href="#cb58-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-172"><a href="#cb58-172" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/get_classification'</span>)</span>
<span id="cb58-173"><a href="#cb58-173" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_classification():</span>
<span id="cb58-174"><a href="#cb58-174" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> is_classifying:</span>
<span id="cb58-175"><a href="#cb58-175" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> jsonify({<span class="st">'label'</span>: <span class="st">'Not classifying'</span>, <span class="st">'probability'</span>: <span class="dv">0</span>})</span>
<span id="cb58-176"><a href="#cb58-176" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb58-177"><a href="#cb58-177" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> classification_queue.get_nowait()</span>
<span id="cb58-178"><a href="#cb58-178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> Queue.Empty:</span>
<span id="cb58-179"><a href="#cb58-179" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> {<span class="st">'label'</span>: <span class="st">'Processing'</span>, <span class="st">'probability'</span>: <span class="dv">0</span>}</span>
<span id="cb58-180"><a href="#cb58-180" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> jsonify(result)</span>
<span id="cb58-181"><a href="#cb58-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-182"><a href="#cb58-182" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb58-183"><a href="#cb58-183" aria-hidden="true" tabindex="-1"></a>    initialize_camera()</span>
<span id="cb58-184"><a href="#cb58-184" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>get_frame, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb58-185"><a href="#cb58-185" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>classification_worker, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb58-186"><a href="#cb58-186" aria-hidden="true" tabindex="-1"></a>    app.run(host<span class="op">=</span><span class="st">'0.0.0.0'</span>, port<span class="op">=</span><span class="dv">5000</span>, threaded<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>On the terminal, run:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> img_class_live_infer.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And access the web interface:</p>
<ul>
<li>On the Raspberry Pi itself (if you have a GUI): Open a web browser and go to <code>http://localhost:5000</code></li>
<li>From another device on the same network: Open a web browser and go to <code>http://&lt;raspberry_pi_ip&gt;:5000</code> (Replace <code>&lt;raspberry_pi_ip&gt;</code> with your Raspberry Pi’s IP address). For example: <code>http://192.168.4.210:5000/</code></li>
</ul>
<p>Here are some screenshots of the app running on an external desktop</p>
<p><img src="images/png/app-inference.png" class="img-fluid"></p>
<p>Here, you can see the app running on the YouTube:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/o1QsQrpCMw4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>The code creates a web application for real-time image classification using a Raspberry Pi, its camera module, and a TensorFlow Lite model. The application uses Flask to serve a web interface where is possible to view the camera feed and see live classification results.</p>
<section id="key-components" class="level4">
<h4 class="anchored" data-anchor-id="key-components">Key Components:</h4>
<ol type="1">
<li><strong>Flask Web Application</strong>: Serves the user interface and handles requests.</li>
<li><strong>PiCamera2</strong>: Captures images from the Raspberry Pi camera module.</li>
<li><strong>TensorFlow Lite</strong>: Runs the image classification model.</li>
<li><strong>Threading</strong>: Manages concurrent operations for smooth performance.</li>
</ol>
</section>
<section id="main-features" class="level4">
<h4 class="anchored" data-anchor-id="main-features">Main Features:</h4>
<ul>
<li>Live camera feed display</li>
<li>Real-time image classification</li>
<li>Adjustable confidence threshold</li>
<li>Start/Stop classification on demand</li>
</ul>
</section>
<section id="code-structure" class="level4">
<h4 class="anchored" data-anchor-id="code-structure">Code Structure:</h4>
<ol type="1">
<li><strong>Imports and Setup</strong>:
<ul>
<li>Flask for web application</li>
<li>PiCamera2 for camera control</li>
<li>TensorFlow Lite for inference</li>
<li>Threading and Queue for concurrent operations</li>
</ul></li>
<li><strong>Global Variables</strong>:
<ul>
<li>Camera and frame management</li>
<li>Classification control</li>
<li>Model and label information</li>
</ul></li>
<li><strong>Camera Functions</strong>:
<ul>
<li><code>initialize_camera()</code>: Sets up the PiCamera2</li>
<li><code>get_frame()</code>: Continuously captures frames</li>
<li><code>generate_frames()</code>: Yields frames for the web feed</li>
</ul></li>
<li><strong>Model Functions</strong>:
<ul>
<li><code>load_model()</code>: Loads the TFLite model</li>
<li><code>classify_image()</code>: Performs inference on a single image</li>
</ul></li>
<li><strong>Classification Worker</strong>:
<ul>
<li>Runs in a separate thread</li>
<li>Continuously classifies frames when active</li>
<li>Updates a queue with the latest results</li>
</ul></li>
<li><strong>Flask Routes</strong>:
<ul>
<li><code>/</code>: Serves the main HTML page</li>
<li><code>/video_feed</code>: Streams the camera feed</li>
<li><code>/start</code> and <code>/stop</code>: Controls classification</li>
<li><code>/update_confidence</code>: Adjusts the confidence threshold</li>
<li><code>/get_classification</code>: Returns the latest classification result</li>
</ul></li>
<li><strong>HTML Template</strong>:
<ul>
<li>Displays camera feed and classification results</li>
<li>Provides controls for starting/stopping and adjusting settings</li>
</ul></li>
<li><strong>Main Execution</strong>:
<ul>
<li>Initializes camera and starts necessary threads</li>
<li>Runs the Flask application</li>
</ul></li>
</ol>
</section>
<section id="key-concepts" class="level4">
<h4 class="anchored" data-anchor-id="key-concepts">Key Concepts:</h4>
<ol type="1">
<li><strong>Concurrent Operations</strong>: Using threads to handle camera capture and classification separately from the web server.</li>
<li><strong>Real-time Updates</strong>: Frequent updates to the classification results without page reloads.</li>
<li><strong>Model Reuse</strong>: Loading the TFLite model once and reusing it for efficiency.</li>
<li><strong>Flexible Configuration</strong>: Allowing users to adjust the confidence threshold on the fly.</li>
</ol>
</section>
<section id="usage" class="level4">
<h4 class="anchored" data-anchor-id="usage">Usage:</h4>
<ol type="1">
<li>Ensure all dependencies are installed.</li>
<li>Run the script on a Raspberry Pi with a camera module.</li>
<li>Access the web interface from a browser using the Raspberry Pi’s IP address.</li>
<li>Start classification and adjust settings as needed.</li>
</ol>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion:</h2>
<p>Image classification has emerged as a powerful and versatile application of machine learning, with significant implications for various fields, from healthcare to environmental monitoring. This chapter has demonstrated how to implement a robust image classification system on edge devices like the Raspi-Zero and Rasp-5, showcasing the potential for real-time, on-device intelligence.</p>
<p>We’ve explored the entire pipeline of an image classification project, from data collection and model training using Edge Impulse Studio to deploying and running inferences on a Raspi. The process highlighted several key points:</p>
<ol type="1">
<li>The importance of proper data collection and preprocessing for training effective models.</li>
<li>The power of transfer learning, allowing us to leverage pre-trained models like MobileNet V2 for efficient training with limited data.</li>
<li>The trade-offs between model accuracy and inference speed, especially crucial for edge devices.</li>
<li>The implementation of real-time classification using a web-based interface, demonstrating practical applications.</li>
</ol>
<p>The ability to run these models on edge devices like the Raspi opens up numerous possibilities for IoT applications, autonomous systems, and real-time monitoring solutions. It allows for reduced latency, improved privacy, and operation in environments with limited connectivity.</p>
<p>As we’ve seen, even with the computational constraints of edge devices, it’s possible to achieve impressive results in terms of both accuracy and speed. The flexibility to adjust model parameters, such as input size and alpha values, allows for fine-tuning to meet specific project requirements.</p>
<p>Looking forward, the field of edge AI and image classification continues to evolve rapidly. Advances in model compression techniques, hardware acceleration, and more efficient neural network architectures promise to further expand the capabilities of edge devices in computer vision tasks.</p>
<p>This project serves as a foundation for more complex computer vision applications and encourages further exploration into the exciting world of edge AI and IoT. Whether it’s for industrial automation, smart home applications, or environmental monitoring, the skills and concepts covered here provide a solid starting point for a wide range of innovative projects.</p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<ul>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/tree/main/IMG_CLASS/dataset">Dataset Example</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/setup_test.ipynb">Setup Test Notebook on a Raspi</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/10_Image_Classification.ipynb">Image Classification Notebook on a Raspi</a></p></li>
<li><p><a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/2_Applications_Deploy/Class_16/cifar_10/CNN_Cifar_10_TFLite.ipynb#scrollTo=iiVBUpuHXEtw">CNN to classify Cifar-10 dataset at CoLab</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/20_Cifar_10_Image_Classification.ipynb">Cifar 10 - Image Classification on a Raspi</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/tree/main/IMG_CLASS/python_scripts">Python Scripts</a></p></li>
<li><p><a href="https://studio.edgeimpulse.com/public/510251/live">Edge Impulse Project</a></p></li>
</ul>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../raspi/setup/setup.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Setup</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../raspi/object_detection/object_detection.html" class="pagination-link">
        <span class="nav-page-text">Object Detection</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb60" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Image Classification {.unnumbered}</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="al">![*DALL·E prompt - A cover image for an 'Image Classification' chapter in a Raspberry Pi tutorial, designed in the same vintage 1950s electronics lab style as previous covers. The scene should feature a Raspberry Pi connected to a camera module, with the camera capturing a photo of the small blue robot provided by the user. The robot should be placed on a workbench, surrounded by classic lab tools like soldering irons, resistors, and wires. The lab background should include vintage equipment like oscilloscopes and tube radios, maintaining the detailed and nostalgic feel of the era. No text or logos should be included.*](images/jpeg/img_class_cover.jpg)</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>Image classification is a fundamental task in computer vision that involves categorizing an image into one of several predefined classes. It's a cornerstone of artificial intelligence, enabling machines to interpret and understand visual information in a way that mimics human perception.</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>Image classification refers to assigning a label or category to an entire image based on its visual content. This task is crucial in computer vision and has numerous applications across various industries. Image classification's importance lies in its ability to automate visual understanding tasks that would otherwise require human intervention.</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a><span class="fu">### Applications in Real-World Scenarios</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>Image classification has found its way into numerous real-world applications, revolutionizing various sectors:</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Healthcare: Assisting in medical image analysis, such as identifying abnormalities in X-rays or MRIs.</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Agriculture: Monitoring crop health and detecting plant diseases through aerial imagery.</span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Automotive: Enabling advanced driver assistance systems and autonomous vehicles to recognize road signs, pedestrians, and other vehicles.</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Retail: Powering visual search capabilities and automated inventory management systems.</span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Security and Surveillance: Enhancing threat detection and facial recognition systems.</span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Environmental Monitoring: Analyzing satellite imagery for deforestation, urban planning, and climate change studies.</span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a><span class="fu">### Advantages of Running Classification on Edge Devices like Raspberry Pi</span></span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a>Implementing image classification on edge devices such as the Raspberry Pi offers several compelling advantages:</span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-26"><a href="#cb60-26" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Low Latency: Processing images locally eliminates the need to send data to cloud servers, significantly reducing response times.</span>
<span id="cb60-27"><a href="#cb60-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-28"><a href="#cb60-28" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Offline Functionality: Classification can be performed without an internet connection, making it suitable for remote or connectivity-challenged environments.</span>
<span id="cb60-29"><a href="#cb60-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-30"><a href="#cb60-30" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Privacy and Security: Sensitive image data remains on the local device, addressing data privacy concerns and compliance requirements.</span>
<span id="cb60-31"><a href="#cb60-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-32"><a href="#cb60-32" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Cost-Effectiveness: Eliminates the need for expensive cloud computing resources, especially for continuous or high-volume classification tasks.</span>
<span id="cb60-33"><a href="#cb60-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-34"><a href="#cb60-34" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Scalability: Enables distributed computing architectures where multiple devices can work independently or in a network.</span>
<span id="cb60-35"><a href="#cb60-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-36"><a href="#cb60-36" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Energy Efficiency: Optimized models on dedicated hardware can be more energy-efficient than cloud-based solutions, which is crucial for battery-powered or remote applications.</span>
<span id="cb60-37"><a href="#cb60-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-38"><a href="#cb60-38" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>Customization: Deploying specialized or frequently updated models tailored to specific use cases is more manageable.</span>
<span id="cb60-39"><a href="#cb60-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-40"><a href="#cb60-40" aria-hidden="true" tabindex="-1"></a>We can create more responsive, secure, and efficient computer vision solutions by leveraging the power of edge devices like Raspberry Pi for image classification. This approach opens up new possibilities for integrating intelligent visual processing into various applications and environments.</span>
<span id="cb60-41"><a href="#cb60-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-42"><a href="#cb60-42" aria-hidden="true" tabindex="-1"></a>In the following sections, we'll explore how to implement and optimize image classification on the Raspberry Pi, harnessing these advantages to create powerful and efficient computer vision systems.</span>
<span id="cb60-43"><a href="#cb60-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-44"><a href="#cb60-44" aria-hidden="true" tabindex="-1"></a><span class="fu">## Setting Up the Environment</span></span>
<span id="cb60-45"><a href="#cb60-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-46"><a href="#cb60-46" aria-hidden="true" tabindex="-1"></a><span class="fu">### Updating the Raspberry Pi</span></span>
<span id="cb60-47"><a href="#cb60-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-48"><a href="#cb60-48" aria-hidden="true" tabindex="-1"></a>First, ensure your Raspberry Pi is up to date:</span>
<span id="cb60-49"><a href="#cb60-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-50"><a href="#cb60-50" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-51"><a href="#cb60-51" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span>
<span id="cb60-52"><a href="#cb60-52" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt upgrade <span class="at">-y</span></span>
<span id="cb60-53"><a href="#cb60-53" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-54"><a href="#cb60-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-55"><a href="#cb60-55" aria-hidden="true" tabindex="-1"></a><span class="fu">### Installing Required Libraries</span></span>
<span id="cb60-56"><a href="#cb60-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-57"><a href="#cb60-57" aria-hidden="true" tabindex="-1"></a>Install the necessary libraries for image processing and machine learning:</span>
<span id="cb60-58"><a href="#cb60-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-59"><a href="#cb60-59" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-60"><a href="#cb60-60" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install python3-pip</span>
<span id="cb60-61"><a href="#cb60-61" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> rm /usr/lib/python3.11/EXTERNALLY-MANAGED</span>
<span id="cb60-62"><a href="#cb60-62" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install <span class="at">--upgrade</span> pip</span>
<span id="cb60-63"><a href="#cb60-63" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-64"><a href="#cb60-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-65"><a href="#cb60-65" aria-hidden="true" tabindex="-1"></a><span class="fu">### Setting up a Virtual Environment (Optional but Recommended)</span></span>
<span id="cb60-66"><a href="#cb60-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-67"><a href="#cb60-67" aria-hidden="true" tabindex="-1"></a>Create a virtual environment to manage dependencies:</span>
<span id="cb60-68"><a href="#cb60-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-69"><a href="#cb60-69" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-70"><a href="#cb60-70" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">-m</span> venv ~/tflite</span>
<span id="cb60-71"><a href="#cb60-71" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ~/tflite/bin/activate</span>
<span id="cb60-72"><a href="#cb60-72" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-73"><a href="#cb60-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-74"><a href="#cb60-74" aria-hidden="true" tabindex="-1"></a><span class="fu">### Installing TensorFlow Lite</span></span>
<span id="cb60-75"><a href="#cb60-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-76"><a href="#cb60-76" aria-hidden="true" tabindex="-1"></a>We are interested in performing **inference**, which refers to executing a TensorFlow Lite model on a device to make predictions based on input data. To perform an inference with a TensorFlow Lite model, we must run it through an **interpreter**. The TensorFlow Lite interpreter is designed to be lean and fast. The interpreter uses a static graph ordering and a custom (less-dynamic) memory allocator to ensure minimal load, initialization, and execution latency.</span>
<span id="cb60-77"><a href="#cb60-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-78"><a href="#cb60-78" aria-hidden="true" tabindex="-1"></a>We'll use the <span class="co">[</span><span class="ot">TensorFlow Lite runtime</span><span class="co">](https://pypi.org/project/tflite-runtime/)</span> for Raspberry Pi, a simplified library for running machine learning models on mobile and embedded devices, without including all TensorFlow packages. </span>
<span id="cb60-79"><a href="#cb60-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-80"><a href="#cb60-80" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-81"><a href="#cb60-81" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install tflite_runtime <span class="at">--no-deps</span></span>
<span id="cb60-82"><a href="#cb60-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-83"><a href="#cb60-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-84"><a href="#cb60-84" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The wheel installed: </span><span class="in">`tflite_runtime-2.14.0-cp311-cp311-manylinux_2_34_aarch64.whl`</span></span>
<span id="cb60-85"><a href="#cb60-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-86"><a href="#cb60-86" aria-hidden="true" tabindex="-1"></a><span class="fu">### Installing Additional Python Libraries</span></span>
<span id="cb60-87"><a href="#cb60-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-88"><a href="#cb60-88" aria-hidden="true" tabindex="-1"></a>Install required Python libraries for use with Image Classification:</span>
<span id="cb60-89"><a href="#cb60-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-90"><a href="#cb60-90" aria-hidden="true" tabindex="-1"></a>If you have another version of Numpy installed, first uninstall it.</span>
<span id="cb60-91"><a href="#cb60-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-92"><a href="#cb60-92" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-93"><a href="#cb60-93" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> uninstall numpy</span>
<span id="cb60-94"><a href="#cb60-94" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-95"><a href="#cb60-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-96"><a href="#cb60-96" aria-hidden="true" tabindex="-1"></a>Install <span class="in">`version 1.23.2`</span>, which is compatible with the tflite_runtime. </span>
<span id="cb60-97"><a href="#cb60-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-98"><a href="#cb60-98" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-99"><a href="#cb60-99" aria-hidden="true" tabindex="-1"></a> <span class="ex">pip3</span> install numpy==1.23.2</span>
<span id="cb60-100"><a href="#cb60-100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-101"><a href="#cb60-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-102"><a href="#cb60-102" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-103"><a href="#cb60-103" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install Pillow matplotlib</span>
<span id="cb60-104"><a href="#cb60-104" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-105"><a href="#cb60-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-106"><a href="#cb60-106" aria-hidden="true" tabindex="-1"></a><span class="fu">### Creating a working directory:</span></span>
<span id="cb60-107"><a href="#cb60-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-108"><a href="#cb60-108" aria-hidden="true" tabindex="-1"></a>If you are working on the Raspi-Zero with the minimum OS (No Desktop), you may not have a user-pre-defined directory tree (you can check it with <span class="in">`ls`</span>. So, let's create one:</span>
<span id="cb60-109"><a href="#cb60-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-110"><a href="#cb60-110" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-111"><a href="#cb60-111" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> Documents</span>
<span id="cb60-112"><a href="#cb60-112" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> Documents/</span>
<span id="cb60-113"><a href="#cb60-113" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> TFLITE</span>
<span id="cb60-114"><a href="#cb60-114" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> TFLITE/</span>
<span id="cb60-115"><a href="#cb60-115" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> IMG_CLASS</span>
<span id="cb60-116"><a href="#cb60-116" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> IMG_CLASS</span>
<span id="cb60-117"><a href="#cb60-117" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> models</span>
<span id="cb60-118"><a href="#cb60-118" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> models</span>
<span id="cb60-119"><a href="#cb60-119" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-120"><a href="#cb60-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-121"><a href="#cb60-121" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; On the Raspi-5, the /Documents should be there. </span></span>
<span id="cb60-122"><a href="#cb60-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-123"><a href="#cb60-123" aria-hidden="true" tabindex="-1"></a>**Get a pre-trained Image Classification model**:</span>
<span id="cb60-124"><a href="#cb60-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-125"><a href="#cb60-125" aria-hidden="true" tabindex="-1"></a>An appropriate pre-trained model is crucial for successful image classification on resource-constrained devices like the Raspberry Pi. **MobileNet** is designed for mobile and embedded vision applications with a good balance between accuracy and speed. Versions: MobileNetV1, MobileNetV2, MobileNetV3. Let's download the V2:</span>
<span id="cb60-126"><a href="#cb60-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-127"><a href="#cb60-127" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-128"><a href="#cb60-128" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://storage.googleapis.com/download.tensorflow.org/models/</span>
<span id="cb60-129"><a href="#cb60-129" aria-hidden="true" tabindex="-1"></a><span class="ex">tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz</span></span>
<span id="cb60-130"><a href="#cb60-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-131"><a href="#cb60-131" aria-hidden="true" tabindex="-1"></a><span class="fu">tar</span> xzf mobilenet_v2_1.0_224_quant.tgz</span>
<span id="cb60-132"><a href="#cb60-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-133"><a href="#cb60-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-134"><a href="#cb60-134" aria-hidden="true" tabindex="-1"></a>Get its labels:</span>
<span id="cb60-135"><a href="#cb60-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-136"><a href="#cb60-136" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-137"><a href="#cb60-137" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/</span>
<span id="cb60-138"><a href="#cb60-138" aria-hidden="true" tabindex="-1"></a><span class="ex">lite/java/demo/app/src/main/assets/labels_mobilenet_quant_v1_224.txt</span> <span class="at">-O</span> labels.txt</span>
<span id="cb60-139"><a href="#cb60-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-140"><a href="#cb60-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-141"><a href="#cb60-141" aria-hidden="true" tabindex="-1"></a>In the end, you should have the models in its directory: </span>
<span id="cb60-142"><a href="#cb60-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-143"><a href="#cb60-143" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/models_dir.png)</span></span>
<span id="cb60-144"><a href="#cb60-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-145"><a href="#cb60-145" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; We will only need the </span><span class="in">`mobilenet_v2_1.0_224_quant.tflite`</span><span class="at"> model and the </span><span class="in">`labels.txt`</span><span class="at">. You can delete the other files. </span></span>
<span id="cb60-146"><a href="#cb60-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-147"><a href="#cb60-147" aria-hidden="true" tabindex="-1"></a><span class="fu">### Setting up Jupyter Notebook (Optional)</span></span>
<span id="cb60-148"><a href="#cb60-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-149"><a href="#cb60-149" aria-hidden="true" tabindex="-1"></a>If you prefer using Jupyter Notebook for development:</span>
<span id="cb60-150"><a href="#cb60-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-151"><a href="#cb60-151" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-152"><a href="#cb60-152" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install jupyter</span>
<span id="cb60-153"><a href="#cb60-153" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--generate-config</span></span>
<span id="cb60-154"><a href="#cb60-154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-155"><a href="#cb60-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-156"><a href="#cb60-156" aria-hidden="true" tabindex="-1"></a>To run Jupyter Notebook, run the command (change the IP address for yours):</span>
<span id="cb60-157"><a href="#cb60-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-158"><a href="#cb60-158" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-159"><a href="#cb60-159" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--ip</span><span class="op">=</span>192.168.4.210 <span class="at">--no-browser</span></span>
<span id="cb60-160"><a href="#cb60-160" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-161"><a href="#cb60-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-162"><a href="#cb60-162" aria-hidden="true" tabindex="-1"></a>On the terminal, you can see the local URL address to open the notebook:</span>
<span id="cb60-163"><a href="#cb60-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-164"><a href="#cb60-164" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/notebook_token.png)</span></span>
<span id="cb60-165"><a href="#cb60-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-166"><a href="#cb60-166" aria-hidden="true" tabindex="-1"></a>You can access it from another device by entering the Raspberry Pi's IP address and the provided token in a web browser (you can copy the token from the terminal).</span>
<span id="cb60-167"><a href="#cb60-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-168"><a href="#cb60-168" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/image-20240823145059675.png)</span></span>
<span id="cb60-169"><a href="#cb60-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-170"><a href="#cb60-170" aria-hidden="true" tabindex="-1"></a>Define your working directory in the Raspi and create a new Python 3 notebook.</span>
<span id="cb60-171"><a href="#cb60-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-172"><a href="#cb60-172" aria-hidden="true" tabindex="-1"></a><span class="fu">### Verifying the Setup</span></span>
<span id="cb60-173"><a href="#cb60-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-174"><a href="#cb60-174" aria-hidden="true" tabindex="-1"></a>Test your setup by running a simple Python script:</span>
<span id="cb60-175"><a href="#cb60-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-176"><a href="#cb60-176" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb60-177"><a href="#cb60-177" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb60-178"><a href="#cb60-178" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb60-179"><a href="#cb60-179" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb60-180"><a href="#cb60-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-181"><a href="#cb60-181" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NumPy:"</span>, np.__version__)</span>
<span id="cb60-182"><a href="#cb60-182" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pillow:"</span>, Image.__version__)</span>
<span id="cb60-183"><a href="#cb60-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-184"><a href="#cb60-184" aria-hidden="true" tabindex="-1"></a><span class="co"># Try to create a TFLite Interpreter</span></span>
<span id="cb60-185"><a href="#cb60-185" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/mobilenet_v2_1.0_224_quant.tflite"</span></span>
<span id="cb60-186"><a href="#cb60-186" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb60-187"><a href="#cb60-187" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb60-188"><a href="#cb60-188" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TFLite Interpreter created successfully!"</span>)</span>
<span id="cb60-189"><a href="#cb60-189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-190"><a href="#cb60-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-191"><a href="#cb60-191" aria-hidden="true" tabindex="-1"></a>You can create the Python script using nano on the terminal, saving it with <span class="in">`CTRL+0`</span> + <span class="in">`ENTER`</span> + <span class="in">`CTRL+X`</span></span>
<span id="cb60-192"><a href="#cb60-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-193"><a href="#cb60-193" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/nano.png)</span></span>
<span id="cb60-194"><a href="#cb60-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-195"><a href="#cb60-195" aria-hidden="true" tabindex="-1"></a>And run it with the command:</span>
<span id="cb60-196"><a href="#cb60-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-197"><a href="#cb60-197" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/test_result.png)</span></span>
<span id="cb60-198"><a href="#cb60-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-199"><a href="#cb60-199" aria-hidden="true" tabindex="-1"></a>Or you can run it directly on the <span class="co">[</span><span class="ot">Notebook</span><span class="co">](https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/setup_test.ipynb)</span>:</span>
<span id="cb60-200"><a href="#cb60-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-201"><a href="#cb60-201" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/notebook_test.png)</span></span>
<span id="cb60-202"><a href="#cb60-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-203"><a href="#cb60-203" aria-hidden="true" tabindex="-1"></a><span class="fu">## Making inferences with Mobilenet V2</span></span>
<span id="cb60-204"><a href="#cb60-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-205"><a href="#cb60-205" aria-hidden="true" tabindex="-1"></a>In the last section, we set up the environment, including downloading a popular pre-trained model, Mobilenet V2, trained on ImageNet's 224x224 images (1.2 million) for 1,001 classes (1,000 object categories plus 1 background). The model was converted to a compact 3.5MB TensorFlow Lite format, making it suitable for the limited storage and memory of a Raspberry Pi.</span>
<span id="cb60-206"><a href="#cb60-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-207"><a href="#cb60-207" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/mobilinet_zero.png)</span></span>
<span id="cb60-208"><a href="#cb60-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-209"><a href="#cb60-209" aria-hidden="true" tabindex="-1"></a>Let's start a new <span class="co">[</span><span class="ot">notebook</span><span class="co">](https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/10_Image_Classification.ipynb)</span> to follow all the steps to classify one image:</span>
<span id="cb60-210"><a href="#cb60-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-211"><a href="#cb60-211" aria-hidden="true" tabindex="-1"></a>Import the needed libraries:</span>
<span id="cb60-212"><a href="#cb60-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-213"><a href="#cb60-213" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb60-214"><a href="#cb60-214" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb60-215"><a href="#cb60-215" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb60-216"><a href="#cb60-216" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb60-217"><a href="#cb60-217" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb60-218"><a href="#cb60-218" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb60-219"><a href="#cb60-219" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-220"><a href="#cb60-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-221"><a href="#cb60-221" aria-hidden="true" tabindex="-1"></a>Load the TFLite model and allocate tensors:</span>
<span id="cb60-222"><a href="#cb60-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-223"><a href="#cb60-223" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb60-224"><a href="#cb60-224" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/mobilenet_v2_1.0_224_quant.tflite"</span></span>
<span id="cb60-225"><a href="#cb60-225" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb60-226"><a href="#cb60-226" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb60-227"><a href="#cb60-227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-228"><a href="#cb60-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-229"><a href="#cb60-229" aria-hidden="true" tabindex="-1"></a>Get input and output tensors.</span>
<span id="cb60-230"><a href="#cb60-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-231"><a href="#cb60-231" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb60-232"><a href="#cb60-232" aria-hidden="true" tabindex="-1"></a>input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb60-233"><a href="#cb60-233" aria-hidden="true" tabindex="-1"></a>output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb60-234"><a href="#cb60-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-235"><a href="#cb60-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-236"><a href="#cb60-236" aria-hidden="true" tabindex="-1"></a>**Input details** will give us information about how the model should be fed with an image. The shape of (1, 224, 224, 3) informs us that an image with dimensions (224x224x3) should be input one by one (Batch Dimension: 1). </span>
<span id="cb60-237"><a href="#cb60-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-238"><a href="#cb60-238" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/input_details.png)</span></span>
<span id="cb60-239"><a href="#cb60-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-240"><a href="#cb60-240" aria-hidden="true" tabindex="-1"></a>The **output details** show that the inference will result in an array of 1,001 integer values. Those values result from the image classification, where each value is the probability of that specific label being related to the image.</span>
<span id="cb60-241"><a href="#cb60-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-242"><a href="#cb60-242" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/output_details.png)</span></span>
<span id="cb60-243"><a href="#cb60-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-244"><a href="#cb60-244" aria-hidden="true" tabindex="-1"></a>Let's also inspect the dtype of input details of the model</span>
<span id="cb60-245"><a href="#cb60-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-246"><a href="#cb60-246" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb60-247"><a href="#cb60-247" aria-hidden="true" tabindex="-1"></a>input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb60-248"><a href="#cb60-248" aria-hidden="true" tabindex="-1"></a>input_dtype</span>
<span id="cb60-249"><a href="#cb60-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-250"><a href="#cb60-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-251"><a href="#cb60-251" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-252"><a href="#cb60-252" aria-hidden="true" tabindex="-1"></a><span class="in">dtype('uint8')</span></span>
<span id="cb60-253"><a href="#cb60-253" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-254"><a href="#cb60-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-255"><a href="#cb60-255" aria-hidden="true" tabindex="-1"></a>This shows that the input image should be raw pixels (0 - 255).</span>
<span id="cb60-256"><a href="#cb60-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-257"><a href="#cb60-257" aria-hidden="true" tabindex="-1"></a>Let's get a test image. You can transfer it from your computer or download one for testing. Let's first create a folder under our working directory:</span>
<span id="cb60-258"><a href="#cb60-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-259"><a href="#cb60-259" aria-hidden="true" tabindex="-1"></a><span class="in">```bash</span></span>
<span id="cb60-260"><a href="#cb60-260" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> images</span>
<span id="cb60-261"><a href="#cb60-261" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> images</span>
<span id="cb60-262"><a href="#cb60-262" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg</span>
<span id="cb60-263"><a href="#cb60-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-264"><a href="#cb60-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-265"><a href="#cb60-265" aria-hidden="true" tabindex="-1"></a>Let's load and display  the image:</span>
<span id="cb60-266"><a href="#cb60-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-267"><a href="#cb60-267" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb60-268"><a href="#cb60-268" aria-hidden="true" tabindex="-1"></a><span class="co"># Load he image</span></span>
<span id="cb60-269"><a href="#cb60-269" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"./images/Cat03.jpg"</span></span>
<span id="cb60-270"><a href="#cb60-270" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb60-271"><a href="#cb60-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-272"><a href="#cb60-272" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the image</span></span>
<span id="cb60-273"><a href="#cb60-273" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb60-274"><a href="#cb60-274" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb60-275"><a href="#cb60-275" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Original Image"</span>)</span>
<span id="cb60-276"><a href="#cb60-276" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb60-277"><a href="#cb60-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-278"><a href="#cb60-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-279"><a href="#cb60-279" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/cat_original.png)</span></span>
<span id="cb60-280"><a href="#cb60-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-281"><a href="#cb60-281" aria-hidden="true" tabindex="-1"></a>We can see the image size running the command:</span>
<span id="cb60-282"><a href="#cb60-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-283"><a href="#cb60-283" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb60-284"><a href="#cb60-284" aria-hidden="true" tabindex="-1"></a>width, height <span class="op">=</span> img.size</span>
<span id="cb60-285"><a href="#cb60-285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-286"><a href="#cb60-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-287"><a href="#cb60-287" aria-hidden="true" tabindex="-1"></a>That shows us that the image is an RGB image with a width of 1600 and a height of 1600 pixels. So, to use our model, we should reshape it to (224, 224, 3) and add a batch dimension of 1, as defined in input details: (1, 224, 224, 3). The inference result, as shown in output details, will be an array with a 1001 size, as shown below:</span>
<span id="cb60-288"><a href="#cb60-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-289"><a href="#cb60-289" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/png/process_img.png)</span></span>
<span id="cb60-290"><a href="#cb60-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-291"><a href="#cb60-291" aria-hidden="true" tabindex="-1"></a>So, let's reshape the image, add the batch dimension, and see the result:</span>
<span id="cb60-292"><a href="#cb60-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-293"><a href="#cb60-293" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb60-294"><a href="#cb60-294" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb60-295"><a href="#cb60-295" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span></span>
<span id="cb60-296"><a href="#cb60-296" aria-hidden="true" tabindex="-1"></a>input_data.shape</span>
<span id="cb60-297"><a href="#cb60-297" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-298"><a href="#cb60-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-299"><a href="#cb60-299" aria-hidden="true" tabindex="-1"></a>The input_data shape <span class="kw">is</span> <span class="im">as</span> expected: (<span class="dv">1</span>, <span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>)</span>
<span id="cb60-300"><a href="#cb60-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-301"><a href="#cb60-301" aria-hidden="true" tabindex="-1"></a>Let<span class="st">'s confirm the dtype of the input data:</span></span>
<span id="cb60-302"><a href="#cb60-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-303"><a href="#cb60-303" aria-hidden="true" tabindex="-1"></a><span class="er">```python</span></span>
<span id="cb60-304"><a href="#cb60-304" aria-hidden="true" tabindex="-1"></a>input_data.dtype</span>
<span id="cb60-305"><a href="#cb60-305" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-306"><a href="#cb60-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-307"><a href="#cb60-307" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-308"><a href="#cb60-308" aria-hidden="true" tabindex="-1"></a>dtype(<span class="st">'uint8'</span>)</span>
<span id="cb60-309"><a href="#cb60-309" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-310"><a href="#cb60-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-311"><a href="#cb60-311" aria-hidden="true" tabindex="-1"></a>The <span class="bu">input</span> data dtype <span class="kw">is</span> <span class="st">'uint8'</span>, which <span class="kw">is</span> compatible <span class="cf">with</span> the dtype expected <span class="cf">for</span> the model.</span>
<span id="cb60-312"><a href="#cb60-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-313"><a href="#cb60-313" aria-hidden="true" tabindex="-1"></a>Using the input_data, let<span class="st">'s run the interpreter and get the predictions (output):</span></span>
<span id="cb60-314"><a href="#cb60-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-315"><a href="#cb60-315" aria-hidden="true" tabindex="-1"></a><span class="er">```python</span></span>
<span id="cb60-316"><a href="#cb60-316" aria-hidden="true" tabindex="-1"></a>interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb60-317"><a href="#cb60-317" aria-hidden="true" tabindex="-1"></a>interpreter.invoke()</span>
<span id="cb60-318"><a href="#cb60-318" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb60-319"><a href="#cb60-319" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-320"><a href="#cb60-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-321"><a href="#cb60-321" aria-hidden="true" tabindex="-1"></a>The prediction <span class="kw">is</span> an array <span class="cf">with</span> <span class="dv">1001</span> elements. Let’s get the Top<span class="op">-</span><span class="dv">5</span> indices where their elements have high values:</span>
<span id="cb60-322"><a href="#cb60-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-323"><a href="#cb60-323" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-324"><a href="#cb60-324" aria-hidden="true" tabindex="-1"></a>top_k_results <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb60-325"><a href="#cb60-325" aria-hidden="true" tabindex="-1"></a>top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb60-326"><a href="#cb60-326" aria-hidden="true" tabindex="-1"></a>top_k_indices </span>
<span id="cb60-327"><a href="#cb60-327" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-328"><a href="#cb60-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-329"><a href="#cb60-329" aria-hidden="true" tabindex="-1"></a>The top_k_indices <span class="kw">is</span> an array <span class="cf">with</span> <span class="dv">5</span> elements: `array([<span class="dv">283</span>, <span class="dv">286</span>, <span class="dv">282</span>])`</span>
<span id="cb60-330"><a href="#cb60-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-331"><a href="#cb60-331" aria-hidden="true" tabindex="-1"></a>So, <span class="dv">283</span>, <span class="dv">286</span>, <span class="dv">282</span>, <span class="dv">288</span>, <span class="kw">and</span> <span class="dv">479</span> are the image<span class="st">'s most probable classes. Having the index, we must find to what class it appoints (such as car, cat, or dog). The text file downloaded with the model has a label associated with each index from 0 to 1,000. Let’s use a function to load the .txt file as a list:</span></span>
<span id="cb60-332"><a href="#cb60-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-333"><a href="#cb60-333" aria-hidden="true" tabindex="-1"></a><span class="er">```python</span></span>
<span id="cb60-334"><a href="#cb60-334" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_labels(filename):</span>
<span id="cb60-335"><a href="#cb60-335" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(filename, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb60-336"><a href="#cb60-336" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [line.strip() <span class="cf">for</span> line <span class="kw">in</span> f.readlines()]</span>
<span id="cb60-337"><a href="#cb60-337" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-338"><a href="#cb60-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-339"><a href="#cb60-339" aria-hidden="true" tabindex="-1"></a>And get the <span class="bu">list</span>, printing the labels associated <span class="cf">with</span> the indexes:</span>
<span id="cb60-340"><a href="#cb60-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-341"><a href="#cb60-341" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-342"><a href="#cb60-342" aria-hidden="true" tabindex="-1"></a>labels_path <span class="op">=</span> <span class="st">"./models/labels.txt"</span></span>
<span id="cb60-343"><a href="#cb60-343" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> load_labels(labels_path)</span>
<span id="cb60-344"><a href="#cb60-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-345"><a href="#cb60-345" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">286</span>])</span>
<span id="cb60-346"><a href="#cb60-346" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">283</span>])</span>
<span id="cb60-347"><a href="#cb60-347" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">282</span>])</span>
<span id="cb60-348"><a href="#cb60-348" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">288</span>])</span>
<span id="cb60-349"><a href="#cb60-349" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">479</span>])</span>
<span id="cb60-350"><a href="#cb60-350" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-351"><a href="#cb60-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-352"><a href="#cb60-352" aria-hidden="true" tabindex="-1"></a>As a result, we have:</span>
<span id="cb60-353"><a href="#cb60-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-354"><a href="#cb60-354" aria-hidden="true" tabindex="-1"></a>```bash</span>
<span id="cb60-355"><a href="#cb60-355" aria-hidden="true" tabindex="-1"></a>Egyptian cat</span>
<span id="cb60-356"><a href="#cb60-356" aria-hidden="true" tabindex="-1"></a>tiger cat</span>
<span id="cb60-357"><a href="#cb60-357" aria-hidden="true" tabindex="-1"></a>tabby</span>
<span id="cb60-358"><a href="#cb60-358" aria-hidden="true" tabindex="-1"></a>lynx</span>
<span id="cb60-359"><a href="#cb60-359" aria-hidden="true" tabindex="-1"></a>carton</span>
<span id="cb60-360"><a href="#cb60-360" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-361"><a href="#cb60-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-362"><a href="#cb60-362" aria-hidden="true" tabindex="-1"></a>At least the four top indices are related to felines. The <span class="op">**</span>prediction<span class="op">**</span> content <span class="kw">is</span> the probability associated <span class="cf">with</span> each one of the labels. As we saw on output details, those values are quantized <span class="kw">and</span> should be dequantized <span class="kw">and</span> <span class="bu">apply</span> softmax. </span>
<span id="cb60-363"><a href="#cb60-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-364"><a href="#cb60-364" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-365"><a href="#cb60-365" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb60-366"><a href="#cb60-366" aria-hidden="true" tabindex="-1"></a>dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb60-367"><a href="#cb60-367" aria-hidden="true" tabindex="-1"></a>exp_output <span class="op">=</span> np.exp(dequantized_output <span class="op">-</span> np.<span class="bu">max</span>(dequantized_output))</span>
<span id="cb60-368"><a href="#cb60-368" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> exp_output <span class="op">/</span> np.<span class="bu">sum</span>(exp_output)</span>
<span id="cb60-369"><a href="#cb60-369" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-370"><a href="#cb60-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-371"><a href="#cb60-371" aria-hidden="true" tabindex="-1"></a>Let<span class="st">'s print the top-5 probabilities:</span></span>
<span id="cb60-372"><a href="#cb60-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-373"><a href="#cb60-373" aria-hidden="true" tabindex="-1"></a><span class="er">```python</span></span>
<span id="cb60-374"><a href="#cb60-374" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">286</span>])</span>
<span id="cb60-375"><a href="#cb60-375" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">283</span>])</span>
<span id="cb60-376"><a href="#cb60-376" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">282</span>])</span>
<span id="cb60-377"><a href="#cb60-377" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">288</span>])</span>
<span id="cb60-378"><a href="#cb60-378" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">479</span>])</span>
<span id="cb60-379"><a href="#cb60-379" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-380"><a href="#cb60-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-381"><a href="#cb60-381" aria-hidden="true" tabindex="-1"></a>```bash</span>
<span id="cb60-382"><a href="#cb60-382" aria-hidden="true" tabindex="-1"></a><span class="fl">0.27741462</span></span>
<span id="cb60-383"><a href="#cb60-383" aria-hidden="true" tabindex="-1"></a><span class="fl">0.3732285</span></span>
<span id="cb60-384"><a href="#cb60-384" aria-hidden="true" tabindex="-1"></a><span class="fl">0.16919471</span></span>
<span id="cb60-385"><a href="#cb60-385" aria-hidden="true" tabindex="-1"></a><span class="fl">0.10319158</span></span>
<span id="cb60-386"><a href="#cb60-386" aria-hidden="true" tabindex="-1"></a><span class="fl">0.023410844</span></span>
<span id="cb60-387"><a href="#cb60-387" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-388"><a href="#cb60-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-389"><a href="#cb60-389" aria-hidden="true" tabindex="-1"></a>For clarity, let<span class="st">'s create a function to relate the labels with the probabilities:</span></span>
<span id="cb60-390"><a href="#cb60-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-391"><a href="#cb60-391" aria-hidden="true" tabindex="-1"></a><span class="er">```python</span></span>
<span id="cb60-392"><a href="#cb60-392" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb60-393"><a href="#cb60-393" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb60-394"><a href="#cb60-394" aria-hidden="true" tabindex="-1"></a>        labels[top_k_indices[i]],</span>
<span id="cb60-395"><a href="#cb60-395" aria-hidden="true" tabindex="-1"></a>        (<span class="bu">int</span>(probabilities[top_k_indices[i]]<span class="op">*</span><span class="dv">100</span>))))</span>
<span id="cb60-396"><a href="#cb60-396" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-397"><a href="#cb60-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-398"><a href="#cb60-398" aria-hidden="true" tabindex="-1"></a>```bash</span>
<span id="cb60-399"><a href="#cb60-399" aria-hidden="true" tabindex="-1"></a>tiger cat           : <span class="dv">37</span><span class="op">%</span></span>
<span id="cb60-400"><a href="#cb60-400" aria-hidden="true" tabindex="-1"></a>Egyptian cat        : <span class="dv">27</span><span class="op">%</span></span>
<span id="cb60-401"><a href="#cb60-401" aria-hidden="true" tabindex="-1"></a>tabby               : <span class="dv">16</span><span class="op">%</span></span>
<span id="cb60-402"><a href="#cb60-402" aria-hidden="true" tabindex="-1"></a>lynx                : <span class="dv">10</span><span class="op">%</span></span>
<span id="cb60-403"><a href="#cb60-403" aria-hidden="true" tabindex="-1"></a>carton              : <span class="dv">2</span><span class="op">%</span></span>
<span id="cb60-404"><a href="#cb60-404" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-405"><a href="#cb60-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-406"><a href="#cb60-406" aria-hidden="true" tabindex="-1"></a><span class="co">### Define a general Image Classification function</span></span>
<span id="cb60-407"><a href="#cb60-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-408"><a href="#cb60-408" aria-hidden="true" tabindex="-1"></a>Let<span class="st">'s create a general function to give an image as input, and we get the Top-5 possible classes:</span></span>
<span id="cb60-409"><a href="#cb60-409" aria-hidden="true" tabindex="-1"></a><span class="er">&lt;div class="scroll-code-block"&gt;</span></span>
<span id="cb60-410"><a href="#cb60-410" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-411"><a href="#cb60-411" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_classification(img_path, model_path, labels, top_k_results<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb60-412"><a href="#cb60-412" aria-hidden="true" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb60-413"><a href="#cb60-413" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb60-414"><a href="#cb60-414" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb60-415"><a href="#cb60-415" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)</span>
<span id="cb60-416"><a href="#cb60-416" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb60-417"><a href="#cb60-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-418"><a href="#cb60-418" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the TFLite model</span></span>
<span id="cb60-419"><a href="#cb60-419" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb60-420"><a href="#cb60-420" aria-hidden="true" tabindex="-1"></a>    interpreter.allocate_tensors()</span>
<span id="cb60-421"><a href="#cb60-421" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-422"><a href="#cb60-422" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get input and output tensors</span></span>
<span id="cb60-423"><a href="#cb60-423" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb60-424"><a href="#cb60-424" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb60-425"><a href="#cb60-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-426"><a href="#cb60-426" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess</span></span>
<span id="cb60-427"><a href="#cb60-427" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb60-428"><a href="#cb60-428" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb60-429"><a href="#cb60-429" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb60-430"><a href="#cb60-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-431"><a href="#cb60-431" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb60-432"><a href="#cb60-432" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb60-433"><a href="#cb60-433" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb60-434"><a href="#cb60-434" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-435"><a href="#cb60-435" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain results and map them to the classes</span></span>
<span id="cb60-436"><a href="#cb60-436" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb60-437"><a href="#cb60-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-438"><a href="#cb60-438" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of the top k results</span></span>
<span id="cb60-439"><a href="#cb60-439" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb60-440"><a href="#cb60-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-441"><a href="#cb60-441" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get quantization parameters</span></span>
<span id="cb60-442"><a href="#cb60-442" aria-hidden="true" tabindex="-1"></a>    scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb60-443"><a href="#cb60-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-444"><a href="#cb60-444" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dequantize the output and apply softmax</span></span>
<span id="cb60-445"><a href="#cb60-445" aria-hidden="true" tabindex="-1"></a>    dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb60-446"><a href="#cb60-446" aria-hidden="true" tabindex="-1"></a>    exp_output <span class="op">=</span> np.exp(dequantized_output <span class="op">-</span> np.<span class="bu">max</span>(dequantized_output))</span>
<span id="cb60-447"><a href="#cb60-447" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> exp_output <span class="op">/</span> np.<span class="bu">sum</span>(exp_output)</span>
<span id="cb60-448"><a href="#cb60-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-449"><a href="#cb60-449" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb60-450"><a href="#cb60-450" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb60-451"><a href="#cb60-451" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb60-452"><a href="#cb60-452" aria-hidden="true" tabindex="-1"></a>            labels[top_k_indices[i]],</span>
<span id="cb60-453"><a href="#cb60-453" aria-hidden="true" tabindex="-1"></a>            (<span class="bu">int</span>(probabilities[top_k_indices[i]]<span class="op">*</span><span class="dv">100</span>))))</span>
<span id="cb60-454"><a href="#cb60-454" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-455"><a href="#cb60-455" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;/</span>div<span class="op">&gt;</span></span>
<span id="cb60-456"><a href="#cb60-456" aria-hidden="true" tabindex="-1"></a>And loading some images <span class="cf">for</span> testing, we have:</span>
<span id="cb60-457"><a href="#cb60-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-458"><a href="#cb60-458" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>jpeg<span class="op">/</span>img_class_func.jpg)</span>
<span id="cb60-459"><a href="#cb60-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-460"><a href="#cb60-460" aria-hidden="true" tabindex="-1"></a><span class="co">### Testing with a model trained from scratch</span></span>
<span id="cb60-461"><a href="#cb60-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-462"><a href="#cb60-462" aria-hidden="true" tabindex="-1"></a>Let<span class="st">'s get a TFLite model trained from scratch. For that, you can follow the Notebook: </span></span>
<span id="cb60-463"><a href="#cb60-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-464"><a href="#cb60-464" aria-hidden="true" tabindex="-1"></a><span class="er">[CNN to classify Cifar-10 dataset](https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/2_Applications_Deploy/Class_16/cifar_10/CNN_Cifar_10_TFLite.ipynb#scrollTo=iiVBUpuHXEtw)</span></span>
<span id="cb60-465"><a href="#cb60-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-466"><a href="#cb60-466" aria-hidden="true" tabindex="-1"></a><span class="er"> In the notebook, we trained a model using the CIFAR10 dataset, which contains 60,000 images from 10 classes of CIFAR </span>(<span class="op">*</span>airplane, automobile, bird, cat, deer, dog, frog, horse, ship, <span class="kw">and</span> truck<span class="op">*</span>). CIFAR has <span class="dv">32</span><span class="er">x32</span> color images (<span class="dv">3</span> color channels) where the objects are <span class="kw">not</span> centered <span class="kw">and</span> can have the <span class="bu">object</span> <span class="cf">with</span> a background, such <span class="im">as</span> airplanes that might have a cloudy sky behind them<span class="op">!</span> In short, small but real images. </span>
<span id="cb60-467"><a href="#cb60-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-468"><a href="#cb60-468" aria-hidden="true" tabindex="-1"></a>The CNN trained model (<span class="op">*</span>cifar10_model.keras<span class="op">*</span>) had a size of <span class="fl">2.0</span><span class="er">MB</span>. Using the <span class="op">*</span>TFLite Converter<span class="op">*</span>, the model <span class="op">*</span>cifar10.tflite<span class="op">*</span> became <span class="cf">with</span> <span class="dv">674</span><span class="er">MB</span> (around <span class="dv">1</span><span class="op">/</span><span class="dv">3</span> of the original size). </span>
<span id="cb60-469"><a href="#cb60-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-470"><a href="#cb60-470" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>cifar10_model.png)</span>
<span id="cb60-471"><a href="#cb60-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-472"><a href="#cb60-472" aria-hidden="true" tabindex="-1"></a>On the notebook [Cifar <span class="dv">10</span> <span class="op">-</span> Image Classification on a Raspi <span class="cf">with</span> TFLite](https:<span class="op">//</span>github.com<span class="op">/</span>Mjrovai<span class="op">/</span>EdgeML<span class="op">-</span><span class="cf">with</span><span class="op">-</span>Raspberry<span class="op">-</span>Pi<span class="op">/</span>blob<span class="op">/</span>main<span class="op">/</span>IMG_CLASS<span class="op">/</span>notebooks<span class="op">/</span><span class="dv">20</span><span class="er">_Cifar_10_Image_Classification</span>.ipynb) (which can be run over the Raspi), we can follow the same steps we did <span class="cf">with</span> the `mobilenet_v2_1<span class="fl">.0_224</span><span class="er">_quant</span>.tflite`. Below are examples of images using the <span class="op">*</span>General Function <span class="cf">for</span> Image Classification<span class="op">*</span> on a Raspi<span class="op">-</span>Zero, <span class="im">as</span> shown <span class="kw">in</span> the last section.</span>
<span id="cb60-473"><a href="#cb60-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-474"><a href="#cb60-474" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>infer<span class="op">-</span>cifar10.png)</span>
<span id="cb60-475"><a href="#cb60-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-476"><a href="#cb60-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-477"><a href="#cb60-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-478"><a href="#cb60-478" aria-hidden="true" tabindex="-1"></a><span class="co">### Installing Picamera2</span></span>
<span id="cb60-479"><a href="#cb60-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-480"><a href="#cb60-480" aria-hidden="true" tabindex="-1"></a>[Picamera2](https:<span class="op">//</span>github.com<span class="op">/</span>raspberrypi<span class="op">/</span>picamera2), a Python library <span class="cf">for</span> interacting <span class="cf">with</span> Raspberry Pi’s camera, <span class="kw">is</span> based on the <span class="op">*</span>libcamera<span class="op">*</span> camera stack, <span class="kw">and</span> the Raspberry Pi foundation maintains it. The Picamera2 library <span class="kw">is</span> supported on <span class="bu">all</span> Raspberry Pi models, <span class="im">from</span> the Pi Zero to the RPi <span class="fl">5.</span> It <span class="kw">is</span> already installed system<span class="op">-</span>wide on the Raspi, but we should make it accessible within the virtual environment.</span>
<span id="cb60-481"><a href="#cb60-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-482"><a href="#cb60-482" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> First, activate the virtual environment <span class="cf">if</span> it<span class="st">'s not already activated:</span></span>
<span id="cb60-483"><a href="#cb60-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-484"><a href="#cb60-484" aria-hidden="true" tabindex="-1"></a><span class="er">    ```bash</span></span>
<span id="cb60-485"><a href="#cb60-485" aria-hidden="true" tabindex="-1"></a>    source <span class="op">~/</span>tflite<span class="op">/</span><span class="bu">bin</span><span class="op">/</span>activate</span>
<span id="cb60-486"><a href="#cb60-486" aria-hidden="true" tabindex="-1"></a>    ```</span>
<span id="cb60-487"><a href="#cb60-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-488"><a href="#cb60-488" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Now, let<span class="st">'s create a .pth file in your virtual environment to add the system site-packages path:</span></span>
<span id="cb60-489"><a href="#cb60-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-490"><a href="#cb60-490" aria-hidden="true" tabindex="-1"></a><span class="er">    ```bash</span></span>
<span id="cb60-491"><a href="#cb60-491" aria-hidden="true" tabindex="-1"></a>    echo <span class="st">"/usr/lib/python3/dist-packages"</span> <span class="op">&gt;</span> $VIRTUAL_ENV<span class="op">/</span>lib<span class="op">/</span>python3<span class="fl">.11</span><span class="op">/</span></span>
<span id="cb60-492"><a href="#cb60-492" aria-hidden="true" tabindex="-1"></a>    site<span class="op">-</span>packages<span class="op">/</span>system_site_packages.pth</span>
<span id="cb60-493"><a href="#cb60-493" aria-hidden="true" tabindex="-1"></a>    ```</span>
<span id="cb60-494"><a href="#cb60-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-495"><a href="#cb60-495" aria-hidden="true" tabindex="-1"></a>    <span class="op">&gt;</span> Note: If your Python version differs, replace  `python3<span class="fl">.11</span>` <span class="cf">with</span> the appropriate version.</span>
<span id="cb60-496"><a href="#cb60-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-497"><a href="#cb60-497" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> After creating this <span class="bu">file</span>, <span class="cf">try</span> importing picamera2 <span class="kw">in</span> Python:</span>
<span id="cb60-498"><a href="#cb60-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-499"><a href="#cb60-499" aria-hidden="true" tabindex="-1"></a>    ```bash</span>
<span id="cb60-500"><a href="#cb60-500" aria-hidden="true" tabindex="-1"></a>    python3</span>
<span id="cb60-501"><a href="#cb60-501" aria-hidden="true" tabindex="-1"></a>    <span class="op">&gt;&gt;&gt;</span> <span class="im">import</span> picamera2</span>
<span id="cb60-502"><a href="#cb60-502" aria-hidden="true" tabindex="-1"></a>    <span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(picamera2.<span class="va">__file__</span>)</span>
<span id="cb60-503"><a href="#cb60-503" aria-hidden="true" tabindex="-1"></a>    ```</span>
<span id="cb60-504"><a href="#cb60-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-505"><a href="#cb60-505" aria-hidden="true" tabindex="-1"></a>The above code will show the <span class="bu">file</span> location of the `picamera2` module itself, proving that the library can be accessed <span class="im">from</span> the environment. </span>
<span id="cb60-506"><a href="#cb60-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-507"><a href="#cb60-507" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-508"><a href="#cb60-508" aria-hidden="true" tabindex="-1"></a><span class="op">/</span>home<span class="op">/</span>mjrovai<span class="op">/</span>tflite<span class="op">/</span>lib<span class="op">/</span>python3<span class="fl">.11</span><span class="op">/</span>site<span class="op">-</span>packages<span class="op">/</span>picamera2<span class="op">/</span><span class="fu">__init__</span>.py</span>
<span id="cb60-509"><a href="#cb60-509" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-510"><a href="#cb60-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-511"><a href="#cb60-511" aria-hidden="true" tabindex="-1"></a>You can also <span class="bu">list</span> the available cameras <span class="kw">in</span> the system:</span>
<span id="cb60-512"><a href="#cb60-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-513"><a href="#cb60-513" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-514"><a href="#cb60-514" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(Picamera2.global_camera_info())</span>
<span id="cb60-515"><a href="#cb60-515" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-516"><a href="#cb60-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-517"><a href="#cb60-517" aria-hidden="true" tabindex="-1"></a>In my case, <span class="cf">with</span> a USB installed, I got:</span>
<span id="cb60-518"><a href="#cb60-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-519"><a href="#cb60-519" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>cam_installed.png)</span>
<span id="cb60-520"><a href="#cb60-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-521"><a href="#cb60-521" aria-hidden="true" tabindex="-1"></a>Now that we<span class="st">'ve confirmed picamera2 is working in the environment with an `index 0`,  let'</span>s <span class="cf">try</span> a simple Python script to capture an image <span class="im">from</span> your USB camera:</span>
<span id="cb60-522"><a href="#cb60-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-523"><a href="#cb60-523" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-524"><a href="#cb60-524" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb60-525"><a href="#cb60-525" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb60-526"><a href="#cb60-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-527"><a href="#cb60-527" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the camera</span></span>
<span id="cb60-528"><a href="#cb60-528" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> Picamera2() <span class="co"># default is index 0</span></span>
<span id="cb60-529"><a href="#cb60-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-530"><a href="#cb60-530" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure the camera</span></span>
<span id="cb60-531"><a href="#cb60-531" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> picam2.create_still_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">640</span>, <span class="dv">480</span>)})</span>
<span id="cb60-532"><a href="#cb60-532" aria-hidden="true" tabindex="-1"></a>picam2.configure(config)</span>
<span id="cb60-533"><a href="#cb60-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-534"><a href="#cb60-534" aria-hidden="true" tabindex="-1"></a><span class="co"># Start the camera</span></span>
<span id="cb60-535"><a href="#cb60-535" aria-hidden="true" tabindex="-1"></a>picam2.start()</span>
<span id="cb60-536"><a href="#cb60-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-537"><a href="#cb60-537" aria-hidden="true" tabindex="-1"></a><span class="co"># Wait for the camera to warm up</span></span>
<span id="cb60-538"><a href="#cb60-538" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">2</span>)</span>
<span id="cb60-539"><a href="#cb60-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-540"><a href="#cb60-540" aria-hidden="true" tabindex="-1"></a><span class="co"># Capture an image</span></span>
<span id="cb60-541"><a href="#cb60-541" aria-hidden="true" tabindex="-1"></a>picam2.capture_file(<span class="st">"usb_camera_image.jpg"</span>)</span>
<span id="cb60-542"><a href="#cb60-542" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Image captured and saved as 'usb_camera_image.jpg'"</span>)</span>
<span id="cb60-543"><a href="#cb60-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-544"><a href="#cb60-544" aria-hidden="true" tabindex="-1"></a><span class="co"># Stop the camera</span></span>
<span id="cb60-545"><a href="#cb60-545" aria-hidden="true" tabindex="-1"></a>picam2.stop()</span>
<span id="cb60-546"><a href="#cb60-546" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-547"><a href="#cb60-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-548"><a href="#cb60-548" aria-hidden="true" tabindex="-1"></a>Use the Nano text editor, the Jupyter Notebook, <span class="kw">or</span> <span class="bu">any</span> other editor. Save this <span class="im">as</span> a Python script (e.g., `capture_image.py`) <span class="kw">and</span> run it. This should capture an image <span class="im">from</span> your camera <span class="kw">and</span> save it <span class="im">as</span> <span class="st">"usb_camera_image.jpg"</span> <span class="kw">in</span> the same directory <span class="im">as</span> your script.</span>
<span id="cb60-549"><a href="#cb60-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-550"><a href="#cb60-550" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>capture_test.png)</span>
<span id="cb60-551"><a href="#cb60-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-552"><a href="#cb60-552" aria-hidden="true" tabindex="-1"></a>If the Jupyter <span class="kw">is</span> <span class="bu">open</span>, you can see the captured image on your computer. Otherwise, transfer the <span class="bu">file</span> <span class="im">from</span> the Raspi to your computer.  </span>
<span id="cb60-553"><a href="#cb60-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-554"><a href="#cb60-554" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>img_test_result.png)</span>
<span id="cb60-555"><a href="#cb60-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-556"><a href="#cb60-556" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> If you are working <span class="cf">with</span> a Raspi<span class="op">-</span><span class="dv">5</span> <span class="cf">with</span> a whole desktop, you can <span class="bu">open</span> the <span class="bu">file</span> directly on the device. </span>
<span id="cb60-557"><a href="#cb60-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-558"><a href="#cb60-558" aria-hidden="true" tabindex="-1"></a><span class="co">## Image Classification Project</span></span>
<span id="cb60-559"><a href="#cb60-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-560"><a href="#cb60-560" aria-hidden="true" tabindex="-1"></a>Now, we will develop a complete Image Classification project using the Edge Impulse Studio. As we did <span class="cf">with</span> the Movilinet V2, the trained <span class="kw">and</span> converted TFLite model will be used <span class="cf">for</span> inference. </span>
<span id="cb60-561"><a href="#cb60-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-562"><a href="#cb60-562" aria-hidden="true" tabindex="-1"></a><span class="co">### The Goal</span></span>
<span id="cb60-563"><a href="#cb60-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-564"><a href="#cb60-564" aria-hidden="true" tabindex="-1"></a>The first step <span class="kw">in</span> <span class="bu">any</span> ML project <span class="kw">is</span> to define its goal. In this case, it <span class="kw">is</span> to detect <span class="kw">and</span> classify two specific objects present <span class="kw">in</span> one image. For this project, we will use two small toys: a robot <span class="kw">and</span> a small Brazilian parrot (named Periquito). We will also collect images of a <span class="op">*</span>background<span class="op">*</span> where those two objects are absent.</span>
<span id="cb60-565"><a href="#cb60-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-566"><a href="#cb60-566" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>jpeg<span class="op">/</span>project_goal.jpg)</span>
<span id="cb60-567"><a href="#cb60-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-568"><a href="#cb60-568" aria-hidden="true" tabindex="-1"></a><span class="co">### Data Collection</span></span>
<span id="cb60-569"><a href="#cb60-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-570"><a href="#cb60-570" aria-hidden="true" tabindex="-1"></a>Once we have defined our Machine Learning project goal, the <span class="bu">next</span> <span class="kw">and</span> most crucial step <span class="kw">is</span> collecting the dataset. We can use a phone <span class="cf">for</span> the image capture, but we will use the Raspi here. Let<span class="st">'s set up a simple web server on our Raspberry Pi to view the `QVGA (320 x 240)` captured images in a browser. </span></span>
<span id="cb60-571"><a href="#cb60-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-572"><a href="#cb60-572" aria-hidden="true" tabindex="-1"></a><span class="er">1. First, let's install Flask, a lightweight web framework for Python:</span></span>
<span id="cb60-573"><a href="#cb60-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-574"><a href="#cb60-574" aria-hidden="true" tabindex="-1"></a>    ```bash</span>
<span id="cb60-575"><a href="#cb60-575" aria-hidden="true" tabindex="-1"></a>    pip3 install flask</span>
<span id="cb60-576"><a href="#cb60-576" aria-hidden="true" tabindex="-1"></a>    ```</span>
<span id="cb60-577"><a href="#cb60-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-578"><a href="#cb60-578" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Let<span class="st">'s create a new Python script combining image capture with a web server.  We'</span>ll call it `get_img_data.py`:</span>
<span id="cb60-579"><a href="#cb60-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-580"><a href="#cb60-580" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>div <span class="kw">class</span><span class="op">=</span><span class="st">"scroll-code-block"</span><span class="op">&gt;</span></span>
<span id="cb60-581"><a href="#cb60-581" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-582"><a href="#cb60-582" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask, Response, render_template_string, request, redirect, url_for</span>
<span id="cb60-583"><a href="#cb60-583" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb60-584"><a href="#cb60-584" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb60-585"><a href="#cb60-585" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb60-586"><a href="#cb60-586" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb60-587"><a href="#cb60-587" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb60-588"><a href="#cb60-588" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> signal</span>
<span id="cb60-589"><a href="#cb60-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-590"><a href="#cb60-590" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> Flask(<span class="va">__name__</span>)</span>
<span id="cb60-591"><a href="#cb60-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-592"><a href="#cb60-592" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb60-593"><a href="#cb60-593" aria-hidden="true" tabindex="-1"></a>base_dir <span class="op">=</span> <span class="st">"dataset"</span></span>
<span id="cb60-594"><a href="#cb60-594" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb60-595"><a href="#cb60-595" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> <span class="va">None</span></span>
<span id="cb60-596"><a href="#cb60-596" aria-hidden="true" tabindex="-1"></a>frame_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb60-597"><a href="#cb60-597" aria-hidden="true" tabindex="-1"></a>capture_counts <span class="op">=</span> {}</span>
<span id="cb60-598"><a href="#cb60-598" aria-hidden="true" tabindex="-1"></a>current_label <span class="op">=</span> <span class="va">None</span></span>
<span id="cb60-599"><a href="#cb60-599" aria-hidden="true" tabindex="-1"></a>shutdown_event <span class="op">=</span> threading.Event()</span>
<span id="cb60-600"><a href="#cb60-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-601"><a href="#cb60-601" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_camera():</span>
<span id="cb60-602"><a href="#cb60-602" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> picam2</span>
<span id="cb60-603"><a href="#cb60-603" aria-hidden="true" tabindex="-1"></a>    picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb60-604"><a href="#cb60-604" aria-hidden="true" tabindex="-1"></a>    config <span class="op">=</span> picam2.create_preview_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">320</span>, <span class="dv">240</span>)})</span>
<span id="cb60-605"><a href="#cb60-605" aria-hidden="true" tabindex="-1"></a>    picam2.configure(config)</span>
<span id="cb60-606"><a href="#cb60-606" aria-hidden="true" tabindex="-1"></a>    picam2.start()</span>
<span id="cb60-607"><a href="#cb60-607" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Wait for camera to warm up</span></span>
<span id="cb60-608"><a href="#cb60-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-609"><a href="#cb60-609" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_frame():</span>
<span id="cb60-610"><a href="#cb60-610" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> frame</span>
<span id="cb60-611"><a href="#cb60-611" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb60-612"><a href="#cb60-612" aria-hidden="true" tabindex="-1"></a>        stream <span class="op">=</span> io.BytesIO()</span>
<span id="cb60-613"><a href="#cb60-613" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(stream, <span class="bu">format</span><span class="op">=</span><span class="st">'jpeg'</span>)</span>
<span id="cb60-614"><a href="#cb60-614" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb60-615"><a href="#cb60-615" aria-hidden="true" tabindex="-1"></a>            frame <span class="op">=</span> stream.getvalue()</span>
<span id="cb60-616"><a href="#cb60-616" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust as needed for smooth preview</span></span>
<span id="cb60-617"><a href="#cb60-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-618"><a href="#cb60-618" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_frames():</span>
<span id="cb60-619"><a href="#cb60-619" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb60-620"><a href="#cb60-620" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb60-621"><a href="#cb60-621" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb60-622"><a href="#cb60-622" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (<span class="st">b'--frame</span><span class="ch">\r\n</span><span class="st">'</span></span>
<span id="cb60-623"><a href="#cb60-623" aria-hidden="true" tabindex="-1"></a>                       <span class="st">b'Content-Type: image/jpeg</span><span class="ch">\r\n\r\n</span><span class="st">'</span> <span class="op">+</span> frame <span class="op">+</span> <span class="st">b'</span><span class="ch">\r\n</span><span class="st">'</span>)</span>
<span id="cb60-624"><a href="#cb60-624" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust as needed for smooth streaming</span></span>
<span id="cb60-625"><a href="#cb60-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-626"><a href="#cb60-626" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> shutdown_server():</span>
<span id="cb60-627"><a href="#cb60-627" aria-hidden="true" tabindex="-1"></a>    shutdown_event.<span class="bu">set</span>()</span>
<span id="cb60-628"><a href="#cb60-628" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> picam2:</span>
<span id="cb60-629"><a href="#cb60-629" aria-hidden="true" tabindex="-1"></a>        picam2.stop()</span>
<span id="cb60-630"><a href="#cb60-630" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Give some time for other threads to finish</span></span>
<span id="cb60-631"><a href="#cb60-631" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)</span>
<span id="cb60-632"><a href="#cb60-632" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Send SIGINT to the main process</span></span>
<span id="cb60-633"><a href="#cb60-633" aria-hidden="true" tabindex="-1"></a>    os.kill(os.getpid(), signal.SIGINT)</span>
<span id="cb60-634"><a href="#cb60-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-635"><a href="#cb60-635" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/'</span>, methods<span class="op">=</span>[<span class="st">'GET'</span>, <span class="st">'POST'</span>])</span>
<span id="cb60-636"><a href="#cb60-636" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> index():</span>
<span id="cb60-637"><a href="#cb60-637" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> current_label</span>
<span id="cb60-638"><a href="#cb60-638" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> request.method <span class="op">==</span> <span class="st">'POST'</span>:</span>
<span id="cb60-639"><a href="#cb60-639" aria-hidden="true" tabindex="-1"></a>        current_label <span class="op">=</span> request.form[<span class="st">'label'</span>]</span>
<span id="cb60-640"><a href="#cb60-640" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_label <span class="kw">not</span> <span class="kw">in</span> capture_counts:</span>
<span id="cb60-641"><a href="#cb60-641" aria-hidden="true" tabindex="-1"></a>            capture_counts[current_label] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb60-642"><a href="#cb60-642" aria-hidden="true" tabindex="-1"></a>        os.makedirs(os.path.join(base_dir, current_label), exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-643"><a href="#cb60-643" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> redirect(url_for(<span class="st">'capture_page'</span>))</span>
<span id="cb60-644"><a href="#cb60-644" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb60-645"><a href="#cb60-645" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb60-646"><a href="#cb60-646" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb60-647"><a href="#cb60-647" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb60-648"><a href="#cb60-648" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture - Label Entry&lt;/title&gt;</span></span>
<span id="cb60-649"><a href="#cb60-649" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb60-650"><a href="#cb60-650" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb60-651"><a href="#cb60-651" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Enter Label for Dataset&lt;/h1&gt;</span></span>
<span id="cb60-652"><a href="#cb60-652" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form method="post"&gt;</span></span>
<span id="cb60-653"><a href="#cb60-653" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="text" name="label" required&gt;</span></span>
<span id="cb60-654"><a href="#cb60-654" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Start Capture"&gt;</span></span>
<span id="cb60-655"><a href="#cb60-655" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb60-656"><a href="#cb60-656" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb60-657"><a href="#cb60-657" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb60-658"><a href="#cb60-658" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>)</span>
<span id="cb60-659"><a href="#cb60-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-660"><a href="#cb60-660" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/capture'</span>)</span>
<span id="cb60-661"><a href="#cb60-661" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> capture_page():</span>
<span id="cb60-662"><a href="#cb60-662" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb60-663"><a href="#cb60-663" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb60-664"><a href="#cb60-664" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb60-665"><a href="#cb60-665" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb60-666"><a href="#cb60-666" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture&lt;/title&gt;</span></span>
<span id="cb60-667"><a href="#cb60-667" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script&gt;</span></span>
<span id="cb60-668"><a href="#cb60-668" aria-hidden="true" tabindex="-1"></a><span class="st">                var shutdownInitiated = false;</span></span>
<span id="cb60-669"><a href="#cb60-669" aria-hidden="true" tabindex="-1"></a><span class="st">                function checkShutdown() {</span></span>
<span id="cb60-670"><a href="#cb60-670" aria-hidden="true" tabindex="-1"></a><span class="st">                    if (!shutdownInitiated) {</span></span>
<span id="cb60-671"><a href="#cb60-671" aria-hidden="true" tabindex="-1"></a><span class="st">                        fetch('/check_shutdown')</span></span>
<span id="cb60-672"><a href="#cb60-672" aria-hidden="true" tabindex="-1"></a><span class="st">                            .then(response =&gt; response.json())</span></span>
<span id="cb60-673"><a href="#cb60-673" aria-hidden="true" tabindex="-1"></a><span class="st">                            .then(data =&gt; {</span></span>
<span id="cb60-674"><a href="#cb60-674" aria-hidden="true" tabindex="-1"></a><span class="st">                                if (data.shutdown) {</span></span>
<span id="cb60-675"><a href="#cb60-675" aria-hidden="true" tabindex="-1"></a><span class="st">                                    shutdownInitiated = true;</span></span>
<span id="cb60-676"><a href="#cb60-676" aria-hidden="true" tabindex="-1"></a><span class="st">                                    document.getElementById('video-feed').src = '';</span></span>
<span id="cb60-677"><a href="#cb60-677" aria-hidden="true" tabindex="-1"></a><span class="st">                                    document.getElementById('shutdown-message')</span></span>
<span id="cb60-678"><a href="#cb60-678" aria-hidden="true" tabindex="-1"></a><span class="st">                                    .style.display = 'block';</span></span>
<span id="cb60-679"><a href="#cb60-679" aria-hidden="true" tabindex="-1"></a><span class="st">                                }</span></span>
<span id="cb60-680"><a href="#cb60-680" aria-hidden="true" tabindex="-1"></a><span class="st">                            });</span></span>
<span id="cb60-681"><a href="#cb60-681" aria-hidden="true" tabindex="-1"></a><span class="st">                    }</span></span>
<span id="cb60-682"><a href="#cb60-682" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb60-683"><a href="#cb60-683" aria-hidden="true" tabindex="-1"></a><span class="st">                setInterval(checkShutdown, 1000);  // Check every second</span></span>
<span id="cb60-684"><a href="#cb60-684" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb60-685"><a href="#cb60-685" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb60-686"><a href="#cb60-686" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb60-687"><a href="#cb60-687" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Dataset Capture&lt;/h1&gt;</span></span>
<span id="cb60-688"><a href="#cb60-688" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Current Label: </span><span class="sc">{{</span><span class="st"> label </span><span class="sc">}}</span><span class="st">&lt;/p&gt;</span></span>
<span id="cb60-689"><a href="#cb60-689" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Images captured for this label: </span><span class="sc">{{</span><span class="st"> capture_count </span><span class="sc">}}</span><span class="st">&lt;/p&gt;</span></span>
<span id="cb60-690"><a href="#cb60-690" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;img id="video-feed" src="</span><span class="sc">{{</span><span class="st"> url_for('video_feed') </span><span class="sc">}}</span><span class="st">" width="640" </span></span>
<span id="cb60-691"><a href="#cb60-691" aria-hidden="true" tabindex="-1"></a><span class="st">            height="480" /&gt;</span></span>
<span id="cb60-692"><a href="#cb60-692" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;div id="shutdown-message" style="display: none; color: red;"&gt;</span></span>
<span id="cb60-693"><a href="#cb60-693" aria-hidden="true" tabindex="-1"></a><span class="st">                Capture process has been stopped. You can close this window.</span></span>
<span id="cb60-694"><a href="#cb60-694" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/div&gt;</span></span>
<span id="cb60-695"><a href="#cb60-695" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/capture_image" method="post"&gt;</span></span>
<span id="cb60-696"><a href="#cb60-696" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Capture Image"&gt;</span></span>
<span id="cb60-697"><a href="#cb60-697" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb60-698"><a href="#cb60-698" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/stop" method="post"&gt;</span></span>
<span id="cb60-699"><a href="#cb60-699" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Stop Capture" </span></span>
<span id="cb60-700"><a href="#cb60-700" aria-hidden="true" tabindex="-1"></a><span class="st">                style="background-color: #ff6666;"&gt;</span></span>
<span id="cb60-701"><a href="#cb60-701" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb60-702"><a href="#cb60-702" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/" method="get"&gt;</span></span>
<span id="cb60-703"><a href="#cb60-703" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Change Label" </span></span>
<span id="cb60-704"><a href="#cb60-704" aria-hidden="true" tabindex="-1"></a><span class="st">                style="background-color: #ffff66;"&gt;</span></span>
<span id="cb60-705"><a href="#cb60-705" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb60-706"><a href="#cb60-706" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb60-707"><a href="#cb60-707" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb60-708"><a href="#cb60-708" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>, label<span class="op">=</span>current_label, capture_count<span class="op">=</span>capture_counts.get(current_label, <span class="dv">0</span>))</span>
<span id="cb60-709"><a href="#cb60-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-710"><a href="#cb60-710" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/video_feed'</span>)</span>
<span id="cb60-711"><a href="#cb60-711" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> video_feed():</span>
<span id="cb60-712"><a href="#cb60-712" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Response(generate_frames(),</span>
<span id="cb60-713"><a href="#cb60-713" aria-hidden="true" tabindex="-1"></a>                    mimetype<span class="op">=</span><span class="st">'multipart/x-mixed-replace; boundary=frame'</span>)</span>
<span id="cb60-714"><a href="#cb60-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-715"><a href="#cb60-715" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/capture_image'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb60-716"><a href="#cb60-716" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> capture_image():</span>
<span id="cb60-717"><a href="#cb60-717" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> capture_counts</span>
<span id="cb60-718"><a href="#cb60-718" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_label <span class="kw">and</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb60-719"><a href="#cb60-719" aria-hidden="true" tabindex="-1"></a>        capture_counts[current_label] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb60-720"><a href="#cb60-720" aria-hidden="true" tabindex="-1"></a>        timestamp <span class="op">=</span> time.strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">-%H%M%S"</span>)</span>
<span id="cb60-721"><a href="#cb60-721" aria-hidden="true" tabindex="-1"></a>        filename <span class="op">=</span> <span class="ss">f"image_</span><span class="sc">{</span>timestamp<span class="sc">}</span><span class="ss">.jpg"</span></span>
<span id="cb60-722"><a href="#cb60-722" aria-hidden="true" tabindex="-1"></a>        full_path <span class="op">=</span> os.path.join(base_dir, current_label, filename)</span>
<span id="cb60-723"><a href="#cb60-723" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb60-724"><a href="#cb60-724" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(full_path)</span>
<span id="cb60-725"><a href="#cb60-725" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-726"><a href="#cb60-726" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> redirect(url_for(<span class="st">'capture_page'</span>))</span>
<span id="cb60-727"><a href="#cb60-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-728"><a href="#cb60-728" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/stop'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb60-729"><a href="#cb60-729" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stop():</span>
<span id="cb60-730"><a href="#cb60-730" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> render_template_string(<span class="st">'''</span></span>
<span id="cb60-731"><a href="#cb60-731" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb60-732"><a href="#cb60-732" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb60-733"><a href="#cb60-733" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb60-734"><a href="#cb60-734" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture - Stopped&lt;/title&gt;</span></span>
<span id="cb60-735"><a href="#cb60-735" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb60-736"><a href="#cb60-736" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb60-737"><a href="#cb60-737" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Dataset Capture Stopped&lt;/h1&gt;</span></span>
<span id="cb60-738"><a href="#cb60-738" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;The capture process has been stopped. You can close this window.&lt;/p&gt;</span></span>
<span id="cb60-739"><a href="#cb60-739" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Summary of captures:&lt;/p&gt;</span></span>
<span id="cb60-740"><a href="#cb60-740" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;ul&gt;</span></span>
<span id="cb60-741"><a href="#cb60-741" aria-hidden="true" tabindex="-1"></a><span class="st">            {</span><span class="sc">% f</span><span class="st">or label, count in capture_counts.items() %}</span></span>
<span id="cb60-742"><a href="#cb60-742" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;li&gt;</span><span class="sc">{{</span><span class="st"> label </span><span class="sc">}}</span><span class="st">: </span><span class="sc">{{</span><span class="st"> count </span><span class="sc">}}</span><span class="st"> images&lt;/li&gt;</span></span>
<span id="cb60-743"><a href="#cb60-743" aria-hidden="true" tabindex="-1"></a><span class="st">            {</span><span class="sc">% e</span><span class="st">ndfor %}</span></span>
<span id="cb60-744"><a href="#cb60-744" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/ul&gt;</span></span>
<span id="cb60-745"><a href="#cb60-745" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb60-746"><a href="#cb60-746" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb60-747"><a href="#cb60-747" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>, capture_counts<span class="op">=</span>capture_counts)</span>
<span id="cb60-748"><a href="#cb60-748" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-749"><a href="#cb60-749" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start a new thread to shutdown the server</span></span>
<span id="cb60-750"><a href="#cb60-750" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>shutdown_server).start()</span>
<span id="cb60-751"><a href="#cb60-751" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-752"><a href="#cb60-752" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> summary</span>
<span id="cb60-753"><a href="#cb60-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-754"><a href="#cb60-754" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/check_shutdown'</span>)</span>
<span id="cb60-755"><a href="#cb60-755" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_shutdown():</span>
<span id="cb60-756"><a href="#cb60-756" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'shutdown'</span>: shutdown_event.is_set()}</span>
<span id="cb60-757"><a href="#cb60-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-758"><a href="#cb60-758" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb60-759"><a href="#cb60-759" aria-hidden="true" tabindex="-1"></a>    initialize_camera()</span>
<span id="cb60-760"><a href="#cb60-760" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>get_frame, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb60-761"><a href="#cb60-761" aria-hidden="true" tabindex="-1"></a>    app.run(host<span class="op">=</span><span class="st">'0.0.0.0'</span>, port<span class="op">=</span><span class="dv">5000</span>, threaded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-762"><a href="#cb60-762" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-763"><a href="#cb60-763" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;/</span>div<span class="op">&gt;</span></span>
<span id="cb60-764"><a href="#cb60-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-765"><a href="#cb60-765" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> Run this script:</span>
<span id="cb60-766"><a href="#cb60-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-767"><a href="#cb60-767" aria-hidden="true" tabindex="-1"></a>    ```bash</span>
<span id="cb60-768"><a href="#cb60-768" aria-hidden="true" tabindex="-1"></a>    python3 get_img_data.py</span>
<span id="cb60-769"><a href="#cb60-769" aria-hidden="true" tabindex="-1"></a>    ```</span>
<span id="cb60-770"><a href="#cb60-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-771"><a href="#cb60-771" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Access the web interface:</span>
<span id="cb60-772"><a href="#cb60-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-773"><a href="#cb60-773" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> On the Raspberry Pi itself (<span class="cf">if</span> you have a GUI): Open a web browser <span class="kw">and</span> go to `http:<span class="op">//</span>localhost:<span class="dv">5000</span>`</span>
<span id="cb60-774"><a href="#cb60-774" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> From another device on the same network: Open a web browser <span class="kw">and</span> go to `http:<span class="op">//&lt;</span>raspberry_pi_ip<span class="op">&gt;</span>:<span class="dv">5000</span>` (Replace `<span class="op">&lt;</span>raspberry_pi_ip<span class="op">&gt;</span>` <span class="cf">with</span> your Raspberry Pi<span class="st">'s IP address). For example: `http://192.168.4.210:5000/`</span></span>
<span id="cb60-775"><a href="#cb60-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-776"><a href="#cb60-776" aria-hidden="true" tabindex="-1"></a><span class="er">This Python script creates a web-based interface for capturing and organizing image datasets using a Raspberry Pi and its camera. It's handy for machine learning projects that require labeled image data.</span></span>
<span id="cb60-777"><a href="#cb60-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-778"><a href="#cb60-778" aria-hidden="true" tabindex="-1"></a><span class="co">#### Key Features:</span></span>
<span id="cb60-779"><a href="#cb60-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-780"><a href="#cb60-780" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> <span class="op">**</span>Web Interface<span class="op">**</span>: Accessible <span class="im">from</span> <span class="bu">any</span> device on the same network <span class="im">as</span> the Raspberry Pi.</span>
<span id="cb60-781"><a href="#cb60-781" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> <span class="op">**</span>Live Camera Preview<span class="op">**</span>: This shows a real<span class="op">-</span>time feed <span class="im">from</span> the camera.</span>
<span id="cb60-782"><a href="#cb60-782" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> <span class="op">**</span>Labeling System<span class="op">**</span>: Allows users to <span class="bu">input</span> labels <span class="cf">for</span> different categories of images.</span>
<span id="cb60-783"><a href="#cb60-783" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> <span class="op">**</span>Organized Storage<span class="op">**</span>: Automatically saves images <span class="kw">in</span> label<span class="op">-</span>specific subdirectories.</span>
<span id="cb60-784"><a href="#cb60-784" aria-hidden="true" tabindex="-1"></a><span class="fl">5.</span> <span class="op">**</span>Per<span class="op">-</span>Label Counters<span class="op">**</span>: Keeps track of how many images are captured <span class="cf">for</span> each label.</span>
<span id="cb60-785"><a href="#cb60-785" aria-hidden="true" tabindex="-1"></a><span class="fl">6.</span> <span class="op">**</span>Summary Statistics<span class="op">**</span>: Provides a summary of captured images when stopping the capture process.</span>
<span id="cb60-786"><a href="#cb60-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-787"><a href="#cb60-787" aria-hidden="true" tabindex="-1"></a><span class="co">#### Main Components:</span></span>
<span id="cb60-788"><a href="#cb60-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-789"><a href="#cb60-789" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> <span class="op">**</span>Flask Web Application<span class="op">**</span>: Handles routing <span class="kw">and</span> serves the web interface.</span>
<span id="cb60-790"><a href="#cb60-790" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> <span class="op">**</span>Picamera2 Integration<span class="op">**</span>: Controls the Raspberry Pi camera.</span>
<span id="cb60-791"><a href="#cb60-791" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> <span class="op">**</span>Threaded Frame Capture<span class="op">**</span>: Ensures smooth live preview.</span>
<span id="cb60-792"><a href="#cb60-792" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> <span class="op">**</span>File Management<span class="op">**</span>: Organizes captured images into labeled directories.</span>
<span id="cb60-793"><a href="#cb60-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-794"><a href="#cb60-794" aria-hidden="true" tabindex="-1"></a><span class="co">#### Key Functions:</span></span>
<span id="cb60-795"><a href="#cb60-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-796"><a href="#cb60-796" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `initialize_camera()`: Sets up the Picamera2 instance.</span>
<span id="cb60-797"><a href="#cb60-797" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `get_frame()`: Continuously captures frames <span class="cf">for</span> the live preview.</span>
<span id="cb60-798"><a href="#cb60-798" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `generate_frames()`: Yields frames <span class="cf">for</span> the live video feed.</span>
<span id="cb60-799"><a href="#cb60-799" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `shutdown_server()`: Sets the shutdown event, stops the camera, <span class="kw">and</span> shuts down the Flask server</span>
<span id="cb60-800"><a href="#cb60-800" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `index()`: Handles the label <span class="bu">input</span> page.</span>
<span id="cb60-801"><a href="#cb60-801" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `capture_page()`: Displays the main capture interface.</span>
<span id="cb60-802"><a href="#cb60-802" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `video_feed()`: Shows a live preview to position the camera</span>
<span id="cb60-803"><a href="#cb60-803" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `capture_image()`: Saves an image <span class="cf">with</span> the current label.</span>
<span id="cb60-804"><a href="#cb60-804" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> `stop()`: Stops the capture process <span class="kw">and</span> displays a summary.</span>
<span id="cb60-805"><a href="#cb60-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-806"><a href="#cb60-806" aria-hidden="true" tabindex="-1"></a><span class="co">#### Usage Flow:</span></span>
<span id="cb60-807"><a href="#cb60-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-808"><a href="#cb60-808" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> Start the script on your Raspberry Pi.</span>
<span id="cb60-809"><a href="#cb60-809" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Access the web interface <span class="im">from</span> a browser.</span>
<span id="cb60-810"><a href="#cb60-810" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Enter a label <span class="cf">for</span> the images you want to capture <span class="kw">and</span> press `Start Capture`.</span>
<span id="cb60-811"><a href="#cb60-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-812"><a href="#cb60-812" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>enter_label.png)</span>
<span id="cb60-813"><a href="#cb60-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-814"><a href="#cb60-814" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> Use the live preview to position the camera.</span>
<span id="cb60-815"><a href="#cb60-815" aria-hidden="true" tabindex="-1"></a><span class="fl">5.</span> Click `Capture Image` to save images under the current label.</span>
<span id="cb60-816"><a href="#cb60-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-817"><a href="#cb60-817" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>capture.png)</span>
<span id="cb60-818"><a href="#cb60-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-819"><a href="#cb60-819" aria-hidden="true" tabindex="-1"></a><span class="fl">6.</span> Change labels <span class="im">as</span> needed <span class="cf">for</span> different categories, selecting `Change Label`.</span>
<span id="cb60-820"><a href="#cb60-820" aria-hidden="true" tabindex="-1"></a><span class="fl">7.</span> Click `Stop Capture` when finished to see a summary.</span>
<span id="cb60-821"><a href="#cb60-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-822"><a href="#cb60-822" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>stop.png)</span>
<span id="cb60-823"><a href="#cb60-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-824"><a href="#cb60-824" aria-hidden="true" tabindex="-1"></a><span class="co">#### Technical Notes:</span></span>
<span id="cb60-825"><a href="#cb60-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-826"><a href="#cb60-826" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> The script uses threading to handle concurrent frame capture <span class="kw">and</span> web serving.</span>
<span id="cb60-827"><a href="#cb60-827" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Images are saved <span class="cf">with</span> timestamps <span class="kw">in</span> their filenames <span class="cf">for</span> uniqueness.</span>
<span id="cb60-828"><a href="#cb60-828" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> The web interface <span class="kw">is</span> responsive <span class="kw">and</span> can be accessed <span class="im">from</span> mobile devices.</span>
<span id="cb60-829"><a href="#cb60-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-830"><a href="#cb60-830" aria-hidden="true" tabindex="-1"></a><span class="co">#### Customization Possibilities:</span></span>
<span id="cb60-831"><a href="#cb60-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-832"><a href="#cb60-832" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Adjust image resolution <span class="kw">in</span> the `initialize_camera()` function. Here we used QVGA (<span class="dv">320</span><span class="er">X240</span>).</span>
<span id="cb60-833"><a href="#cb60-833" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Modify the HTML templates <span class="cf">for</span> a different look <span class="kw">and</span> feel.</span>
<span id="cb60-834"><a href="#cb60-834" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Add additional image processing <span class="kw">or</span> analysis steps <span class="kw">in</span> the `capture_image()` function.</span>
<span id="cb60-835"><a href="#cb60-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-836"><a href="#cb60-836" aria-hidden="true" tabindex="-1"></a><span class="co">#### Number of samples on Dataset:</span></span>
<span id="cb60-837"><a href="#cb60-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-838"><a href="#cb60-838" aria-hidden="true" tabindex="-1"></a>Get around <span class="dv">60</span> images <span class="im">from</span> each category (`periquito`, `robot` <span class="kw">and</span> `background`). Try to capture different angles, backgrounds, <span class="kw">and</span> light conditions. On the Raspi, we will end <span class="cf">with</span> a folder named `dataset`, witch contains <span class="dv">3</span> sub<span class="op">-</span>folders <span class="op">*</span>periquito,<span class="op">*</span> <span class="op">*</span>robot<span class="op">*</span>, <span class="kw">and</span> <span class="op">*</span>background<span class="op">*</span>. one <span class="cf">for</span> each <span class="kw">class</span> of images.</span>
<span id="cb60-839"><a href="#cb60-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-840"><a href="#cb60-840" aria-hidden="true" tabindex="-1"></a>You can use `Filezilla` to transfer the created dataset to your main computer. </span>
<span id="cb60-841"><a href="#cb60-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-842"><a href="#cb60-842" aria-hidden="true" tabindex="-1"></a><span class="co">## Training the model with Edge Impulse Studio</span></span>
<span id="cb60-843"><a href="#cb60-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-844"><a href="#cb60-844" aria-hidden="true" tabindex="-1"></a>We will use the Edge Impulse Studio to train our model. Go to the  [Edge Impulse Page](https:<span class="op">//</span>edgeimpulse.com<span class="op">/</span>), enter your account credentials, <span class="kw">and</span> create a new project:</span>
<span id="cb60-845"><a href="#cb60-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-846"><a href="#cb60-846" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>new<span class="op">-</span>proj<span class="op">-</span>ei.png)</span>
<span id="cb60-847"><a href="#cb60-847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-848"><a href="#cb60-848" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> Here, you can clone a similar project: [Raspi <span class="op">-</span> Img Class](https:<span class="op">//</span>studio.edgeimpulse.com<span class="op">/</span>public<span class="op">/</span><span class="dv">510251</span><span class="op">/</span>live).</span>
<span id="cb60-849"><a href="#cb60-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-850"><a href="#cb60-850" aria-hidden="true" tabindex="-1"></a><span class="co">### Dataset</span></span>
<span id="cb60-851"><a href="#cb60-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-852"><a href="#cb60-852" aria-hidden="true" tabindex="-1"></a>We will walk through four main steps using the EI Studio (<span class="kw">or</span> Studio). These steps are crucial <span class="kw">in</span> preparing our model <span class="cf">for</span> use on the Raspi: Dataset, Impulse, Tests, <span class="kw">and</span> Deploy (on the Edge Device, <span class="kw">in</span> this case, the Raspi).</span>
<span id="cb60-853"><a href="#cb60-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-854"><a href="#cb60-854" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> Regarding the Dataset, it <span class="kw">is</span> essential to point out that our Original Dataset, captured <span class="cf">with</span> the Raspi, will be split into <span class="op">*</span>Training<span class="op">*</span>, <span class="op">*</span>Validation<span class="op">*</span>, <span class="kw">and</span> <span class="op">*</span>Test<span class="op">*</span>. The Test Set will be separated <span class="im">from</span> the beginning <span class="kw">and</span> reserved <span class="cf">for</span> use only <span class="kw">in</span> the Test phase after training. The Validation Set will be used during training.</span>
<span id="cb60-855"><a href="#cb60-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-856"><a href="#cb60-856" aria-hidden="true" tabindex="-1"></a>On Studio, follow the steps to upload the captured data:</span>
<span id="cb60-857"><a href="#cb60-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-858"><a href="#cb60-858" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> Go to the `Data acquisition` tab, <span class="kw">and</span> <span class="kw">in</span> the `UPLOAD DATA` section, upload the files <span class="im">from</span> your computer <span class="kw">in</span> the chosen categories.</span>
<span id="cb60-859"><a href="#cb60-859" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Leave to the Studio the splitting of the original dataset into <span class="op">*</span>train <span class="kw">and</span> test<span class="op">*</span> <span class="kw">and</span> choose the label about</span>
<span id="cb60-860"><a href="#cb60-860" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Repeat the procedure <span class="cf">for</span> <span class="bu">all</span> three classes. At the end, you should see your <span class="st">"raw data"</span> <span class="kw">in</span> the Studio:</span>
<span id="cb60-861"><a href="#cb60-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-862"><a href="#cb60-862" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>data<span class="op">-</span>Aquisition.png)</span>
<span id="cb60-863"><a href="#cb60-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-864"><a href="#cb60-864" aria-hidden="true" tabindex="-1"></a>The Studio allows you to explore your data, showing a complete view of <span class="bu">all</span> the data <span class="kw">in</span> your project. You can clear, inspect, <span class="kw">or</span> change labels by clicking on individual data items. In our case, a straightforward project, the data seems OK.</span>
<span id="cb60-865"><a href="#cb60-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-866"><a href="#cb60-866" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>data<span class="op">-</span>esplorer.png)</span>
<span id="cb60-867"><a href="#cb60-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-868"><a href="#cb60-868" aria-hidden="true" tabindex="-1"></a><span class="co">## The Impulse Design</span></span>
<span id="cb60-869"><a href="#cb60-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-870"><a href="#cb60-870" aria-hidden="true" tabindex="-1"></a>In this phase, we should define how to:</span>
<span id="cb60-871"><a href="#cb60-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-872"><a href="#cb60-872" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Pre<span class="op">-</span>process our data, which consists of resizing the individual images <span class="kw">and</span> determining the `color depth` to use (be it RGB <span class="kw">or</span> Grayscale) <span class="kw">and</span></span>
<span id="cb60-873"><a href="#cb60-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-874"><a href="#cb60-874" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Specify a Model. In this case, it will be the `Transfer Learning (Images)` to fine<span class="op">-</span>tune a pre<span class="op">-</span>trained MobileNet V2 image classification model on our data. This method performs well even <span class="cf">with</span> relatively small image datasets (around <span class="dv">180</span> images <span class="kw">in</span> our case).</span>
<span id="cb60-875"><a href="#cb60-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-876"><a href="#cb60-876" aria-hidden="true" tabindex="-1"></a>Transfer Learning <span class="cf">with</span> MobileNet offers a streamlined approach to model training, which <span class="kw">is</span> especially beneficial <span class="cf">for</span> resource<span class="op">-</span>constrained environments <span class="kw">and</span> projects <span class="cf">with</span> limited labeled data. MobileNet, known <span class="cf">for</span> its lightweight architecture, <span class="kw">is</span> a pre<span class="op">-</span>trained model that has already learned valuable features <span class="im">from</span> a large dataset (ImageNet).</span>
<span id="cb60-877"><a href="#cb60-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-878"><a href="#cb60-878" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>jpeg<span class="op">/</span>model_1.jpg)</span>
<span id="cb60-879"><a href="#cb60-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-880"><a href="#cb60-880" aria-hidden="true" tabindex="-1"></a>By leveraging these learned features, we can train a new model <span class="cf">for</span> your specific task <span class="cf">with</span> fewer data <span class="kw">and</span> computational resources <span class="kw">and</span> achieve competitive accuracy.</span>
<span id="cb60-881"><a href="#cb60-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-882"><a href="#cb60-882" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>jpeg<span class="op">/</span>model_2.jpg)</span>
<span id="cb60-883"><a href="#cb60-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-884"><a href="#cb60-884" aria-hidden="true" tabindex="-1"></a>This approach significantly reduces training time <span class="kw">and</span> computational cost, making it ideal <span class="cf">for</span> quick prototyping <span class="kw">and</span> deployment on embedded devices where efficiency <span class="kw">is</span> paramount.</span>
<span id="cb60-885"><a href="#cb60-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-886"><a href="#cb60-886" aria-hidden="true" tabindex="-1"></a>Go to the Impulse Design Tab <span class="kw">and</span> create the <span class="op">*</span>impulse<span class="op">*</span>, defining an image size of <span class="dv">160</span><span class="er">x160</span> <span class="kw">and</span> squashing them (squared form, without cropping). Select Image <span class="kw">and</span> Transfer Learning blocks. Save the Impulse.</span>
<span id="cb60-887"><a href="#cb60-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-888"><a href="#cb60-888" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>impulse.png)</span>
<span id="cb60-889"><a href="#cb60-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-890"><a href="#cb60-890" aria-hidden="true" tabindex="-1"></a><span class="co">### Image Pre-Processing</span></span>
<span id="cb60-891"><a href="#cb60-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-892"><a href="#cb60-892" aria-hidden="true" tabindex="-1"></a>All the <span class="bu">input</span> QVGA<span class="op">/</span>RGB565 images will be converted to <span class="dv">76</span>,<span class="dv">800</span> features (<span class="dv">160</span><span class="er">x160x3</span>).</span>
<span id="cb60-893"><a href="#cb60-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-894"><a href="#cb60-894" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>preproc.png)</span>
<span id="cb60-895"><a href="#cb60-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-896"><a href="#cb60-896" aria-hidden="true" tabindex="-1"></a>Press `Save parameters` <span class="kw">and</span> select `Generate features` <span class="kw">in</span> the <span class="bu">next</span> tab.</span>
<span id="cb60-897"><a href="#cb60-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-898"><a href="#cb60-898" aria-hidden="true" tabindex="-1"></a><span class="co">### Model Design</span></span>
<span id="cb60-899"><a href="#cb60-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-900"><a href="#cb60-900" aria-hidden="true" tabindex="-1"></a>MobileNet <span class="kw">is</span> a family of efficient convolutional neural networks designed <span class="cf">for</span> mobile <span class="kw">and</span> embedded vision applications. The key features of MobileNet are:</span>
<span id="cb60-901"><a href="#cb60-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-902"><a href="#cb60-902" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> Lightweight: Optimized <span class="cf">for</span> mobile devices <span class="kw">and</span> embedded systems <span class="cf">with</span> limited computational resources.</span>
<span id="cb60-903"><a href="#cb60-903" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Speed: Fast inference times, suitable <span class="cf">for</span> real<span class="op">-</span>time applications.</span>
<span id="cb60-904"><a href="#cb60-904" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Accuracy: Maintains good accuracy despite its compact size.</span>
<span id="cb60-905"><a href="#cb60-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-906"><a href="#cb60-906" aria-hidden="true" tabindex="-1"></a>[MobileNetV2](https:<span class="op">//</span>arxiv.org<span class="op">/</span><span class="bu">abs</span><span class="op">/</span><span class="fl">1801.04381</span>), introduced <span class="kw">in</span> <span class="dv">2018</span>, improves the original MobileNet architecture. Key features include:</span>
<span id="cb60-907"><a href="#cb60-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-908"><a href="#cb60-908" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> Inverted Residuals: Inverted residual structures are used where shortcut connections are made between thin bottleneck layers.</span>
<span id="cb60-909"><a href="#cb60-909" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Linear Bottlenecks: Removes non<span class="op">-</span>linearities <span class="kw">in</span> the narrow layers to prevent the destruction of information.</span>
<span id="cb60-910"><a href="#cb60-910" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Depth<span class="op">-</span>wise Separable Convolutions: Continues to use this efficient operation <span class="im">from</span> MobileNetV1.</span>
<span id="cb60-911"><a href="#cb60-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-912"><a href="#cb60-912" aria-hidden="true" tabindex="-1"></a>In our project, we will do a `Transfer Learning` <span class="cf">with</span> the `MobileNetV2 <span class="dv">160</span><span class="er">x160</span> <span class="fl">1.0</span>`,  which means that the images used <span class="cf">for</span> training (<span class="kw">and</span> future inference) should have an <span class="op">*</span><span class="bu">input</span> Size<span class="op">*</span> of <span class="dv">160</span><span class="er">x160</span> pixels <span class="kw">and</span> a <span class="op">*</span>Width Multiplier<span class="op">*</span> of <span class="fl">1.0</span> (full width, <span class="kw">not</span> reduced). This configuration balances between model size, speed, <span class="kw">and</span> accuracy.</span>
<span id="cb60-913"><a href="#cb60-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-914"><a href="#cb60-914" aria-hidden="true" tabindex="-1"></a><span class="co">### Model Training</span></span>
<span id="cb60-915"><a href="#cb60-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-916"><a href="#cb60-916" aria-hidden="true" tabindex="-1"></a>Another valuable deep learning technique <span class="kw">is</span> <span class="op">**</span>Data Augmentation<span class="op">**</span>. Data augmentation improves the accuracy of machine learning models by creating additional artificial data. A data augmentation system makes small, random changes to the training data during the training process (such <span class="im">as</span> flipping, cropping, <span class="kw">or</span> rotating the images).</span>
<span id="cb60-917"><a href="#cb60-917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-918"><a href="#cb60-918" aria-hidden="true" tabindex="-1"></a>Looking under the hood, here you can see how Edge Impulse implements a data Augmentation policy on your data:</span>
<span id="cb60-919"><a href="#cb60-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-920"><a href="#cb60-920" aria-hidden="true" tabindex="-1"></a>``` python</span>
<span id="cb60-921"><a href="#cb60-921" aria-hidden="true" tabindex="-1"></a><span class="co"># Implements the data augmentation policy</span></span>
<span id="cb60-922"><a href="#cb60-922" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> augment_image(image, label):</span>
<span id="cb60-923"><a href="#cb60-923" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flips the image randomly</span></span>
<span id="cb60-924"><a href="#cb60-924" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_flip_left_right(image)</span>
<span id="cb60-925"><a href="#cb60-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-926"><a href="#cb60-926" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Increase the image size, then randomly crop it down to</span></span>
<span id="cb60-927"><a href="#cb60-927" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the original dimensions</span></span>
<span id="cb60-928"><a href="#cb60-928" aria-hidden="true" tabindex="-1"></a>    resize_factor <span class="op">=</span> random.uniform(<span class="dv">1</span>, <span class="fl">1.2</span>)</span>
<span id="cb60-929"><a href="#cb60-929" aria-hidden="true" tabindex="-1"></a>    new_height <span class="op">=</span> math.floor(resize_factor <span class="op">*</span> INPUT_SHAPE[<span class="dv">0</span>])</span>
<span id="cb60-930"><a href="#cb60-930" aria-hidden="true" tabindex="-1"></a>    new_width <span class="op">=</span> math.floor(resize_factor <span class="op">*</span> INPUT_SHAPE[<span class="dv">1</span>])</span>
<span id="cb60-931"><a href="#cb60-931" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.resize_with_crop_or_pad(image, new_height, new_width)</span>
<span id="cb60-932"><a href="#cb60-932" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_crop(image, size<span class="op">=</span>INPUT_SHAPE)</span>
<span id="cb60-933"><a href="#cb60-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-934"><a href="#cb60-934" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vary the brightness of the image</span></span>
<span id="cb60-935"><a href="#cb60-935" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_brightness(image, max_delta<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb60-936"><a href="#cb60-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-937"><a href="#cb60-937" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> image, label</span>
<span id="cb60-938"><a href="#cb60-938" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-939"><a href="#cb60-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-940"><a href="#cb60-940" aria-hidden="true" tabindex="-1"></a>Exposure to these variations during training can <span class="bu">help</span> prevent your model <span class="im">from</span> taking shortcuts by <span class="st">"memorizing"</span> superficial clues <span class="kw">in</span> your training data, meaning it may better reflect the deep underlying patterns <span class="kw">in</span> your dataset.</span>
<span id="cb60-941"><a href="#cb60-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-942"><a href="#cb60-942" aria-hidden="true" tabindex="-1"></a>The final dense layer of our model will have <span class="dv">0</span> neurons <span class="cf">with</span> a <span class="dv">10</span><span class="op">%</span> dropout <span class="cf">for</span> overfitting prevention. Here <span class="kw">is</span> the Training result:</span>
<span id="cb60-943"><a href="#cb60-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-944"><a href="#cb60-944" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>result<span class="op">-</span>train.png)</span>
<span id="cb60-945"><a href="#cb60-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-946"><a href="#cb60-946" aria-hidden="true" tabindex="-1"></a>The result <span class="kw">is</span> excellent, <span class="cf">with</span> a reasonable <span class="dv">35</span><span class="er">ms</span> of latency (<span class="cf">for</span> a Rasp<span class="op">-</span><span class="dv">4</span>), which should result <span class="kw">in</span> around <span class="dv">30</span> fps (frames per second) during inference. A Raspi<span class="op">-</span>Zero should be slower, <span class="kw">and</span> the Rasp<span class="op">-</span><span class="dv">5</span>, faster. </span>
<span id="cb60-947"><a href="#cb60-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-948"><a href="#cb60-948" aria-hidden="true" tabindex="-1"></a><span class="co">### Trading off: Accuracy versus speed</span></span>
<span id="cb60-949"><a href="#cb60-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-950"><a href="#cb60-950" aria-hidden="true" tabindex="-1"></a>If faster inference <span class="kw">is</span> needed, we should train the model using smaller alphas (<span class="fl">0.35</span>, <span class="fl">0.5</span>, <span class="kw">and</span> <span class="fl">0.75</span>) <span class="kw">or</span> even <span class="bu">reduce</span> the image <span class="bu">input</span> size, trading <span class="cf">with</span> accuracy. However, reducing the <span class="bu">input</span> image size <span class="kw">and</span> decreasing the alpha (width multiplier) can speed up inference <span class="cf">for</span> MobileNet V2, but they have different trade<span class="op">-</span>offs. Let<span class="st">'s compare:</span></span>
<span id="cb60-951"><a href="#cb60-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-952"><a href="#cb60-952" aria-hidden="true" tabindex="-1"></a><span class="er">1. Reducing Image Input Size:</span></span>
<span id="cb60-953"><a href="#cb60-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-954"><a href="#cb60-954" aria-hidden="true" tabindex="-1"></a>Pros:</span>
<span id="cb60-955"><a href="#cb60-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-956"><a href="#cb60-956" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Significantly reduces the computational cost across <span class="bu">all</span> layers.</span>
<span id="cb60-957"><a href="#cb60-957" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Decreases memory usage.</span>
<span id="cb60-958"><a href="#cb60-958" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> It often provides a substantial speed boost.</span>
<span id="cb60-959"><a href="#cb60-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-960"><a href="#cb60-960" aria-hidden="true" tabindex="-1"></a>Cons:</span>
<span id="cb60-961"><a href="#cb60-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-962"><a href="#cb60-962" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> It may <span class="bu">reduce</span> the model<span class="st">'s ability to detect small features or fine details.</span></span>
<span id="cb60-963"><a href="#cb60-963" aria-hidden="true" tabindex="-1"></a><span class="er">- It can significantly impact accuracy, especially for tasks requiring fine-grained recognition.</span></span>
<span id="cb60-964"><a href="#cb60-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-965"><a href="#cb60-965" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Reducing Alpha (Width Multiplier):</span>
<span id="cb60-966"><a href="#cb60-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-967"><a href="#cb60-967" aria-hidden="true" tabindex="-1"></a>Pros:</span>
<span id="cb60-968"><a href="#cb60-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-969"><a href="#cb60-969" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Reduces the number of parameters <span class="kw">and</span> computations <span class="kw">in</span> the model.</span>
<span id="cb60-970"><a href="#cb60-970" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Maintains the original <span class="bu">input</span> resolution, potentially preserving more detail.</span>
<span id="cb60-971"><a href="#cb60-971" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> It can provide a good balance between speed <span class="kw">and</span> accuracy.</span>
<span id="cb60-972"><a href="#cb60-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-973"><a href="#cb60-973" aria-hidden="true" tabindex="-1"></a>Cons:</span>
<span id="cb60-974"><a href="#cb60-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-975"><a href="#cb60-975" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> It may <span class="kw">not</span> speed up inference <span class="im">as</span> dramatically <span class="im">as</span> reducing <span class="bu">input</span> size.</span>
<span id="cb60-976"><a href="#cb60-976" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> It can <span class="bu">reduce</span> the model<span class="st">'s capacity to learn complex features.</span></span>
<span id="cb60-977"><a href="#cb60-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-978"><a href="#cb60-978" aria-hidden="true" tabindex="-1"></a><span class="er">Comparison:</span></span>
<span id="cb60-979"><a href="#cb60-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-980"><a href="#cb60-980" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> Speed Impact: </span>
<span id="cb60-981"><a href="#cb60-981" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Reducing <span class="bu">input</span> size often provides a more substantial speed boost because it reduces computations quadratically (halving both width <span class="kw">and</span> height reduces computations by about <span class="dv">75</span><span class="op">%</span>).</span>
<span id="cb60-982"><a href="#cb60-982" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Reducing alpha provides a more linear reduction <span class="kw">in</span> computations.</span>
<span id="cb60-983"><a href="#cb60-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-984"><a href="#cb60-984" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Accuracy Impact:</span>
<span id="cb60-985"><a href="#cb60-985" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Reducing <span class="bu">input</span> size can severely impact accuracy, especially when detecting small objects <span class="kw">or</span> fine details.</span>
<span id="cb60-986"><a href="#cb60-986" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Reducing alpha tends to have a more gradual impact on accuracy.</span>
<span id="cb60-987"><a href="#cb60-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-988"><a href="#cb60-988" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Model Architecture:</span>
<span id="cb60-989"><a href="#cb60-989" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Changing <span class="bu">input</span> size doesn<span class="st">'t alter the model'</span>s architecture.</span>
<span id="cb60-990"><a href="#cb60-990" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Changing alpha modifies the model<span class="st">'s structure by reducing the number of channels in each layer.</span></span>
<span id="cb60-991"><a href="#cb60-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-992"><a href="#cb60-992" aria-hidden="true" tabindex="-1"></a><span class="er">Recommendation:</span></span>
<span id="cb60-993"><a href="#cb60-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-994"><a href="#cb60-994" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> If our application doesn<span class="st">'t require detecting tiny details and can tolerate some loss in accuracy, reducing the input size is often the most effective way to speed up inference.</span></span>
<span id="cb60-995"><a href="#cb60-995" aria-hidden="true" tabindex="-1"></a><span class="er">2. Reducing alpha might be preferable if maintaining the ability to detect fine details is crucial or if you need a more balanced trade-off between speed and accuracy.</span></span>
<span id="cb60-996"><a href="#cb60-996" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> For best results, you might want to experiment <span class="cf">with</span> both:</span>
<span id="cb60-997"><a href="#cb60-997" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Try MobileNet V2 <span class="cf">with</span> <span class="bu">input</span> sizes like <span class="dv">160</span><span class="er">x160</span> <span class="kw">or</span> <span class="dv">92</span><span class="er">x92</span></span>
<span id="cb60-998"><a href="#cb60-998" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Experiment <span class="cf">with</span> alpha values like <span class="fl">1.0</span>, <span class="fl">0.75</span>, <span class="fl">0.5</span> <span class="kw">or</span> <span class="fl">0.35</span>.</span>
<span id="cb60-999"><a href="#cb60-999" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> Always benchmark the different configurations on your specific hardware <span class="kw">and</span> <span class="cf">with</span> your particular dataset to find the optimal balance <span class="cf">for</span> your use case.</span>
<span id="cb60-1000"><a href="#cb60-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1001"><a href="#cb60-1001" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> Remember, the best choice depends on your specific requirements <span class="cf">for</span> accuracy, speed, <span class="kw">and</span> the nature of the images you<span class="st">'re working with. It'</span>s often worth experimenting <span class="cf">with</span> combinations to find the optimal configuration <span class="cf">for</span> your particular use case.</span>
<span id="cb60-1002"><a href="#cb60-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1003"><a href="#cb60-1003" aria-hidden="true" tabindex="-1"></a><span class="co">### Model Testing</span></span>
<span id="cb60-1004"><a href="#cb60-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1005"><a href="#cb60-1005" aria-hidden="true" tabindex="-1"></a>Now, you should take the data <span class="bu">set</span> aside at the start of the project <span class="kw">and</span> run the trained model using it <span class="im">as</span> <span class="bu">input</span>. Again, the result <span class="kw">is</span> excellent (<span class="fl">92.22</span><span class="op">%</span>).</span>
<span id="cb60-1006"><a href="#cb60-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1007"><a href="#cb60-1007" aria-hidden="true" tabindex="-1"></a><span class="co">### Deploying the model</span></span>
<span id="cb60-1008"><a href="#cb60-1008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1009"><a href="#cb60-1009" aria-hidden="true" tabindex="-1"></a>As we did <span class="kw">in</span> the previous section, we can deploy the trained model <span class="im">as</span> .tflite <span class="kw">and</span> use Raspi to run it using Python.</span>
<span id="cb60-1010"><a href="#cb60-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1011"><a href="#cb60-1011" aria-hidden="true" tabindex="-1"></a>On the `Dashboard` tab, go to Transfer learning model (int8 quantized) <span class="kw">and</span> click on the download icon:</span>
<span id="cb60-1012"><a href="#cb60-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1013"><a href="#cb60-1013" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>model.png)</span>
<span id="cb60-1014"><a href="#cb60-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1015"><a href="#cb60-1015" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> Let<span class="st">'s also download the float32 version for comparasion</span></span>
<span id="cb60-1016"><a href="#cb60-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1017"><a href="#cb60-1017" aria-hidden="true" tabindex="-1"></a><span class="er">Transfer the model from your computer to the Raspi </span>(.<span class="op">/</span>models), <span class="cf">for</span> example, using FileZilla. Also, capture some images <span class="cf">for</span> inference (.<span class="op">/</span>images). </span>
<span id="cb60-1018"><a href="#cb60-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1019"><a href="#cb60-1019" aria-hidden="true" tabindex="-1"></a>Import the needed libraries:</span>
<span id="cb60-1020"><a href="#cb60-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1021"><a href="#cb60-1021" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-1022"><a href="#cb60-1022" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb60-1023"><a href="#cb60-1023" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb60-1024"><a href="#cb60-1024" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb60-1025"><a href="#cb60-1025" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb60-1026"><a href="#cb60-1026" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb60-1027"><a href="#cb60-1027" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1028"><a href="#cb60-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1029"><a href="#cb60-1029" aria-hidden="true" tabindex="-1"></a>Define the paths <span class="kw">and</span> labels:</span>
<span id="cb60-1030"><a href="#cb60-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1031"><a href="#cb60-1031" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-1032"><a href="#cb60-1032" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"./images/robot.jpg"</span></span>
<span id="cb60-1033"><a href="#cb60-1033" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/ei-raspi-img-class-int8-quantized-model.tflite"</span></span>
<span id="cb60-1034"><a href="#cb60-1034" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'background'</span>, <span class="st">'periquito'</span>, <span class="st">'robot'</span>]</span>
<span id="cb60-1035"><a href="#cb60-1035" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1036"><a href="#cb60-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1037"><a href="#cb60-1037" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> Note that the models trained on the Edge Impulse Studio will output values <span class="cf">with</span> index <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, etc., where the actual labels will follow an alphabetic order.</span>
<span id="cb60-1038"><a href="#cb60-1038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1039"><a href="#cb60-1039" aria-hidden="true" tabindex="-1"></a>Load the model, allocate the tensors, <span class="kw">and</span> get the <span class="bu">input</span> <span class="kw">and</span> output tensor details:</span>
<span id="cb60-1040"><a href="#cb60-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1041"><a href="#cb60-1041" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-1042"><a href="#cb60-1042" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the TFLite model</span></span>
<span id="cb60-1043"><a href="#cb60-1043" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb60-1044"><a href="#cb60-1044" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb60-1045"><a href="#cb60-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1046"><a href="#cb60-1046" aria-hidden="true" tabindex="-1"></a><span class="co"># Get input and output tensors</span></span>
<span id="cb60-1047"><a href="#cb60-1047" aria-hidden="true" tabindex="-1"></a>input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb60-1048"><a href="#cb60-1048" aria-hidden="true" tabindex="-1"></a>output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb60-1049"><a href="#cb60-1049" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1050"><a href="#cb60-1050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1051"><a href="#cb60-1051" aria-hidden="true" tabindex="-1"></a>One important difference to note <span class="kw">is</span> that the `dtype` of the <span class="bu">input</span> details of the model <span class="kw">is</span> now `int8`, which means that the <span class="bu">input</span> values go <span class="im">from</span> <span class="op">-</span><span class="dv">128</span> to <span class="op">+</span><span class="dv">127</span>, <span class="cf">while</span> each pixel of our image goes <span class="im">from</span> <span class="dv">0</span> to <span class="fl">256.</span> This means that we should pre<span class="op">-</span>process the image to match it. We can check here:</span>
<span id="cb60-1052"><a href="#cb60-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1053"><a href="#cb60-1053" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-1054"><a href="#cb60-1054" aria-hidden="true" tabindex="-1"></a>input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb60-1055"><a href="#cb60-1055" aria-hidden="true" tabindex="-1"></a>input_dtype</span>
<span id="cb60-1056"><a href="#cb60-1056" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1057"><a href="#cb60-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1058"><a href="#cb60-1058" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1059"><a href="#cb60-1059" aria-hidden="true" tabindex="-1"></a>numpy.int8</span>
<span id="cb60-1060"><a href="#cb60-1060" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1061"><a href="#cb60-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1062"><a href="#cb60-1062" aria-hidden="true" tabindex="-1"></a>So, let<span class="st">'s open the image and show it:</span></span>
<span id="cb60-1063"><a href="#cb60-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1064"><a href="#cb60-1064" aria-hidden="true" tabindex="-1"></a><span class="er">```python</span></span>
<span id="cb60-1065"><a href="#cb60-1065" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb60-1066"><a href="#cb60-1066" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb60-1067"><a href="#cb60-1067" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb60-1068"><a href="#cb60-1068" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb60-1069"><a href="#cb60-1069" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb60-1070"><a href="#cb60-1070" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1071"><a href="#cb60-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1072"><a href="#cb60-1072" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>infer_robot.png)</span>
<span id="cb60-1073"><a href="#cb60-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1074"><a href="#cb60-1074" aria-hidden="true" tabindex="-1"></a>And perform the pre<span class="op">-</span>processing:</span>
<span id="cb60-1075"><a href="#cb60-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1076"><a href="#cb60-1076" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-1077"><a href="#cb60-1077" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb60-1078"><a href="#cb60-1078" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb60-1079"><a href="#cb60-1079" aria-hidden="true" tabindex="-1"></a>                  input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb60-1080"><a href="#cb60-1080" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> np.array(img, dtype<span class="op">=</span>np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb60-1081"><a href="#cb60-1081" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> (img_array <span class="op">/</span> scale <span class="op">+</span> zero_point).clip(<span class="op">-</span><span class="dv">128</span>, <span class="dv">127</span>).astype(np.int8)</span>
<span id="cb60-1082"><a href="#cb60-1082" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> np.expand_dims(img_array, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb60-1083"><a href="#cb60-1083" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1084"><a href="#cb60-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1085"><a href="#cb60-1085" aria-hidden="true" tabindex="-1"></a>Checking the <span class="bu">input</span> data, we can verify that the <span class="bu">input</span> tensor <span class="kw">is</span> compatible <span class="cf">with</span> what <span class="kw">is</span> expected by the model:</span>
<span id="cb60-1086"><a href="#cb60-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1087"><a href="#cb60-1087" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-1088"><a href="#cb60-1088" aria-hidden="true" tabindex="-1"></a>input_data.shape, input_data.dtype</span>
<span id="cb60-1089"><a href="#cb60-1089" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1090"><a href="#cb60-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1091"><a href="#cb60-1091" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1092"><a href="#cb60-1092" aria-hidden="true" tabindex="-1"></a>((<span class="dv">1</span>, <span class="dv">160</span>, <span class="dv">160</span>, <span class="dv">3</span>), dtype(<span class="st">'int8'</span>))</span>
<span id="cb60-1093"><a href="#cb60-1093" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1094"><a href="#cb60-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1095"><a href="#cb60-1095" aria-hidden="true" tabindex="-1"></a>Now, it <span class="kw">is</span> time to perform the inference. Let<span class="st">'s also calculate the latency of the model:</span></span>
<span id="cb60-1096"><a href="#cb60-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1097"><a href="#cb60-1097" aria-hidden="true" tabindex="-1"></a><span class="er">```python</span></span>
<span id="cb60-1098"><a href="#cb60-1098" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb60-1099"><a href="#cb60-1099" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb60-1100"><a href="#cb60-1100" aria-hidden="true" tabindex="-1"></a>interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb60-1101"><a href="#cb60-1101" aria-hidden="true" tabindex="-1"></a>interpreter.invoke()</span>
<span id="cb60-1102"><a href="#cb60-1102" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb60-1103"><a href="#cb60-1103" aria-hidden="true" tabindex="-1"></a>inference_time <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to milliseconds</span></span>
<span id="cb60-1104"><a href="#cb60-1104" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"Inference time: </span><span class="sc">{:.1f}</span><span class="st">ms"</span>.<span class="bu">format</span>(inference_time))</span>
<span id="cb60-1105"><a href="#cb60-1105" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1106"><a href="#cb60-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1107"><a href="#cb60-1107" aria-hidden="true" tabindex="-1"></a>The model will take around <span class="dv">125</span><span class="er">ms</span> to perform the inference <span class="kw">in</span> the Raspi<span class="op">-</span>Zero, which <span class="kw">is</span> <span class="dv">3</span> to <span class="dv">4</span> times longer than a Raspi<span class="op">-</span><span class="fl">5.</span></span>
<span id="cb60-1108"><a href="#cb60-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1109"><a href="#cb60-1109" aria-hidden="true" tabindex="-1"></a>Now, we can get the output labels <span class="kw">and</span> probabilities. It <span class="kw">is</span> also important to note that the model trained on the Edge Impulse Studio has a softmax <span class="kw">in</span> its output (different <span class="im">from</span> the original Movilenet V2), <span class="kw">and</span> we should use the model<span class="st">'s raw output as the “probabilities.”</span></span>
<span id="cb60-1110"><a href="#cb60-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1111"><a href="#cb60-1111" aria-hidden="true" tabindex="-1"></a><span class="er">```python</span></span>
<span id="cb60-1112"><a href="#cb60-1112" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain results and map them to the classes</span></span>
<span id="cb60-1113"><a href="#cb60-1113" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb60-1114"><a href="#cb60-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1115"><a href="#cb60-1115" aria-hidden="true" tabindex="-1"></a><span class="co"># Get indices of the top k results</span></span>
<span id="cb60-1116"><a href="#cb60-1116" aria-hidden="true" tabindex="-1"></a>top_k_results<span class="op">=</span><span class="dv">3</span></span>
<span id="cb60-1117"><a href="#cb60-1117" aria-hidden="true" tabindex="-1"></a>top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb60-1118"><a href="#cb60-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1119"><a href="#cb60-1119" aria-hidden="true" tabindex="-1"></a><span class="co"># Get quantization parameters</span></span>
<span id="cb60-1120"><a href="#cb60-1120" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb60-1121"><a href="#cb60-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1122"><a href="#cb60-1122" aria-hidden="true" tabindex="-1"></a><span class="co"># Dequantize the output</span></span>
<span id="cb60-1123"><a href="#cb60-1123" aria-hidden="true" tabindex="-1"></a>dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb60-1124"><a href="#cb60-1124" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> dequantized_output</span>
<span id="cb60-1125"><a href="#cb60-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1126"><a href="#cb60-1126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb60-1127"><a href="#cb60-1127" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb60-1128"><a href="#cb60-1128" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb60-1129"><a href="#cb60-1129" aria-hidden="true" tabindex="-1"></a>        labels[top_k_indices[i]],</span>
<span id="cb60-1130"><a href="#cb60-1130" aria-hidden="true" tabindex="-1"></a>        probabilities[top_k_indices[i]] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb60-1131"><a href="#cb60-1131" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1132"><a href="#cb60-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1133"><a href="#cb60-1133" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>infer<span class="op">-</span>result.png)</span>
<span id="cb60-1134"><a href="#cb60-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1135"><a href="#cb60-1135" aria-hidden="true" tabindex="-1"></a>Let’s modify the function created before so that we can handle different <span class="bu">type</span> of models:</span>
<span id="cb60-1136"><a href="#cb60-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1137"><a href="#cb60-1137" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>div <span class="kw">class</span><span class="op">=</span><span class="st">"scroll-code-block"</span><span class="op">&gt;</span></span>
<span id="cb60-1138"><a href="#cb60-1138" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-1139"><a href="#cb60-1139" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_classification(img_path, model_path, labels, top_k_results<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb60-1140"><a href="#cb60-1140" aria-hidden="true" tabindex="-1"></a>                         apply_softmax<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb60-1141"><a href="#cb60-1141" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the image</span></span>
<span id="cb60-1142"><a href="#cb60-1142" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb60-1143"><a href="#cb60-1143" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb60-1144"><a href="#cb60-1144" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)</span>
<span id="cb60-1145"><a href="#cb60-1145" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb60-1146"><a href="#cb60-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1147"><a href="#cb60-1147" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the TFLite model</span></span>
<span id="cb60-1148"><a href="#cb60-1148" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb60-1149"><a href="#cb60-1149" aria-hidden="true" tabindex="-1"></a>    interpreter.allocate_tensors()</span>
<span id="cb60-1150"><a href="#cb60-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1151"><a href="#cb60-1151" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get input and output tensors</span></span>
<span id="cb60-1152"><a href="#cb60-1152" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb60-1153"><a href="#cb60-1153" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb60-1154"><a href="#cb60-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1155"><a href="#cb60-1155" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess</span></span>
<span id="cb60-1156"><a href="#cb60-1156" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb60-1157"><a href="#cb60-1157" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb60-1158"><a href="#cb60-1158" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-1159"><a href="#cb60-1159" aria-hidden="true" tabindex="-1"></a>    input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb60-1160"><a href="#cb60-1160" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-1161"><a href="#cb60-1161" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> input_dtype <span class="op">==</span> np.uint8:</span>
<span id="cb60-1162"><a href="#cb60-1162" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(np.array(img), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb60-1163"><a href="#cb60-1163" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> input_dtype <span class="op">==</span> np.int8:</span>
<span id="cb60-1164"><a href="#cb60-1164" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb60-1165"><a href="#cb60-1165" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> np.array(img, dtype<span class="op">=</span>np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb60-1166"><a href="#cb60-1166" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> (img_array <span class="op">/</span> scale <span class="op">+</span> zero_point).clip(<span class="op">-</span><span class="dv">128</span>, <span class="dv">127</span>).astype(np.int8)</span>
<span id="cb60-1167"><a href="#cb60-1167" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(img_array, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb60-1168"><a href="#cb60-1168" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  <span class="co"># float32</span></span>
<span id="cb60-1169"><a href="#cb60-1169" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(np.array(img, dtype<span class="op">=</span>np.float32), axis<span class="op">=</span><span class="dv">0</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb60-1170"><a href="#cb60-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1171"><a href="#cb60-1171" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb60-1172"><a href="#cb60-1172" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb60-1173"><a href="#cb60-1173" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb60-1174"><a href="#cb60-1174" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb60-1175"><a href="#cb60-1175" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb60-1176"><a href="#cb60-1176" aria-hidden="true" tabindex="-1"></a>    inference_time <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to milliseconds</span></span>
<span id="cb60-1177"><a href="#cb60-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1178"><a href="#cb60-1178" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain results</span></span>
<span id="cb60-1179"><a href="#cb60-1179" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb60-1180"><a href="#cb60-1180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1181"><a href="#cb60-1181" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of the top k results</span></span>
<span id="cb60-1182"><a href="#cb60-1182" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb60-1183"><a href="#cb60-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1184"><a href="#cb60-1184" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle output based on type</span></span>
<span id="cb60-1185"><a href="#cb60-1185" aria-hidden="true" tabindex="-1"></a>    output_dtype <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb60-1186"><a href="#cb60-1186" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_dtype <span class="kw">in</span> [np.int8, np.uint8]:</span>
<span id="cb60-1187"><a href="#cb60-1187" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dequantize the output</span></span>
<span id="cb60-1188"><a href="#cb60-1188" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb60-1189"><a href="#cb60-1189" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb60-1190"><a href="#cb60-1190" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-1191"><a href="#cb60-1191" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> apply_softmax:</span>
<span id="cb60-1192"><a href="#cb60-1192" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply softmax</span></span>
<span id="cb60-1193"><a href="#cb60-1193" aria-hidden="true" tabindex="-1"></a>        exp_preds <span class="op">=</span> np.exp(predictions <span class="op">-</span> np.<span class="bu">max</span>(predictions))</span>
<span id="cb60-1194"><a href="#cb60-1194" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> exp_preds <span class="op">/</span> np.<span class="bu">sum</span>(exp_preds)</span>
<span id="cb60-1195"><a href="#cb60-1195" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb60-1196"><a href="#cb60-1196" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> predictions</span>
<span id="cb60-1197"><a href="#cb60-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1198"><a href="#cb60-1198" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb60-1199"><a href="#cb60-1199" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb60-1200"><a href="#cb60-1200" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb60-1201"><a href="#cb60-1201" aria-hidden="true" tabindex="-1"></a>            labels[top_k_indices[i]],</span>
<span id="cb60-1202"><a href="#cb60-1202" aria-hidden="true" tabindex="-1"></a>            probabilities[top_k_indices[i]] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb60-1203"><a href="#cb60-1203" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (<span class="st">"</span><span class="ch">\n\t</span><span class="st">Inference time: </span><span class="sc">{:.1f}</span><span class="st">ms"</span>.<span class="bu">format</span>(inference_time))</span>
<span id="cb60-1204"><a href="#cb60-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1205"><a href="#cb60-1205" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1206"><a href="#cb60-1206" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;/</span>div<span class="op">&gt;</span></span>
<span id="cb60-1207"><a href="#cb60-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1208"><a href="#cb60-1208" aria-hidden="true" tabindex="-1"></a>And test it <span class="cf">with</span> different images <span class="kw">and</span> the int8 quantized model (<span class="op">**</span><span class="dv">160</span><span class="er">x160</span> alpha <span class="op">=</span><span class="fl">1.0</span><span class="op">**</span>). </span>
<span id="cb60-1209"><a href="#cb60-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1210"><a href="#cb60-1210" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>infer<span class="op">-</span>int8<span class="op">-</span><span class="fl">160.</span><span class="er">png</span>)</span>
<span id="cb60-1211"><a href="#cb60-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1212"><a href="#cb60-1212" aria-hidden="true" tabindex="-1"></a>Let<span class="st">'s download a smaller model, such as the one trained for the [Nicla Vision Lab](https://studio.edgeimpulse.com/public/353482/live) (int8 quantized model (96x96 alpha = 0.1), as a test. We can use the same function:</span></span>
<span id="cb60-1213"><a href="#cb60-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1214"><a href="#cb60-1214" aria-hidden="true" tabindex="-1"></a><span class="er">![](images/png/infer-int8-96.png)</span></span>
<span id="cb60-1215"><a href="#cb60-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1216"><a href="#cb60-1216" aria-hidden="true" tabindex="-1"></a><span class="er">The model lost some accuracy, but it is still OK once our model does not look for many details. Regarding latency, we are around **ten times faster** on the Rasp-Zero. </span></span>
<span id="cb60-1217"><a href="#cb60-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1218"><a href="#cb60-1218" aria-hidden="true" tabindex="-1"></a><span class="co">## Live Image Classification</span></span>
<span id="cb60-1219"><a href="#cb60-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1220"><a href="#cb60-1220" aria-hidden="true" tabindex="-1"></a>Let<span class="st">'s develop an app to capture images with the USB camera in real time, showing its classification. </span></span>
<span id="cb60-1221"><a href="#cb60-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1222"><a href="#cb60-1222" aria-hidden="true" tabindex="-1"></a><span class="er">Using the nano on the terminal, save the code below, such as `img_class_live_infer.py`. </span></span>
<span id="cb60-1223"><a href="#cb60-1223" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>div <span class="kw">class</span><span class="op">=</span><span class="st">"scroll-code-block"</span><span class="op">&gt;</span></span>
<span id="cb60-1224"><a href="#cb60-1224" aria-hidden="true" tabindex="-1"></a>```python</span>
<span id="cb60-1225"><a href="#cb60-1225" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask, Response, render_template_string, request, jsonify</span>
<span id="cb60-1226"><a href="#cb60-1226" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb60-1227"><a href="#cb60-1227" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb60-1228"><a href="#cb60-1228" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb60-1229"><a href="#cb60-1229" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb60-1230"><a href="#cb60-1230" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb60-1231"><a href="#cb60-1231" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb60-1232"><a href="#cb60-1232" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb60-1233"><a href="#cb60-1233" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> queue <span class="im">import</span> Queue</span>
<span id="cb60-1234"><a href="#cb60-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1235"><a href="#cb60-1235" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> Flask(<span class="va">__name__</span>)</span>
<span id="cb60-1236"><a href="#cb60-1236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1237"><a href="#cb60-1237" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb60-1238"><a href="#cb60-1238" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb60-1239"><a href="#cb60-1239" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> <span class="va">None</span></span>
<span id="cb60-1240"><a href="#cb60-1240" aria-hidden="true" tabindex="-1"></a>frame_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb60-1241"><a href="#cb60-1241" aria-hidden="true" tabindex="-1"></a>is_classifying <span class="op">=</span> <span class="va">False</span></span>
<span id="cb60-1242"><a href="#cb60-1242" aria-hidden="true" tabindex="-1"></a>confidence_threshold <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb60-1243"><a href="#cb60-1243" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/ei-raspi-img-class-int8-quantized-model.tflite"</span></span>
<span id="cb60-1244"><a href="#cb60-1244" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'background'</span>, <span class="st">'periquito'</span>, <span class="st">'robot'</span>]</span>
<span id="cb60-1245"><a href="#cb60-1245" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> <span class="va">None</span></span>
<span id="cb60-1246"><a href="#cb60-1246" aria-hidden="true" tabindex="-1"></a>classification_queue <span class="op">=</span> Queue(maxsize<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb60-1247"><a href="#cb60-1247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1248"><a href="#cb60-1248" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_camera():</span>
<span id="cb60-1249"><a href="#cb60-1249" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> picam2</span>
<span id="cb60-1250"><a href="#cb60-1250" aria-hidden="true" tabindex="-1"></a>    picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb60-1251"><a href="#cb60-1251" aria-hidden="true" tabindex="-1"></a>    config <span class="op">=</span> picam2.create_preview_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">320</span>, <span class="dv">240</span>)})</span>
<span id="cb60-1252"><a href="#cb60-1252" aria-hidden="true" tabindex="-1"></a>    picam2.configure(config)</span>
<span id="cb60-1253"><a href="#cb60-1253" aria-hidden="true" tabindex="-1"></a>    picam2.start()</span>
<span id="cb60-1254"><a href="#cb60-1254" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Wait for camera to warm up</span></span>
<span id="cb60-1255"><a href="#cb60-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1256"><a href="#cb60-1256" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_frame():</span>
<span id="cb60-1257"><a href="#cb60-1257" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> frame</span>
<span id="cb60-1258"><a href="#cb60-1258" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb60-1259"><a href="#cb60-1259" aria-hidden="true" tabindex="-1"></a>        stream <span class="op">=</span> io.BytesIO()</span>
<span id="cb60-1260"><a href="#cb60-1260" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(stream, <span class="bu">format</span><span class="op">=</span><span class="st">'jpeg'</span>)</span>
<span id="cb60-1261"><a href="#cb60-1261" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb60-1262"><a href="#cb60-1262" aria-hidden="true" tabindex="-1"></a>            frame <span class="op">=</span> stream.getvalue()</span>
<span id="cb60-1263"><a href="#cb60-1263" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Capture frames more frequently</span></span>
<span id="cb60-1264"><a href="#cb60-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1265"><a href="#cb60-1265" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_frames():</span>
<span id="cb60-1266"><a href="#cb60-1266" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb60-1267"><a href="#cb60-1267" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb60-1268"><a href="#cb60-1268" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb60-1269"><a href="#cb60-1269" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (<span class="st">b'--frame</span><span class="ch">\r\n</span><span class="st">'</span></span>
<span id="cb60-1270"><a href="#cb60-1270" aria-hidden="true" tabindex="-1"></a>                       <span class="st">b'Content-Type: image/jpeg</span><span class="ch">\r\n\r\n</span><span class="st">'</span> <span class="op">+</span> frame <span class="op">+</span> <span class="st">b'</span><span class="ch">\r\n</span><span class="st">'</span>)</span>
<span id="cb60-1271"><a href="#cb60-1271" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)</span>
<span id="cb60-1272"><a href="#cb60-1272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1273"><a href="#cb60-1273" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_model():</span>
<span id="cb60-1274"><a href="#cb60-1274" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> interpreter</span>
<span id="cb60-1275"><a href="#cb60-1275" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> interpreter <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb60-1276"><a href="#cb60-1276" aria-hidden="true" tabindex="-1"></a>        interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb60-1277"><a href="#cb60-1277" aria-hidden="true" tabindex="-1"></a>        interpreter.allocate_tensors()</span>
<span id="cb60-1278"><a href="#cb60-1278" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> interpreter</span>
<span id="cb60-1279"><a href="#cb60-1279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1280"><a href="#cb60-1280" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_image(img, interpreter):</span>
<span id="cb60-1281"><a href="#cb60-1281" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb60-1282"><a href="#cb60-1282" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb60-1283"><a href="#cb60-1283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1284"><a href="#cb60-1284" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb60-1285"><a href="#cb60-1285" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb60-1286"><a href="#cb60-1286" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> np.expand_dims(np.array(img), axis<span class="op">=</span><span class="dv">0</span>)<span class="op">\</span></span>
<span id="cb60-1287"><a href="#cb60-1287" aria-hidden="true" tabindex="-1"></a>                             .astype(input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>])</span>
<span id="cb60-1288"><a href="#cb60-1288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1289"><a href="#cb60-1289" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb60-1290"><a href="#cb60-1290" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb60-1291"><a href="#cb60-1291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1292"><a href="#cb60-1292" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb60-1293"><a href="#cb60-1293" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle output based on type</span></span>
<span id="cb60-1294"><a href="#cb60-1294" aria-hidden="true" tabindex="-1"></a>    output_dtype <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb60-1295"><a href="#cb60-1295" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_dtype <span class="kw">in</span> [np.int8, np.uint8]:</span>
<span id="cb60-1296"><a href="#cb60-1296" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dequantize the output</span></span>
<span id="cb60-1297"><a href="#cb60-1297" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb60-1298"><a href="#cb60-1298" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb60-1299"><a href="#cb60-1299" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions</span>
<span id="cb60-1300"><a href="#cb60-1300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1301"><a href="#cb60-1301" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classification_worker():</span>
<span id="cb60-1302"><a href="#cb60-1302" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> load_model()</span>
<span id="cb60-1303"><a href="#cb60-1303" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb60-1304"><a href="#cb60-1304" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> is_classifying:</span>
<span id="cb60-1305"><a href="#cb60-1305" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> frame_lock:</span>
<span id="cb60-1306"><a href="#cb60-1306" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb60-1307"><a href="#cb60-1307" aria-hidden="true" tabindex="-1"></a>                    img <span class="op">=</span> Image.<span class="bu">open</span>(io.BytesIO(frame))</span>
<span id="cb60-1308"><a href="#cb60-1308" aria-hidden="true" tabindex="-1"></a>            predictions <span class="op">=</span> classify_image(img, interpreter)</span>
<span id="cb60-1309"><a href="#cb60-1309" aria-hidden="true" tabindex="-1"></a>            max_prob <span class="op">=</span> np.<span class="bu">max</span>(predictions)</span>
<span id="cb60-1310"><a href="#cb60-1310" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> max_prob <span class="op">&gt;=</span> confidence_threshold:</span>
<span id="cb60-1311"><a href="#cb60-1311" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> labels[np.argmax(predictions)]</span>
<span id="cb60-1312"><a href="#cb60-1312" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb60-1313"><a href="#cb60-1313" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> <span class="st">'Uncertain'</span></span>
<span id="cb60-1314"><a href="#cb60-1314" aria-hidden="true" tabindex="-1"></a>            classification_queue.put({<span class="st">'label'</span>: label, </span>
<span id="cb60-1315"><a href="#cb60-1315" aria-hidden="true" tabindex="-1"></a>                                      <span class="st">'probability'</span>: <span class="bu">float</span>(max_prob)})</span>
<span id="cb60-1316"><a href="#cb60-1316" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust based on your needs</span></span>
<span id="cb60-1317"><a href="#cb60-1317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1318"><a href="#cb60-1318" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/'</span>)</span>
<span id="cb60-1319"><a href="#cb60-1319" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> index():</span>
<span id="cb60-1320"><a href="#cb60-1320" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb60-1321"><a href="#cb60-1321" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb60-1322"><a href="#cb60-1322" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb60-1323"><a href="#cb60-1323" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb60-1324"><a href="#cb60-1324" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Image Classification&lt;/title&gt;</span></span>
<span id="cb60-1325"><a href="#cb60-1325" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script </span></span>
<span id="cb60-1326"><a href="#cb60-1326" aria-hidden="true" tabindex="-1"></a><span class="st">                src="https://code.jquery.com/jquery-3.6.0.min.js"&gt;</span></span>
<span id="cb60-1327"><a href="#cb60-1327" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb60-1328"><a href="#cb60-1328" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script&gt;</span></span>
<span id="cb60-1329"><a href="#cb60-1329" aria-hidden="true" tabindex="-1"></a><span class="st">                function startClassification() {</span></span>
<span id="cb60-1330"><a href="#cb60-1330" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/start');</span></span>
<span id="cb60-1331"><a href="#cb60-1331" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#startBtn').prop('disabled', true);</span></span>
<span id="cb60-1332"><a href="#cb60-1332" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#stopBtn').prop('disabled', false);</span></span>
<span id="cb60-1333"><a href="#cb60-1333" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb60-1334"><a href="#cb60-1334" aria-hidden="true" tabindex="-1"></a><span class="st">                function stopClassification() {</span></span>
<span id="cb60-1335"><a href="#cb60-1335" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/stop');</span></span>
<span id="cb60-1336"><a href="#cb60-1336" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#startBtn').prop('disabled', false);</span></span>
<span id="cb60-1337"><a href="#cb60-1337" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#stopBtn').prop('disabled', true);</span></span>
<span id="cb60-1338"><a href="#cb60-1338" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb60-1339"><a href="#cb60-1339" aria-hidden="true" tabindex="-1"></a><span class="st">                function updateConfidence() {</span></span>
<span id="cb60-1340"><a href="#cb60-1340" aria-hidden="true" tabindex="-1"></a><span class="st">                    var confidence = $('#confidence').val();</span></span>
<span id="cb60-1341"><a href="#cb60-1341" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/update_confidence', {confidence: confidence});</span></span>
<span id="cb60-1342"><a href="#cb60-1342" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb60-1343"><a href="#cb60-1343" aria-hidden="true" tabindex="-1"></a><span class="st">                function updateClassification() {</span></span>
<span id="cb60-1344"><a href="#cb60-1344" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.get('/get_classification', function(data) {</span></span>
<span id="cb60-1345"><a href="#cb60-1345" aria-hidden="true" tabindex="-1"></a><span class="st">                        $('#classification').text(data.label + ': ' </span></span>
<span id="cb60-1346"><a href="#cb60-1346" aria-hidden="true" tabindex="-1"></a><span class="st">                        + data.probability.toFixed(2));</span></span>
<span id="cb60-1347"><a href="#cb60-1347" aria-hidden="true" tabindex="-1"></a><span class="st">                    });</span></span>
<span id="cb60-1348"><a href="#cb60-1348" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb60-1349"><a href="#cb60-1349" aria-hidden="true" tabindex="-1"></a><span class="st">                $(document).ready(function() {</span></span>
<span id="cb60-1350"><a href="#cb60-1350" aria-hidden="true" tabindex="-1"></a><span class="st">                    setInterval(updateClassification, 100);  </span></span>
<span id="cb60-1351"><a href="#cb60-1351" aria-hidden="true" tabindex="-1"></a><span class="st">                    // Update every 100ms</span></span>
<span id="cb60-1352"><a href="#cb60-1352" aria-hidden="true" tabindex="-1"></a><span class="st">                });</span></span>
<span id="cb60-1353"><a href="#cb60-1353" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb60-1354"><a href="#cb60-1354" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb60-1355"><a href="#cb60-1355" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb60-1356"><a href="#cb60-1356" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Image Classification&lt;/h1&gt;</span></span>
<span id="cb60-1357"><a href="#cb60-1357" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;img src="</span><span class="sc">{{</span><span class="st"> url_for('video_feed') </span><span class="sc">}}</span><span class="st">" width="640" height="480" /&gt;</span></span>
<span id="cb60-1358"><a href="#cb60-1358" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb60-1359"><a href="#cb60-1359" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;button id="startBtn" onclick="startClassification()"&gt;</span></span>
<span id="cb60-1360"><a href="#cb60-1360" aria-hidden="true" tabindex="-1"></a><span class="st">            Start Classification&lt;/button&gt;</span></span>
<span id="cb60-1361"><a href="#cb60-1361" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;button id="stopBtn" onclick="stopClassification()" disabled&gt;</span></span>
<span id="cb60-1362"><a href="#cb60-1362" aria-hidden="true" tabindex="-1"></a><span class="st">            Stop Classification&lt;/button&gt;</span></span>
<span id="cb60-1363"><a href="#cb60-1363" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb60-1364"><a href="#cb60-1364" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;label for="confidence"&gt;Confidence Threshold:&lt;/label&gt;</span></span>
<span id="cb60-1365"><a href="#cb60-1365" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;input type="number" id="confidence" name="confidence" min="0" </span></span>
<span id="cb60-1366"><a href="#cb60-1366" aria-hidden="true" tabindex="-1"></a><span class="st">            max="1" step="0.1" value="0.8" onchange="updateConfidence()"&gt;</span></span>
<span id="cb60-1367"><a href="#cb60-1367" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb60-1368"><a href="#cb60-1368" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;div id="classification"&gt;Waiting for classification...&lt;/div&gt;</span></span>
<span id="cb60-1369"><a href="#cb60-1369" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb60-1370"><a href="#cb60-1370" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb60-1371"><a href="#cb60-1371" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>)</span>
<span id="cb60-1372"><a href="#cb60-1372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1373"><a href="#cb60-1373" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/video_feed'</span>)</span>
<span id="cb60-1374"><a href="#cb60-1374" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> video_feed():</span>
<span id="cb60-1375"><a href="#cb60-1375" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Response(generate_frames(),</span>
<span id="cb60-1376"><a href="#cb60-1376" aria-hidden="true" tabindex="-1"></a>                    mimetype<span class="op">=</span><span class="st">'multipart/x-mixed-replace; boundary=frame'</span>)</span>
<span id="cb60-1377"><a href="#cb60-1377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1378"><a href="#cb60-1378" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/start'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb60-1379"><a href="#cb60-1379" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> start_classification():</span>
<span id="cb60-1380"><a href="#cb60-1380" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> is_classifying</span>
<span id="cb60-1381"><a href="#cb60-1381" aria-hidden="true" tabindex="-1"></a>    is_classifying <span class="op">=</span> <span class="va">True</span></span>
<span id="cb60-1382"><a href="#cb60-1382" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb60-1383"><a href="#cb60-1383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1384"><a href="#cb60-1384" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/stop'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb60-1385"><a href="#cb60-1385" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stop_classification():</span>
<span id="cb60-1386"><a href="#cb60-1386" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> is_classifying</span>
<span id="cb60-1387"><a href="#cb60-1387" aria-hidden="true" tabindex="-1"></a>    is_classifying <span class="op">=</span> <span class="va">False</span></span>
<span id="cb60-1388"><a href="#cb60-1388" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb60-1389"><a href="#cb60-1389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1390"><a href="#cb60-1390" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/update_confidence'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb60-1391"><a href="#cb60-1391" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_confidence():</span>
<span id="cb60-1392"><a href="#cb60-1392" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> confidence_threshold</span>
<span id="cb60-1393"><a href="#cb60-1393" aria-hidden="true" tabindex="-1"></a>    confidence_threshold <span class="op">=</span> <span class="bu">float</span>(request.form[<span class="st">'confidence'</span>])</span>
<span id="cb60-1394"><a href="#cb60-1394" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb60-1395"><a href="#cb60-1395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1396"><a href="#cb60-1396" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/get_classification'</span>)</span>
<span id="cb60-1397"><a href="#cb60-1397" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_classification():</span>
<span id="cb60-1398"><a href="#cb60-1398" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> is_classifying:</span>
<span id="cb60-1399"><a href="#cb60-1399" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> jsonify({<span class="st">'label'</span>: <span class="st">'Not classifying'</span>, <span class="st">'probability'</span>: <span class="dv">0</span>})</span>
<span id="cb60-1400"><a href="#cb60-1400" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb60-1401"><a href="#cb60-1401" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> classification_queue.get_nowait()</span>
<span id="cb60-1402"><a href="#cb60-1402" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> Queue.Empty:</span>
<span id="cb60-1403"><a href="#cb60-1403" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> {<span class="st">'label'</span>: <span class="st">'Processing'</span>, <span class="st">'probability'</span>: <span class="dv">0</span>}</span>
<span id="cb60-1404"><a href="#cb60-1404" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> jsonify(result)</span>
<span id="cb60-1405"><a href="#cb60-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1406"><a href="#cb60-1406" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb60-1407"><a href="#cb60-1407" aria-hidden="true" tabindex="-1"></a>    initialize_camera()</span>
<span id="cb60-1408"><a href="#cb60-1408" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>get_frame, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb60-1409"><a href="#cb60-1409" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>classification_worker, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb60-1410"><a href="#cb60-1410" aria-hidden="true" tabindex="-1"></a>    app.run(host<span class="op">=</span><span class="st">'0.0.0.0'</span>, port<span class="op">=</span><span class="dv">5000</span>, threaded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-1411"><a href="#cb60-1411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1412"><a href="#cb60-1412" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1413"><a href="#cb60-1413" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;/</span>div<span class="op">&gt;</span></span>
<span id="cb60-1414"><a href="#cb60-1414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1415"><a href="#cb60-1415" aria-hidden="true" tabindex="-1"></a>On the terminal, run:</span>
<span id="cb60-1416"><a href="#cb60-1416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1417"><a href="#cb60-1417" aria-hidden="true" tabindex="-1"></a>```bash</span>
<span id="cb60-1418"><a href="#cb60-1418" aria-hidden="true" tabindex="-1"></a>python3 img_class_live_infer.py</span>
<span id="cb60-1419"><a href="#cb60-1419" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb60-1420"><a href="#cb60-1420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1421"><a href="#cb60-1421" aria-hidden="true" tabindex="-1"></a>And access the web interface:</span>
<span id="cb60-1422"><a href="#cb60-1422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1423"><a href="#cb60-1423" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> On the Raspberry Pi itself (<span class="cf">if</span> you have a GUI): Open a web browser <span class="kw">and</span> go to `http:<span class="op">//</span>localhost:<span class="dv">5000</span>`</span>
<span id="cb60-1424"><a href="#cb60-1424" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> From another device on the same network: Open a web browser <span class="kw">and</span> go to `http:<span class="op">//&lt;</span>raspberry_pi_ip<span class="op">&gt;</span>:<span class="dv">5000</span>` (Replace `<span class="op">&lt;</span>raspberry_pi_ip<span class="op">&gt;</span>` <span class="cf">with</span> your Raspberry Pi<span class="st">'s IP address). For example: `http://192.168.4.210:5000/`</span></span>
<span id="cb60-1425"><a href="#cb60-1425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1426"><a href="#cb60-1426" aria-hidden="true" tabindex="-1"></a><span class="er">Here are some screenshots of the app running on an external desktop</span></span>
<span id="cb60-1427"><a href="#cb60-1427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1428"><a href="#cb60-1428" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>[](images<span class="op">/</span>png<span class="op">/</span>app<span class="op">-</span>inference.png)</span>
<span id="cb60-1429"><a href="#cb60-1429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1430"><a href="#cb60-1430" aria-hidden="true" tabindex="-1"></a>Here, you can see the app running on the YouTube:</span>
<span id="cb60-1431"><a href="#cb60-1431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1432"><a href="#cb60-1432" aria-hidden="true" tabindex="-1"></a>{{<span class="op">&lt;</span> video https:<span class="op">//</span>www.youtube.com<span class="op">/</span>watch?v<span class="op">=</span>o1QsQrpCMw4 <span class="op">&gt;</span>}}</span>
<span id="cb60-1433"><a href="#cb60-1433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1434"><a href="#cb60-1434" aria-hidden="true" tabindex="-1"></a>The code creates a web application <span class="cf">for</span> real<span class="op">-</span>time image classification using a Raspberry Pi, its camera module, <span class="kw">and</span> a TensorFlow Lite model. The application uses Flask to serve a web interface where <span class="kw">is</span> possible to view the camera feed <span class="kw">and</span> see live classification results.</span>
<span id="cb60-1435"><a href="#cb60-1435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1436"><a href="#cb60-1436" aria-hidden="true" tabindex="-1"></a><span class="co">#### Key Components:</span></span>
<span id="cb60-1437"><a href="#cb60-1437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1438"><a href="#cb60-1438" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> <span class="op">**</span>Flask Web Application<span class="op">**</span>: Serves the user interface <span class="kw">and</span> handles requests.</span>
<span id="cb60-1439"><a href="#cb60-1439" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> <span class="op">**</span>PiCamera2<span class="op">**</span>: Captures images <span class="im">from</span> the Raspberry Pi camera module.</span>
<span id="cb60-1440"><a href="#cb60-1440" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> <span class="op">**</span>TensorFlow Lite<span class="op">**</span>: Runs the image classification model.</span>
<span id="cb60-1441"><a href="#cb60-1441" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> <span class="op">**</span>Threading<span class="op">**</span>: Manages concurrent operations <span class="cf">for</span> smooth performance.</span>
<span id="cb60-1442"><a href="#cb60-1442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1443"><a href="#cb60-1443" aria-hidden="true" tabindex="-1"></a><span class="co">#### Main Features:</span></span>
<span id="cb60-1444"><a href="#cb60-1444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1445"><a href="#cb60-1445" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Live camera feed display</span>
<span id="cb60-1446"><a href="#cb60-1446" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Real<span class="op">-</span>time image classification</span>
<span id="cb60-1447"><a href="#cb60-1447" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Adjustable confidence threshold</span>
<span id="cb60-1448"><a href="#cb60-1448" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Start<span class="op">/</span>Stop classification on demand</span>
<span id="cb60-1449"><a href="#cb60-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1450"><a href="#cb60-1450" aria-hidden="true" tabindex="-1"></a><span class="co">#### Code Structure:</span></span>
<span id="cb60-1451"><a href="#cb60-1451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1452"><a href="#cb60-1452" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> <span class="op">**</span>Imports <span class="kw">and</span> Setup<span class="op">**</span>:</span>
<span id="cb60-1453"><a href="#cb60-1453" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Flask <span class="cf">for</span> web application</span>
<span id="cb60-1454"><a href="#cb60-1454" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> PiCamera2 <span class="cf">for</span> camera control</span>
<span id="cb60-1455"><a href="#cb60-1455" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> TensorFlow Lite <span class="cf">for</span> inference</span>
<span id="cb60-1456"><a href="#cb60-1456" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Threading <span class="kw">and</span> Queue <span class="cf">for</span> concurrent operations</span>
<span id="cb60-1457"><a href="#cb60-1457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1458"><a href="#cb60-1458" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> <span class="op">**</span>Global Variables<span class="op">**</span>:</span>
<span id="cb60-1459"><a href="#cb60-1459" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Camera <span class="kw">and</span> frame management</span>
<span id="cb60-1460"><a href="#cb60-1460" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Classification control</span>
<span id="cb60-1461"><a href="#cb60-1461" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Model <span class="kw">and</span> label information</span>
<span id="cb60-1462"><a href="#cb60-1462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1463"><a href="#cb60-1463" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> <span class="op">**</span>Camera Functions<span class="op">**</span>:</span>
<span id="cb60-1464"><a href="#cb60-1464" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `initialize_camera()`: Sets up the PiCamera2</span>
<span id="cb60-1465"><a href="#cb60-1465" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `get_frame()`: Continuously captures frames</span>
<span id="cb60-1466"><a href="#cb60-1466" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `generate_frames()`: Yields frames <span class="cf">for</span> the web feed</span>
<span id="cb60-1467"><a href="#cb60-1467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1468"><a href="#cb60-1468" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> <span class="op">**</span>Model Functions<span class="op">**</span>:</span>
<span id="cb60-1469"><a href="#cb60-1469" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `load_model()`: Loads the TFLite model</span>
<span id="cb60-1470"><a href="#cb60-1470" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `classify_image()`: Performs inference on a single image</span>
<span id="cb60-1471"><a href="#cb60-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1472"><a href="#cb60-1472" aria-hidden="true" tabindex="-1"></a><span class="fl">5.</span> <span class="op">**</span>Classification Worker<span class="op">**</span>:</span>
<span id="cb60-1473"><a href="#cb60-1473" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Runs <span class="kw">in</span> a separate thread</span>
<span id="cb60-1474"><a href="#cb60-1474" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Continuously classifies frames when active</span>
<span id="cb60-1475"><a href="#cb60-1475" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Updates a queue <span class="cf">with</span> the latest results</span>
<span id="cb60-1476"><a href="#cb60-1476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1477"><a href="#cb60-1477" aria-hidden="true" tabindex="-1"></a><span class="fl">6.</span> <span class="op">**</span>Flask Routes<span class="op">**</span>:</span>
<span id="cb60-1478"><a href="#cb60-1478" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `<span class="op">/</span>`: Serves the main HTML page</span>
<span id="cb60-1479"><a href="#cb60-1479" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `<span class="op">/</span>video_feed`: Streams the camera feed</span>
<span id="cb60-1480"><a href="#cb60-1480" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `<span class="op">/</span>start` <span class="kw">and</span> `<span class="op">/</span>stop`: Controls classification</span>
<span id="cb60-1481"><a href="#cb60-1481" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `<span class="op">/</span>update_confidence`: Adjusts the confidence threshold</span>
<span id="cb60-1482"><a href="#cb60-1482" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> `<span class="op">/</span>get_classification`: Returns the latest classification result</span>
<span id="cb60-1483"><a href="#cb60-1483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1484"><a href="#cb60-1484" aria-hidden="true" tabindex="-1"></a><span class="fl">7.</span> <span class="op">**</span>HTML Template<span class="op">**</span>:</span>
<span id="cb60-1485"><a href="#cb60-1485" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Displays camera feed <span class="kw">and</span> classification results</span>
<span id="cb60-1486"><a href="#cb60-1486" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Provides controls <span class="cf">for</span> starting<span class="op">/</span>stopping <span class="kw">and</span> adjusting settings</span>
<span id="cb60-1487"><a href="#cb60-1487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1488"><a href="#cb60-1488" aria-hidden="true" tabindex="-1"></a><span class="fl">8.</span> <span class="op">**</span>Main Execution<span class="op">**</span>:</span>
<span id="cb60-1489"><a href="#cb60-1489" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Initializes camera <span class="kw">and</span> starts necessary threads</span>
<span id="cb60-1490"><a href="#cb60-1490" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> Runs the Flask application</span>
<span id="cb60-1491"><a href="#cb60-1491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1492"><a href="#cb60-1492" aria-hidden="true" tabindex="-1"></a><span class="co">#### Key Concepts:</span></span>
<span id="cb60-1493"><a href="#cb60-1493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1494"><a href="#cb60-1494" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> <span class="op">**</span>Concurrent Operations<span class="op">**</span>: Using threads to handle camera capture <span class="kw">and</span> classification separately <span class="im">from</span> the web server.</span>
<span id="cb60-1495"><a href="#cb60-1495" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> <span class="op">**</span>Real<span class="op">-</span>time Updates<span class="op">**</span>: Frequent updates to the classification results without page reloads.</span>
<span id="cb60-1496"><a href="#cb60-1496" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> <span class="op">**</span>Model Reuse<span class="op">**</span>: Loading the TFLite model once <span class="kw">and</span> reusing it <span class="cf">for</span> efficiency.</span>
<span id="cb60-1497"><a href="#cb60-1497" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> <span class="op">**</span>Flexible Configuration<span class="op">**</span>: Allowing users to adjust the confidence threshold on the fly.</span>
<span id="cb60-1498"><a href="#cb60-1498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1499"><a href="#cb60-1499" aria-hidden="true" tabindex="-1"></a><span class="co">#### Usage:</span></span>
<span id="cb60-1500"><a href="#cb60-1500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1501"><a href="#cb60-1501" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> Ensure <span class="bu">all</span> dependencies are installed.</span>
<span id="cb60-1502"><a href="#cb60-1502" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Run the script on a Raspberry Pi <span class="cf">with</span> a camera module.</span>
<span id="cb60-1503"><a href="#cb60-1503" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Access the web interface <span class="im">from</span> a browser using the Raspberry Pi<span class="st">'s IP address.</span></span>
<span id="cb60-1504"><a href="#cb60-1504" aria-hidden="true" tabindex="-1"></a><span class="er">4. Start classification and adjust settings as needed.</span></span>
<span id="cb60-1505"><a href="#cb60-1505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1506"><a href="#cb60-1506" aria-hidden="true" tabindex="-1"></a><span class="co">## Conclusion:</span></span>
<span id="cb60-1507"><a href="#cb60-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1508"><a href="#cb60-1508" aria-hidden="true" tabindex="-1"></a>Image classification has emerged <span class="im">as</span> a powerful <span class="kw">and</span> versatile application of machine learning, <span class="cf">with</span> significant implications <span class="cf">for</span> various fields, <span class="im">from</span> healthcare to environmental monitoring. This chapter has demonstrated how to implement a robust image classification system on edge devices like the Raspi<span class="op">-</span>Zero <span class="kw">and</span> Rasp<span class="op">-</span><span class="dv">5</span>, showcasing the potential <span class="cf">for</span> real<span class="op">-</span>time, on<span class="op">-</span>device intelligence.</span>
<span id="cb60-1509"><a href="#cb60-1509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1510"><a href="#cb60-1510" aria-hidden="true" tabindex="-1"></a>We<span class="st">'ve explored the entire pipeline of an image classification project, from data collection and model training using Edge Impulse Studio to deploying and running inferences on a Raspi. The process highlighted several key points:</span></span>
<span id="cb60-1511"><a href="#cb60-1511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1512"><a href="#cb60-1512" aria-hidden="true" tabindex="-1"></a><span class="er">1. The importance of proper data collection and preprocessing for training effective models.</span></span>
<span id="cb60-1513"><a href="#cb60-1513" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> The power of transfer learning, allowing us to leverage pre<span class="op">-</span>trained models like MobileNet V2 <span class="cf">for</span> efficient training <span class="cf">with</span> limited data.</span>
<span id="cb60-1514"><a href="#cb60-1514" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> The trade<span class="op">-</span>offs between model accuracy <span class="kw">and</span> inference speed, especially crucial <span class="cf">for</span> edge devices.</span>
<span id="cb60-1515"><a href="#cb60-1515" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> The implementation of real<span class="op">-</span>time classification using a web<span class="op">-</span>based interface, demonstrating practical applications.</span>
<span id="cb60-1516"><a href="#cb60-1516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1517"><a href="#cb60-1517" aria-hidden="true" tabindex="-1"></a>The ability to run these models on edge devices like the Raspi opens up numerous possibilities <span class="cf">for</span> IoT applications, autonomous systems, <span class="kw">and</span> real<span class="op">-</span>time monitoring solutions. It allows <span class="cf">for</span> reduced latency, improved privacy, <span class="kw">and</span> operation <span class="kw">in</span> environments <span class="cf">with</span> limited connectivity.</span>
<span id="cb60-1518"><a href="#cb60-1518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1519"><a href="#cb60-1519" aria-hidden="true" tabindex="-1"></a>As we<span class="st">'ve seen, even with the computational constraints of edge devices, it'</span>s possible to achieve impressive results <span class="kw">in</span> terms of both accuracy <span class="kw">and</span> speed. The flexibility to adjust model parameters, such <span class="im">as</span> <span class="bu">input</span> size <span class="kw">and</span> alpha values, allows <span class="cf">for</span> fine<span class="op">-</span>tuning to meet specific project requirements.</span>
<span id="cb60-1520"><a href="#cb60-1520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1521"><a href="#cb60-1521" aria-hidden="true" tabindex="-1"></a>Looking forward, the field of edge AI <span class="kw">and</span> image classification continues to evolve rapidly. Advances <span class="kw">in</span> model compression techniques, hardware acceleration, <span class="kw">and</span> more efficient neural network architectures promise to further expand the capabilities of edge devices <span class="kw">in</span> computer vision tasks.</span>
<span id="cb60-1522"><a href="#cb60-1522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1523"><a href="#cb60-1523" aria-hidden="true" tabindex="-1"></a>This project serves <span class="im">as</span> a foundation <span class="cf">for</span> more <span class="bu">complex</span> computer vision applications <span class="kw">and</span> encourages further exploration into the exciting world of edge AI <span class="kw">and</span> IoT. Whether it<span class="st">'s for industrial automation, smart home applications, or environmental monitoring, the skills and concepts covered here provide a solid starting point for a wide range of innovative projects.</span></span>
<span id="cb60-1524"><a href="#cb60-1524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1525"><a href="#cb60-1525" aria-hidden="true" tabindex="-1"></a><span class="er">## Resources</span></span>
<span id="cb60-1526"><a href="#cb60-1526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1527"><a href="#cb60-1527" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> [Dataset Example](https:<span class="op">//</span>github.com<span class="op">/</span>Mjrovai<span class="op">/</span>EdgeML<span class="op">-</span><span class="cf">with</span><span class="op">-</span>Raspberry<span class="op">-</span>Pi<span class="op">/</span>tree<span class="op">/</span>main<span class="op">/</span>IMG_CLASS<span class="op">/</span>dataset)</span>
<span id="cb60-1528"><a href="#cb60-1528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1529"><a href="#cb60-1529" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> [Setup Test Notebook on a Raspi](https:<span class="op">//</span>github.com<span class="op">/</span>Mjrovai<span class="op">/</span>EdgeML<span class="op">-</span><span class="cf">with</span><span class="op">-</span>Raspberry<span class="op">-</span>Pi<span class="op">/</span>blob<span class="op">/</span>main<span class="op">/</span>IMG_CLASS<span class="op">/</span>notebooks<span class="op">/</span>setup_test.ipynb)</span>
<span id="cb60-1530"><a href="#cb60-1530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1531"><a href="#cb60-1531" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> [Image Classification Notebook on a Raspi](https:<span class="op">//</span>github.com<span class="op">/</span>Mjrovai<span class="op">/</span>EdgeML<span class="op">-</span><span class="cf">with</span><span class="op">-</span>Raspberry<span class="op">-</span>Pi<span class="op">/</span>blob<span class="op">/</span>main<span class="op">/</span>IMG_CLASS<span class="op">/</span>notebooks<span class="op">/</span><span class="dv">10</span><span class="er">_Image_Classification</span>.ipynb)</span>
<span id="cb60-1532"><a href="#cb60-1532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1533"><a href="#cb60-1533" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> [CNN to classify Cifar<span class="op">-</span><span class="dv">10</span> dataset at CoLab](https:<span class="op">//</span>colab.research.google.com<span class="op">/</span>github<span class="op">/</span>Mjrovai<span class="op">/</span>UNIFEI<span class="op">-</span>IESTI01<span class="op">-</span>TinyML<span class="op">-</span><span class="fl">2022.1</span><span class="op">/</span>blob<span class="op">/</span>main<span class="op">/</span><span class="dv">00</span><span class="er">_Curse_Folder</span><span class="op">/</span><span class="dv">2</span><span class="er">_Applications_Deploy</span><span class="op">/</span>Class_16<span class="op">/</span>cifar_10<span class="op">/</span>CNN_Cifar_10_TFLite.ipynb<span class="co">#scrollTo=iiVBUpuHXEtw)</span></span>
<span id="cb60-1534"><a href="#cb60-1534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1535"><a href="#cb60-1535" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> [Cifar <span class="dv">10</span> <span class="op">-</span> Image Classification on a Raspi](https:<span class="op">//</span>github.com<span class="op">/</span>Mjrovai<span class="op">/</span>EdgeML<span class="op">-</span><span class="cf">with</span><span class="op">-</span>Raspberry<span class="op">-</span>Pi<span class="op">/</span>blob<span class="op">/</span>main<span class="op">/</span>IMG_CLASS<span class="op">/</span>notebooks<span class="op">/</span><span class="dv">20</span><span class="er">_Cifar_10_Image_Classification</span>.ipynb) </span>
<span id="cb60-1536"><a href="#cb60-1536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1537"><a href="#cb60-1537" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> [Python Scripts](https:<span class="op">//</span>github.com<span class="op">/</span>Mjrovai<span class="op">/</span>EdgeML<span class="op">-</span><span class="cf">with</span><span class="op">-</span>Raspberry<span class="op">-</span>Pi<span class="op">/</span>tree<span class="op">/</span>main<span class="op">/</span>IMG_CLASS<span class="op">/</span>python_scripts)</span>
<span id="cb60-1538"><a href="#cb60-1538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-1539"><a href="#cb60-1539" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> [Edge Impulse Project](https:<span class="op">//</span>studio.edgeimpulse.com<span class="op">/</span>public<span class="op">/</span><span class="dv">510251</span><span class="op">/</span>live)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Edited by Prof.&nbsp;Marcelo Rovai (UNIFEI University)</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">This book was built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>



</body></html>