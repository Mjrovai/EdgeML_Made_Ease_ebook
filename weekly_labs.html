<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Edge AI Engineering - Edge AI Engineering - Weekly Labs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./images/unifei-logo.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Edge AI Engineering</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto tools-wide">
    <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Edge-AI-Engineering.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools ms-auto-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./weekly_labs.html">Edge AI Engineering - Weekly Labs</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgments</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about_book.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this Book</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Classification_of_AI_Applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classification of AI Applications</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text"><div class="part">Fixed Function AI (Reactive)</div></span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/image_classification/image_classification_fund.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification Fundamentals</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/image_classification/custom_image_classification_project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Custom Image Classification Project</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/object_detection/object_detection_fundamentals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection: Fundamentals</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/object_detection/custom_object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Custom Object Detection Project</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/object_detection/cv_yolo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computer Vision Applications with YOLO</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/counting_objects_yolo/counting_objects_yolo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Counting objects with YOLO</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/executorch/executorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification with EXECUTORCH</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/hw_acceleration/hw_acceleration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beyond CPU - Hardware Acceleration for Edge AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text"><div class="part">Generative AI (Proactive)</div></span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/rnn-verne/rnn-verne.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Text Generation with RNNs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/kd_intro/kd_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Knowledge Distillation in Practice</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/llm/slm_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/llm/slm_opt_tech.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SLM: Basic Optimization Techniques</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/vlm/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vision-Language Models at the Edge</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/audio_pipeline/audio_pipeline.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Audio and Vision AI Pipeline</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/physical_comp/RPi_Physical_Computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Physical Computing with Raspberry Pi</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/iot/slm_iot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Experimenting with SLMs for IoT Control</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./raspi/advancing_adgeai/adv_edgeai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advancing EdgeAI: Beyond Basic SLMs</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text"><div class="part">Weekly Labs</div></span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./weekly_labs.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Edge AI Engineering - Weekly Labs</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text"><div class="part">References &amp; Author</div></span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./about_the_author.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the author</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#week-1-introduction-and-setup" id="toc-week-1-introduction-and-setup" class="nav-link active" data-scroll-target="#week-1-introduction-and-setup">Week 1: Introduction and Setup</a>
  <ul>
  <li><a href="#lab-1-raspberry-pi-configuration" id="toc-lab-1-raspberry-pi-configuration" class="nav-link" data-scroll-target="#lab-1-raspberry-pi-configuration">Lab 1: Raspberry Pi Configuration</a></li>
  <li><a href="#lab-2-development-environment-setup" id="toc-lab-2-development-environment-setup" class="nav-link" data-scroll-target="#lab-2-development-environment-setup">Lab 2: Development Environment Setup</a></li>
  </ul></li>
  <li><a href="#week-2-image-classification-fundamentals" id="toc-week-2-image-classification-fundamentals" class="nav-link" data-scroll-target="#week-2-image-classification-fundamentals">Week 2: Image Classification Fundamentals</a>
  <ul>
  <li><a href="#lab-3-working-with-pre-trained-models" id="toc-lab-3-working-with-pre-trained-models" class="nav-link" data-scroll-target="#lab-3-working-with-pre-trained-models">Lab 3: Working with Pre-trained Models</a></li>
  <li><a href="#lab-4-custom-dataset-creation" id="toc-lab-4-custom-dataset-creation" class="nav-link" data-scroll-target="#lab-4-custom-dataset-creation">Lab 4: Custom Dataset Creation</a></li>
  </ul></li>
  <li><a href="#week-3-custom-image-classification" id="toc-week-3-custom-image-classification" class="nav-link" data-scroll-target="#week-3-custom-image-classification">Week 3: Custom Image Classification</a>
  <ul>
  <li><a href="#lab-5-edge-impulse-model-training" id="toc-lab-5-edge-impulse-model-training" class="nav-link" data-scroll-target="#lab-5-edge-impulse-model-training">Lab 5: Edge Impulse Model Training</a></li>
  <li><a href="#lab-6-model-deployment-to-raspberry-pi" id="toc-lab-6-model-deployment-to-raspberry-pi" class="nav-link" data-scroll-target="#lab-6-model-deployment-to-raspberry-pi">Lab 6: Model Deployment to Raspberry Pi</a></li>
  </ul></li>
  <li><a href="#week-4-object-detection-fundamentals" id="toc-week-4-object-detection-fundamentals" class="nav-link" data-scroll-target="#week-4-object-detection-fundamentals">Week 4: Object Detection Fundamentals</a>
  <ul>
  <li><a href="#lab-7-pre-trained-object-detection" id="toc-lab-7-pre-trained-object-detection" class="nav-link" data-scroll-target="#lab-7-pre-trained-object-detection">Lab 7: Pre-trained Object Detection</a></li>
  <li><a href="#lab-8-efficientdet-and-fomo-models" id="toc-lab-8-efficientdet-and-fomo-models" class="nav-link" data-scroll-target="#lab-8-efficientdet-and-fomo-models">Lab 8: EfficientDet and FOMO Models</a></li>
  </ul></li>
  <li><a href="#week-5-custom-object-detection" id="toc-week-5-custom-object-detection" class="nav-link" data-scroll-target="#week-5-custom-object-detection">Week 5: Custom Object Detection</a>
  <ul>
  <li><a href="#lab-9-dataset-creation-and-annotation" id="toc-lab-9-dataset-creation-and-annotation" class="nav-link" data-scroll-target="#lab-9-dataset-creation-and-annotation">Lab 9: Dataset Creation and Annotation</a></li>
  <li><a href="#lab-10-training-models-in-edge-impulse" id="toc-lab-10-training-models-in-edge-impulse" class="nav-link" data-scroll-target="#lab-10-training-models-in-edge-impulse">Lab 10: Training Models in Edge Impulse</a></li>
  </ul></li>
  <li><a href="#week-6-advanced-object-detection" id="toc-week-6-advanced-object-detection" class="nav-link" data-scroll-target="#week-6-advanced-object-detection">Week 6: Advanced Object Detection</a>
  <ul>
  <li><a href="#lab-11-fomo-model-training" id="toc-lab-11-fomo-model-training" class="nav-link" data-scroll-target="#lab-11-fomo-model-training">Lab 11: FOMO Model Training</a></li>
  <li><a href="#lab-12-yolo-implementation" id="toc-lab-12-yolo-implementation" class="nav-link" data-scroll-target="#lab-12-yolo-implementation">Lab 12: YOLO Implementation</a></li>
  </ul></li>
  <li><a href="#week-7-object-counting-project" id="toc-week-7-object-counting-project" class="nav-link" data-scroll-target="#week-7-object-counting-project">Week 7: Object Counting Project</a>
  <ul>
  <li><a href="#lab-13-custom-yolo-training" id="toc-lab-13-custom-yolo-training" class="nav-link" data-scroll-target="#lab-13-custom-yolo-training">Lab 13: Custom YOLO Training</a></li>
  <li><a href="#lab-14-fixed-function-ai-integration-optional" id="toc-lab-14-fixed-function-ai-integration-optional" class="nav-link" data-scroll-target="#lab-14-fixed-function-ai-integration-optional">Lab 14: Fixed-Function AI Integration (Optional)</a></li>
  </ul></li>
  <li><a href="#week-8-introduction-to-generative-ai" id="toc-week-8-introduction-to-generative-ai" class="nav-link" data-scroll-target="#week-8-introduction-to-generative-ai">Week 8: Introduction to Generative AI</a>
  <ul>
  <li><a href="#lab-15-raspberry-pi-configuration-for-slms" id="toc-lab-15-raspberry-pi-configuration-for-slms" class="nav-link" data-scroll-target="#lab-15-raspberry-pi-configuration-for-slms">Lab 15: Raspberry Pi Configuration for SLMs</a></li>
  <li><a href="#lab-16-ollama-installation-and-testing" id="toc-lab-16-ollama-installation-and-testing" class="nav-link" data-scroll-target="#lab-16-ollama-installation-and-testing">Lab 16: Ollama Installation and Testing</a></li>
  </ul></li>
  <li><a href="#week-9-slm-python-integration" id="toc-week-9-slm-python-integration" class="nav-link" data-scroll-target="#week-9-slm-python-integration">Week 9: SLM Python Integration</a>
  <ul>
  <li><a href="#lab-17-ollama-python-library" id="toc-lab-17-ollama-python-library" class="nav-link" data-scroll-target="#lab-17-ollama-python-library">Lab 17: Ollama Python Library</a></li>
  <li><a href="#lab-18-function-calling-and-structured-outputs" id="toc-lab-18-function-calling-and-structured-outputs" class="nav-link" data-scroll-target="#lab-18-function-calling-and-structured-outputs">Lab 18: Function Calling and Structured Outputs</a></li>
  </ul></li>
  <li><a href="#week-10-retrieval-augmented-generation" id="toc-week-10-retrieval-augmented-generation" class="nav-link" data-scroll-target="#week-10-retrieval-augmented-generation">Week 10: Retrieval-Augmented Generation</a>
  <ul>
  <li><a href="#lab-19-rag-fundamentals" id="toc-lab-19-rag-fundamentals" class="nav-link" data-scroll-target="#lab-19-rag-fundamentals">Lab 19: RAG Fundamentals</a></li>
  <li><a href="#lab-20-advanced-rag" id="toc-lab-20-advanced-rag" class="nav-link" data-scroll-target="#lab-20-advanced-rag">Lab 20: Advanced RAG</a></li>
  </ul></li>
  <li><a href="#week-11-vision-language-models" id="toc-week-11-vision-language-models" class="nav-link" data-scroll-target="#week-11-vision-language-models">Week 11: Vision-Language Models</a>
  <ul>
  <li><a href="#lab-21-florence-2-setup" id="toc-lab-21-florence-2-setup" class="nav-link" data-scroll-target="#lab-21-florence-2-setup">Lab 21: Florence-2 Setup</a></li>
  <li><a href="#lab-22-vision-tasks-with-florence-2" id="toc-lab-22-vision-tasks-with-florence-2" class="nav-link" data-scroll-target="#lab-22-vision-tasks-with-florence-2">Lab 22: Vision Tasks with Florence-2</a></li>
  </ul></li>
  <li><a href="#week-12-physical-computing-basics" id="toc-week-12-physical-computing-basics" class="nav-link" data-scroll-target="#week-12-physical-computing-basics">Week 12: Physical Computing Basics</a>
  <ul>
  <li><a href="#lab-23-sensor-and-actuator-integration" id="toc-lab-23-sensor-and-actuator-integration" class="nav-link" data-scroll-target="#lab-23-sensor-and-actuator-integration">Lab 23: Sensor and Actuator Integration</a></li>
  <li><a href="#lab-24-jupyter-notebook-integration" id="toc-lab-24-jupyter-notebook-integration" class="nav-link" data-scroll-target="#lab-24-jupyter-notebook-integration">Lab 24: Jupyter Notebook Integration</a></li>
  </ul></li>
  <li><a href="#week-13-slm-physical-computing-integration" id="toc-week-13-slm-physical-computing-integration" class="nav-link" data-scroll-target="#week-13-slm-physical-computing-integration">Week 13: SLM-Physical Computing Integration</a>
  <ul>
  <li><a href="#lab-25-basic-slm-analysis" id="toc-lab-25-basic-slm-analysis" class="nav-link" data-scroll-target="#lab-25-basic-slm-analysis">Lab 25: Basic SLM Analysis</a></li>
  <li><a href="#lab-26-slm-iot-control-system" id="toc-lab-26-slm-iot-control-system" class="nav-link" data-scroll-target="#lab-26-slm-iot-control-system">Lab 26: SLM-IoT Control System</a></li>
  </ul></li>
  <li><a href="#week-14-advanced-edge-ai-techniques" id="toc-week-14-advanced-edge-ai-techniques" class="nav-link" data-scroll-target="#week-14-advanced-edge-ai-techniques">Week 14: Advanced Edge AI Techniques</a>
  <ul>
  <li><a href="#lab-27-building-agents" id="toc-lab-27-building-agents" class="nav-link" data-scroll-target="#lab-27-building-agents">Lab 27: Building Agents</a></li>
  <li><a href="#lab-28-advanced-prompting-and-validation" id="toc-lab-28-advanced-prompting-and-validation" class="nav-link" data-scroll-target="#lab-28-advanced-prompting-and-validation">Lab 28: Advanced Prompting and Validation</a></li>
  </ul></li>
  <li><a href="#week-15-final-project-integration" id="toc-week-15-final-project-integration" class="nav-link" data-scroll-target="#week-15-final-project-integration">Week 15: Final Project Integration</a>
  <ul>
  <li><a href="#lab-29-agentic-rag-system" id="toc-lab-29-agentic-rag-system" class="nav-link" data-scroll-target="#lab-29-agentic-rag-system">Lab 29: Agentic RAG System</a></li>
  <li><a href="#lab-30-final-project" id="toc-lab-30-final-project" class="nav-link" data-scroll-target="#lab-30-final-project">Lab 30: Final Project</a></li>
  </ul></li>
  <li><a href="#hardware-requirements" id="toc-hardware-requirements" class="nav-link" data-scroll-target="#hardware-requirements">Hardware Requirements</a>
  <ul>
  <li><a href="#basic-setup-weeks-1-7" id="toc-basic-setup-weeks-1-7" class="nav-link" data-scroll-target="#basic-setup-weeks-1-7">Basic Setup (Weeks 1-7)</a></li>
  <li><a href="#generative-ai-weeks-8-15" id="toc-generative-ai-weeks-8-15" class="nav-link" data-scroll-target="#generative-ai-weeks-8-15">Generative AI (Weeks 8-15)</a></li>
  <li><a href="#physical-computing-weeks-12-15" id="toc-physical-computing-weeks-12-15" class="nav-link" data-scroll-target="#physical-computing-weeks-12-15">Physical Computing (Weeks 12-15)</a></li>
  </ul></li>
  <li><a href="#software-requirements" id="toc-software-requirements" class="nav-link" data-scroll-target="#software-requirements">Software Requirements</a>
  <ul>
  <li><a href="#development-environment" id="toc-development-environment" class="nav-link" data-scroll-target="#development-environment">Development Environment</a></li>
  <li><a href="#computer-vision-and-dl" id="toc-computer-vision-and-dl" class="nav-link" data-scroll-target="#computer-vision-and-dl">Computer Vision and DL</a></li>
  <li><a href="#generative-ai" id="toc-generative-ai" class="nav-link" data-scroll-target="#generative-ai">Generative AI</a></li>
  <li><a href="#physical-computing" id="toc-physical-computing" class="nav-link" data-scroll-target="#physical-computing">Physical Computing</a></li>
  </ul></li>
  <li><a href="#assessment-criteria" id="toc-assessment-criteria" class="nav-link" data-scroll-target="#assessment-criteria">Assessment Criteria</a></li>
  <li><a href="#tips-for-success" id="toc-tips-for-success" class="nav-link" data-scroll-target="#tips-for-success">Tips for Success</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/edit/main/weekly_labs.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/weekly_labs.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Edge AI Engineering - Weekly Labs</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="week-1-introduction-and-setup" class="level2">
<h2 class="anchored" data-anchor-id="week-1-introduction-and-setup">Week 1: Introduction and Setup</h2>
<section id="lab-1-raspberry-pi-configuration" class="level3">
<h3 class="anchored" data-anchor-id="lab-1-raspberry-pi-configuration">Lab 1: Raspberry Pi Configuration</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Install Raspberry Pi OS using Raspberry Pi Imager</li>
<li>Configure basic settings (hostname, SSH, WiFi)</li>
<li>Learn essential Linux commands</li>
<li>Manage files between your computer and Raspberry Pi</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Download Raspberry Pi Imager on your computer</li>
<li>Configure OS settings (enable SSH, set hostname, WiFi credentials)</li>
<li>Boot your Raspberry Pi and confirm connectivity</li>
<li>Learn how to use SSH for remote access</li>
<li>Transfer files using SCP or FileZilla</li>
<li>Update your Raspberry Pi OS (<code>sudo apt update &amp;&amp; sudo apt upgrade</code>)</li>
<li>Practice basic Linux commands (ls, cd, mkdir, cp, mv)</li>
</ol>
<p><strong>Deliverable:</strong> Screenshot showing successful SSH connection to your Raspberry Pi</p>
</section>
<section id="lab-2-development-environment-setup" class="level3">
<h3 class="anchored" data-anchor-id="lab-2-development-environment-setup">Lab 2: Development Environment Setup</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Set up Python environment for development</li>
<li>Configure remote development tools</li>
<li>Install essential libraries</li>
<li>Test camera functionality</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p>Install Python essentials: <code>pip install jupyter matplotlib numpy pillow</code></p></li>
<li><p>Configure Jupyter Notebook for remote access:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install jupyter</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--generate-config</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--ip</span><span class="op">=</span>0.0.0.0 <span class="at">--no-browser</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Connect the camera module (USB or CSI) to your Raspberry Pi</p></li>
<li><p>Test camera functionality using command-line tools</p></li>
<li><p>Write a simple Python script to capture an image</p></li>
</ol>
<p><strong>Deliverable:</strong> A simple Python script that captures and displays an image from your camera and a Screenshot showing a successful image capture</p>
<hr>
</section>
</section>
<section id="week-2-image-classification-fundamentals" class="level2">
<h2 class="anchored" data-anchor-id="week-2-image-classification-fundamentals">Week 2: Image Classification Fundamentals</h2>
<section id="lab-3-working-with-pre-trained-models" class="level3">
<h3 class="anchored" data-anchor-id="lab-3-working-with-pre-trained-models">Lab 3: Working with Pre-trained Models</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Install TensorFlow Lite runtime</li>
<li>Download and run MobileNet V2 model</li>
<li>Process and classify images</li>
<li>Understand model inputs and outputs</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p>Install TensorFlow Lite runtime: <code>pip install tflite_runtime</code></p></li>
<li><p>Download MobileNet V2 model:</p>
<pre><code>wget https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgztar xzf mobilenet_v2_1.0_224_quant.tgz</code></pre></li>
<li><p>Download labels file</p></li>
<li><p>Create a Python script that:</p>
<ul>
<li>Loads the TFLite model</li>
<li>Processes input images to 224x224 format</li>
<li>Runs inference on test images</li>
<li>Displays top-5 predicted classes with confidence scores</li>
</ul></li>
</ol>
<p><strong>Deliverable:</strong> Python script that successfully classifies sample images with MobileNet V2 and a Screenshot showing a successful result</p>
</section>
<section id="lab-4-custom-dataset-creation" class="level3">
<h3 class="anchored" data-anchor-id="lab-4-custom-dataset-creation">Lab 4: Custom Dataset Creation</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Create a simple custom dataset using Raspberry Pi camera</li>
<li>Organize images into classes</li>
<li>Prepare dataset for model training</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create a web interface for image capture:
<ul>
<li>Use Flask to create a simple web server</li>
<li>Set up camera preview and capture functionality</li>
<li>Save captured images with appropriate filenames</li>
</ul></li>
<li>Capture at least 50 images per class for 3 classes</li>
<li>Organize the dataset into an appropriate directory structure</li>
<li>Document your dataset creation process</li>
</ol>
<p><strong>Deliverable:</strong> Structured dataset with at least 3 classes and 50 images per class</p>
<hr>
</section>
</section>
<section id="week-3-custom-image-classification" class="level2">
<h2 class="anchored" data-anchor-id="week-3-custom-image-classification">Week 3: Custom Image Classification</h2>
<section id="lab-5-edge-impulse-model-training" class="level3">
<h3 class="anchored" data-anchor-id="lab-5-edge-impulse-model-training">Lab 5: Edge Impulse Model Training</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Create an Edge Impulse project</li>
<li>Upload and process the dataset</li>
<li>Design and train a transfer learning model</li>
<li>Evaluate model performance</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create an Edge Impulse account and a new project</li>
<li>Upload your custom dataset</li>
<li>Create an impulse design:
<ul>
<li>Set image size to 160x160</li>
<li>Use Transfer Learning for feature extraction</li>
</ul></li>
<li>Generate features for all images</li>
<li>Train model using MobileNet V2</li>
<li>Analyze model performance (accuracy, confusion matrix)</li>
<li>Test model on validation data</li>
</ol>
<p><strong>Deliverable:</strong> Edge Impulse project link and screenshot of model performance metrics</p>
</section>
<section id="lab-6-model-deployment-to-raspberry-pi" class="level3">
<h3 class="anchored" data-anchor-id="lab-6-model-deployment-to-raspberry-pi">Lab 6: Model Deployment to Raspberry Pi</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Export trained model to TFLite format</li>
<li>Deploy model to Raspberry Pi</li>
<li>Create a real-time inference application</li>
<li>Optimize inference speed</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Export model as TensorFlow Lite (.tflite)</li>
<li>Transfer the model to Raspberry Pi</li>
<li>Create a Python application that:
<ul>
<li>Captures live images from the camera</li>
<li>Preprocesses images for the model</li>
<li>Runs inference and displays results</li>
<li>Shows confidence scores</li>
</ul></li>
<li>Implement a web interface for real-time classification</li>
</ol>
<p><strong>Deliverable:</strong> Python script for real-time image classification with your custom model and a Screenshot showing a successful result</p>
<hr>
</section>
</section>
<section id="week-4-object-detection-fundamentals" class="level2">
<h2 class="anchored" data-anchor-id="week-4-object-detection-fundamentals">Week 4: Object Detection Fundamentals</h2>
<section id="lab-7-pre-trained-object-detection" class="level3">
<h3 class="anchored" data-anchor-id="lab-7-pre-trained-object-detection">Lab 7: Pre-trained Object Detection</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Understand object detection architecture</li>
<li>Run pre-trained SSD-MobileNet model</li>
<li>Process detection outputs</li>
<li>Visualize detected objects</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Download the pre-trained SSD-MobileNet V1 model</li>
<li>Create a Python script that:
<ul>
<li>Loads the model and labels</li>
<li>Preprocesses input images</li>
<li>Runs inference</li>
<li>Extracts bounding boxes, classes, and scores</li>
<li>Implements Non-Maximum Suppression (NMS)</li>
<li>Visualizes detections with bounding boxes</li>
</ul></li>
<li>Test on various images with multiple objects</li>
</ol>
<p><strong>Deliverable:</strong> Python script that performs and visualizes object detection on test images and a Screenshot showing a successful result.</p>
</section>
<section id="lab-8-efficientdet-and-fomo-models" class="level3">
<h3 class="anchored" data-anchor-id="lab-8-efficientdet-and-fomo-models">Lab 8: EfficientDet and FOMO Models</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Compare different object detection architectures</li>
<li>Implement EfficientDet and FOMO models</li>
<li>Analyze performance differences</li>
<li>Understand trade-offs between models</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Download the EfficientDet Lite0 model</li>
<li>Implement inference with EfficientDet</li>
<li>Compare with SSD-MobileNet implementation</li>
<li>Learn about FOMO (Faster Objects, More Objects)</li>
<li>Analyze trade-offs in accuracy vs.&nbsp;speed</li>
<li>Measure inference time on Raspberry Pi</li>
</ol>
<p><strong>Deliverable:</strong> Comparison report of SSD-MobileNet vs.&nbsp;EfficientDet with performance metrics and visualized results</p>
<hr>
</section>
</section>
<section id="week-5-custom-object-detection" class="level2">
<h2 class="anchored" data-anchor-id="week-5-custom-object-detection">Week 5: Custom Object Detection</h2>
<section id="lab-9-dataset-creation-and-annotation" class="level3">
<h3 class="anchored" data-anchor-id="lab-9-dataset-creation-and-annotation">Lab 9: Dataset Creation and Annotation</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Create an object detection dataset</li>
<li>Learn annotation techniques</li>
<li>Prepare dataset for model training</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Capture at least 100 images containing objects to detect</li>
<li>Upload images to Roboflow or a similar annotation tool</li>
<li>Create bounding box annotations for each object</li>
<li>Apply data augmentation (rotation, brightness adjustment)</li>
<li>Export dataset in YOLO format</li>
<li>Document the annotation process</li>
</ol>
<p><strong>Deliverable:</strong> Annotated dataset with at least 2 object classes and 100 total images</p>
</section>
<section id="lab-10-training-models-in-edge-impulse" class="level3">
<h3 class="anchored" data-anchor-id="lab-10-training-models-in-edge-impulse">Lab 10: Training Models in Edge Impulse</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Upload annotated dataset to Edge Impulse</li>
<li>Train SSD MobileNet object detection model</li>
<li>Evaluate model performance</li>
<li>Export model for deployment</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create a new Edge Impulse project for object detection</li>
<li>Upload annotated dataset (train/test splits)</li>
<li>Create object detection impulse</li>
<li>Train SSD MobileNet model</li>
<li>Evaluate model performance</li>
<li>Export model as TensorFlow Lite</li>
</ol>
<p><strong>Deliverable:</strong> Edge Impulse project link with trained object detection model and performance metrics</p>
<hr>
</section>
</section>
<section id="week-6-advanced-object-detection" class="level2">
<h2 class="anchored" data-anchor-id="week-6-advanced-object-detection">Week 6: Advanced Object Detection</h2>
<section id="lab-11-fomo-model-training" class="level3">
<h3 class="anchored" data-anchor-id="lab-11-fomo-model-training">Lab 11: FOMO Model Training</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Understanding FOMO architecture benefits</li>
<li>Train FOMO model on Edge Impulse</li>
<li>Compare performance with SSD MobileNet</li>
<li>Deploy optimized model to Raspberry Pi</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create a new impulse in Edge Impulse using the same dataset</li>
<li>Train FOMO model instead of SSD MobileNet</li>
<li>Compare inference speed and accuracy</li>
<li>Deploy both models to Raspberry Pi</li>
<li>Create an application that can switch between models</li>
<li>Measure and document performance differences</li>
</ol>
<p><strong>Deliverable:</strong> Python application that compares SSD MobileNet vs.&nbsp;FOMO performance in real-time</p>
</section>
<section id="lab-12-yolo-implementation" class="level3">
<h3 class="anchored" data-anchor-id="lab-12-yolo-implementation">Lab 12: YOLO Implementation</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Install and configure Ultralytics YOLO</li>
<li>Convert models to optimized NCNN format</li>
<li>Create real-time detection application</li>
<li>Implement object counting</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Install Ultralytics: <code>pip install ultralytics</code></li>
<li>Download and test YOLO (n) model</li>
<li>Export model to NCNN format for optimization</li>
<li>Create Python script for real-time detection</li>
<li>Implement object counting algorithm</li>
<li>Add visualization of counts over time</li>
</ol>
<p><strong>Deliverable:</strong> Python application for real-time object detection and counting using YOLO</p>
<hr>
</section>
</section>
<section id="week-7-object-counting-project" class="level2">
<h2 class="anchored" data-anchor-id="week-7-object-counting-project">Week 7: Object Counting Project</h2>
<section id="lab-13-custom-yolo-training" class="level3">
<h3 class="anchored" data-anchor-id="lab-13-custom-yolo-training">Lab 13: Custom YOLO Training</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Train YOLO on a custom dataset</li>
<li>Optimize model for edge deployment</li>
<li>Create a complete application for object counting</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Train the YOLO model on your custom dataset
<ul>
<li>Use Google Colab for training if needed</li>
<li>Set appropriate hyperparameters</li>
</ul></li>
<li>Export optimized model for Raspberry Pi</li>
<li>Create a Python application that:
<ul>
<li>Captures video feed</li>
<li>Detects objects using YOLO</li>
<li>Counts objects over time</li>
<li>Logs results to a database</li>
</ul></li>
</ol>
<p><strong>Deliverable:</strong> Complete object counting application with data logging</p>
</section>
<section id="lab-14-fixed-function-ai-integration-optional" class="level3">
<h3 class="anchored" data-anchor-id="lab-14-fixed-function-ai-integration-optional">Lab 14: Fixed-Function AI Integration (Optional)</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Integrate multiple AI models into a single application</li>
<li>Create a dashboard for visualization</li>
<li>Optimize application for long-term deployment</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create an integration application that combines:
<ul>
<li>Object detection capabilities</li>
<li>Classification for detected objects</li>
<li>Counting and tracking over time</li>
</ul></li>
<li>Implement a simple web dashboard for visualization</li>
<li>Add performance monitoring</li>
<li>Configure application for startup at boot</li>
</ol>
<p><strong>Deliverable:</strong> Integrated application combining multiple AI capabilities with visualization dashboard</p>
<hr>
</section>
</section>
<section id="week-8-introduction-to-generative-ai" class="level2">
<h2 class="anchored" data-anchor-id="week-8-introduction-to-generative-ai">Week 8: Introduction to Generative AI</h2>
<section id="lab-15-raspberry-pi-configuration-for-slms" class="level3">
<h3 class="anchored" data-anchor-id="lab-15-raspberry-pi-configuration-for-slms">Lab 15: Raspberry Pi Configuration for SLMs</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Optimize Raspberry Pi for running Small Language Models</li>
<li>Install an active cooling solution</li>
<li>Configure memory and swap</li>
<li>Install essential libraries</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p>Install active cooling solution on Raspberry Pi 5</p></li>
<li><p>Optimize system configuration:</p>
<ul>
<li>Increase swap memory: <code>sudo dphys-swapfile swapoff</code>, edit <code>/etc/dphys-swapfile</code></li>
<li>Set CONF_SWAPSIZE to 2048</li>
<li><code>sudo dphys-swapfile setup &amp;&amp; sudo dphys-swapfile swapon</code></li>
</ul></li>
<li><p>Install dependencies:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install build-essential python3-dev</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
<p><strong>Deliverable:</strong> Screenshot showing system configuration with increased swap and temperature monitor during stress test</p>
</section>
<section id="lab-16-ollama-installation-and-testing" class="level3">
<h3 class="anchored" data-anchor-id="lab-16-ollama-installation-and-testing">Lab 16: Ollama Installation and Testing</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Install Ollama framework</li>
<li>Pull and test Small Language Models</li>
<li>Benchmark model performance</li>
<li>Monitor resource usage</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p>Install Ollama:</p>
<pre><code>curl -fsSL https://ollama.com/install.sh | sh</code></pre></li>
<li><p>Pull different models (such as):</p>
<pre><code>ollama pull llama3.2:1b
ollama pull gemma:2b
ollama pull phi3:latest</code></pre></li>
<li><p>Run a basic inference test with each model</p></li>
<li><p>Measure and compare:</p>
<ul>
<li>Load time</li>
<li>Inference speed (tokens/sec)</li>
<li>Memory usage</li>
<li>Temperature</li>
</ul></li>
</ol>
<p><strong>Deliverable:</strong> Benchmark report comparing performance metrics of different SLM models on your Raspberry Pi</p>
<hr>
</section>
</section>
<section id="week-9-slm-python-integration" class="level2">
<h2 class="anchored" data-anchor-id="week-9-slm-python-integration">Week 9: SLM Python Integration</h2>
<section id="lab-17-ollama-python-library" class="level3">
<h3 class="anchored" data-anchor-id="lab-17-ollama-python-library">Lab 17: Ollama Python Library</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Use the Ollama Python library</li>
<li>Create interactive applications</li>
<li>Process SLM responses programmatically</li>
<li>Handle multiple conversation turns</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Install Ollama Python library: <code>pip install ollama</code></li>
<li>Create Python script to:
<ul>
<li>Connect to Ollama API</li>
<li>Send prompts to models</li>
<li>Process and format responses</li>
<li>Handle conversation context</li>
</ul></li>
<li>Implement proper error handling</li>
<li>Create a simple interactive CLI application</li>
</ol>
<p><strong>Deliverable:</strong> Python script demonstrating Ollama library usage with conversation handling</p>
</section>
<section id="lab-18-function-calling-and-structured-outputs" class="level3">
<h3 class="anchored" data-anchor-id="lab-18-function-calling-and-structured-outputs">Lab 18: Function Calling and Structured Outputs</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Implement function calling with SLMs</li>
<li>Create applications with structured outputs</li>
<li>Build validation mechanisms</li>
<li>Handle image inputs</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p>Install required libraries:</p>
<pre><code>pip install pydantic instructor openai</code></pre></li>
<li><p>Create Pydantic models for structured outputs</p></li>
<li><p>Implement function calling with an instructor:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> instructor.patch(    OpenAI(base_url<span class="op">=</span><span class="st">"http://localhost:11434/v1"</span>, api_key<span class="op">=</span><span class="st">"ollama"</span>),    mode<span class="op">=</span>instructor.Mode.JSON,)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Build distance calculator application using SLM for city/country recognition</p></li>
<li><p>Add image input processing</p></li>
</ol>
<p><strong>Deliverable:</strong> Python application that uses function calling for structured interaction with SLMs</p>
<hr>
</section>
</section>
<section id="week-10-retrieval-augmented-generation" class="level2">
<h2 class="anchored" data-anchor-id="week-10-retrieval-augmented-generation">Week 10: Retrieval-Augmented Generation</h2>
<section id="lab-19-rag-fundamentals" class="level3">
<h3 class="anchored" data-anchor-id="lab-19-rag-fundamentals">Lab 19: RAG Fundamentals</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Understand RAG architecture</li>
<li>Create vector database</li>
<li>Implement embedding generation</li>
<li>Build simple RAG system</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p>Install required libraries:</p>
<pre><code>pip install langchain chromadb</code></pre></li>
<li><p>Create a simple dataset with text documents</p></li>
<li><p>Implement document splitting and chunking</p></li>
<li><p>Generate embeddings using Ollama</p></li>
<li><p>Store embeddings in ChromaDB</p></li>
<li><p>Create query system</p></li>
</ol>
<p><strong>Deliverable:</strong> Python implementation of a basic RAG system with simple text documents</p>
</section>
<section id="lab-20-advanced-rag" class="level3">
<h3 class="anchored" data-anchor-id="lab-20-advanced-rag">Lab 20: Advanced RAG</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Optimize RAG for edge devices</li>
<li>Implement more efficient retrieval</li>
<li>Create a specialized knowledge base</li>
<li>Build validation mechanisms</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create a specialized knowledge base (e.g., technical documentation)</li>
<li>Implement optimized embedding generation</li>
<li>Fine-tune retrieval parameters</li>
<li>Add response validation</li>
<li>Create a persistent vector store</li>
<li>Benchmark performance</li>
</ol>
<p><strong>Deliverable:</strong> Optimized RAG implementation with specialized knowledge base and performance analysis</p>
<hr>
</section>
</section>
<section id="week-11-vision-language-models" class="level2">
<h2 class="anchored" data-anchor-id="week-11-vision-language-models">Week 11: Vision-Language Models</h2>
<section id="lab-21-florence-2-setup" class="level3">
<h3 class="anchored" data-anchor-id="lab-21-florence-2-setup">Lab 21: Florence-2 Setup</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Install Florence-2 model</li>
<li>Configure environment</li>
<li>Run basic inference tests</li>
<li>Understand model capabilities</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p>Install required dependencies:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install transformers torch torchvision torchaudio</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install timm einops</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install autodistill-florence-2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Download model and test basic functionality</p></li>
<li><p>Run image captioning test</p></li>
<li><p>Measure performance (memory usage, inference time)</p></li>
</ol>
<p><strong>Deliverable:</strong> Python script demonstrating basic Florence-2 functionality with performance metrics</p>
</section>
<section id="lab-22-vision-tasks-with-florence-2" class="level3">
<h3 class="anchored" data-anchor-id="lab-22-vision-tasks-with-florence-2">Lab 22: Vision Tasks with Florence-2</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Implement various vision tasks</li>
<li>Create applications for captioning, detection, grounding</li>
<li>Optimize performance</li>
<li>Combine tasks</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Implement image captioning:
<ul>
<li>Basic caption generation</li>
<li>Detailed caption generation</li>
</ul></li>
<li>Implement object detection:
<ul>
<li>Bounding box visualization</li>
<li>Multiple object detection</li>
</ul></li>
<li>Implement visual grounding:
<ul>
<li>Highlight specific objects based on text prompts</li>
</ul></li>
<li>Create segmentation application</li>
<li>Measure the performance of each task</li>
</ol>
<p><strong>Deliverable:</strong> Python application demonstrating multiple vision tasks with Florence-2 and performance analysis</p>
<hr>
</section>
</section>
<section id="week-12-physical-computing-basics" class="level2">
<h2 class="anchored" data-anchor-id="week-12-physical-computing-basics">Week 12: Physical Computing Basics</h2>
<section id="lab-23-sensor-and-actuator-integration" class="level3">
<h3 class="anchored" data-anchor-id="lab-23-sensor-and-actuator-integration">Lab 23: Sensor and Actuator Integration</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Connect digital sensors</li>
<li>Read environmental data</li>
<li>Control LEDs and actuators</li>
<li>Create a data collection system</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li><p>Connect hardware components:</p>
<ul>
<li>DHT22 temperature/humidity sensor</li>
<li>BMP280 pressure sensor</li>
<li>LEDs (red, yellow, green)</li>
<li>Push button</li>
</ul></li>
<li><p>Install required libraries:</p>
<pre><code>pip install adafruit-circuitpython-dht adafruit-circuitpython-bmp280</code></pre></li>
<li><p>Create a Python script to read sensor data</p></li>
<li><p>Implement LED control based on conditions</p></li>
<li><p>Create visualization of sensor data</p></li>
</ol>
<p><strong>Deliverable:</strong> Python application for reading sensor data and controlling actuators with visualization</p>
</section>
<section id="lab-24-jupyter-notebook-integration" class="level3">
<h3 class="anchored" data-anchor-id="lab-24-jupyter-notebook-integration">Lab 24: Jupyter Notebook Integration</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Use Jupyter Notebook for physical computing</li>
<li>Create interactive widgets</li>
<li>Visualize sensor data in real-time</li>
<li>Control actuators from a notebook</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Install ipywidgets: <code>pip install ipywidgets</code></li>
<li>Create a Jupyter Notebook for sensor data collection</li>
<li>Implement interactive widgets for control</li>
<li>Create real-time visualization</li>
<li>Build a dashboard with multiple data views</li>
</ol>
<p><strong>Deliverable:</strong> Jupyter Notebook with interactive widgets for sensor monitoring and actuator control</p>
<hr>
</section>
</section>
<section id="week-13-slm-physical-computing-integration" class="level2">
<h2 class="anchored" data-anchor-id="week-13-slm-physical-computing-integration">Week 13: SLM-Physical Computing Integration</h2>
<section id="lab-25-basic-slm-analysis" class="level3">
<h3 class="anchored" data-anchor-id="lab-25-basic-slm-analysis">Lab 25: Basic SLM Analysis</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Integrate SLMs with sensor data</li>
<li>Create analysis application</li>
<li>Implement decision-making logic</li>
<li>Control actuators based on SLM responses</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create a Python application that:
<ul>
<li>Collects sensor data</li>
<li>Formats data for SLM prompt</li>
<li>Sends prompt to model</li>
<li>Parses response</li>
<li>Controls actuators based on response</li>
</ul></li>
<li>Implement multiple analysis modes</li>
<li>Add error handling for SLM responses</li>
</ol>
<p><strong>Deliverable:</strong> Python application integrating SLMs with physical sensors and actuators</p>
</section>
<section id="lab-26-slm-iot-control-system" class="level3">
<h3 class="anchored" data-anchor-id="lab-26-slm-iot-control-system">Lab 26: SLM-IoT Control System</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Create a complete IoT monitoring system</li>
<li>Implement natural language interaction</li>
<li>Add data logging and analysis</li>
<li>Create web interface</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Build a complete system with:
<ul>
<li>Sensor data collection</li>
<li>SLM-based analysis</li>
<li>Natural language command processing</li>
<li>Data logging to the database</li>
<li>Web interface for interaction</li>
</ul></li>
<li>Implement multiple SLM models</li>
<li>Add historical data analysis</li>
<li>Create visualization dashboard</li>
</ol>
<p><strong>Deliverable:</strong> Complete IoT monitoring system with SLM integration and web interface</p>
<hr>
</section>
</section>
<section id="week-14-advanced-edge-ai-techniques" class="level2">
<h2 class="anchored" data-anchor-id="week-14-advanced-edge-ai-techniques">Week 14: Advanced Edge AI Techniques</h2>
<section id="lab-27-building-agents" class="level3">
<h3 class="anchored" data-anchor-id="lab-27-building-agents">Lab 27: Building Agents</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Create agent architecture</li>
<li>Implement tool usage</li>
<li>Build decision-making system</li>
<li>Handle complex tasks</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Implement calculator agent:
<ul>
<li>Create a query routing system</li>
<li>Implement tool functions</li>
<li>Build decision-making logic</li>
</ul></li>
<li>Create knowledge router:
<ul>
<li>Implement web search integration</li>
<li>Build classification system</li>
<li>Handle time-based queries</li>
</ul></li>
<li>Measure and optimize performance</li>
</ol>
<p><strong>Deliverable:</strong> Python implementation of agent architecture with tool usage and decision routing</p>
</section>
<section id="lab-28-advanced-prompting-and-validation" class="level3">
<h3 class="anchored" data-anchor-id="lab-28-advanced-prompting-and-validation">Lab 28: Advanced Prompting and Validation</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Implement chain-of-thought prompting</li>
<li>Create few-shot learning examples</li>
<li>Build task decomposition system</li>
<li>Implement response validation</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create examples for different prompting strategies</li>
<li>Implement chain-of-thought framework</li>
<li>Build few-shot learning templates</li>
<li>Create a task decomposition system</li>
<li>Implement validation mechanisms</li>
<li>Compare the effectiveness of different strategies</li>
</ol>
<p><strong>Deliverable:</strong> Python implementation demonstrating different prompting strategies with performance comparison</p>
<hr>
</section>
</section>
<section id="week-15-final-project-integration" class="level2">
<h2 class="anchored" data-anchor-id="week-15-final-project-integration">Week 15: Final Project Integration</h2>
<section id="lab-29-agentic-rag-system" class="level3">
<h3 class="anchored" data-anchor-id="lab-29-agentic-rag-system">Lab 29: Agentic RAG System</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Combine agent architecture with RAG</li>
<li>Create a complete knowledge system</li>
<li>Implement advanced validation</li>
<li>Build query optimization</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Create a complete agentic RAG system:
<ul>
<li>Build knowledge database</li>
<li>Implement agent architecture</li>
<li>Add tool functions</li>
<li>Create validation mechanisms</li>
<li>Optimize retrieval</li>
</ul></li>
<li>Test with complex queries</li>
<li>Measure performance</li>
<li>Create visualization of system components</li>
</ol>
<p><strong>Deliverable:</strong> Complete agentic RAG system with documentation and performance analysis</p>
</section>
<section id="lab-30-final-project" class="level3">
<h3 class="anchored" data-anchor-id="lab-30-final-project">Lab 30: Final Project</h3>
<p><strong>Objectives:</strong></p>
<ul>
<li>Design and implement a comprehensive Edge AI system</li>
<li>Combine multiple techniques</li>
<li>Create complete documentation</li>
<li>Present project</li>
</ul>
<p><strong>Instructions:</strong></p>
<ol type="1">
<li>Design final project combining:
<ul>
<li>Computer vision capabilities</li>
<li>SLM integration</li>
<li>Physical computing</li>
<li>Advanced techniques (RAG, agents, etc.)</li>
</ul></li>
<li>Implement complete system</li>
<li>Create documentation</li>
<li>Measure performance</li>
<li>Prepare presentation</li>
</ol>
<p><strong>Deliverable:</strong> Complete final project with documentation, code, and presentation</p>
<hr>
</section>
</section>
<section id="hardware-requirements" class="level2">
<h2 class="anchored" data-anchor-id="hardware-requirements">Hardware Requirements</h2>
<section id="basic-setup-weeks-1-7" class="level3">
<h3 class="anchored" data-anchor-id="basic-setup-weeks-1-7">Basic Setup (Weeks 1-7)</h3>
<ul>
<li>Raspberry Pi Zero 2W or Pi 5</li>
<li>MicroSD card (32GB+)</li>
<li>Camera module (USB webcam or Pi camera)</li>
<li>Power supply</li>
</ul>
</section>
<section id="generative-ai-weeks-8-15" class="level3">
<h3 class="anchored" data-anchor-id="generative-ai-weeks-8-15">Generative AI (Weeks 8-15)</h3>
<ul>
<li>Raspberry Pi 5 (8GB RAM recommended)</li>
<li>Active cooling solution</li>
<li>MicroSD card (64GB+ recommended)</li>
</ul>
</section>
<section id="physical-computing-weeks-12-15" class="level3">
<h3 class="anchored" data-anchor-id="physical-computing-weeks-12-15">Physical Computing (Weeks 12-15)</h3>
<ul>
<li>DHT22 temperature/humidity sensor</li>
<li>BMP280 pressure/temperature sensor</li>
<li>LEDs (red, yellow, green)</li>
<li>Push button</li>
<li>Resistors (4.7k, 330)</li>
<li>Jumper wires</li>
<li>Breadboard</li>
</ul>
<hr>
</section>
</section>
<section id="software-requirements" class="level2">
<h2 class="anchored" data-anchor-id="software-requirements">Software Requirements</h2>
<section id="development-environment" class="level3">
<h3 class="anchored" data-anchor-id="development-environment">Development Environment</h3>
<ul>
<li>Raspberry Pi OS (64-bit)</li>
<li>Python 3.9+</li>
<li>Jupyter Notebook</li>
<li>SSH client</li>
</ul>
</section>
<section id="computer-vision-and-dl" class="level3">
<h3 class="anchored" data-anchor-id="computer-vision-and-dl">Computer Vision and DL</h3>
<ul>
<li>TensorFlow Lite runtime</li>
<li>OpenCV</li>
<li>Edge Impulse</li>
<li>Ultralytics</li>
</ul>
</section>
<section id="generative-ai" class="level3">
<h3 class="anchored" data-anchor-id="generative-ai">Generative AI</h3>
<ul>
<li>Ollama</li>
<li>Transformers</li>
<li>Pytorch</li>
<li>ChromaDB</li>
<li>LangChain</li>
<li>Pydantic</li>
<li>Instructor</li>
</ul>
</section>
<section id="physical-computing" class="level3">
<h3 class="anchored" data-anchor-id="physical-computing">Physical Computing</h3>
<ul>
<li>GPIO Zero</li>
<li>Adafruit CircuitPython libraries</li>
</ul>
<hr>
</section>
</section>
<section id="assessment-criteria" class="level2">
<h2 class="anchored" data-anchor-id="assessment-criteria">Assessment Criteria</h2>
<p>Each lab will be evaluated based on:</p>
<ol type="1">
<li><strong>Functionality (40%)</strong>: Does the implementation work as specified?</li>
<li><strong>Code Quality (20%)</strong>: Is the code well-structured, documented, and efficient?</li>
<li><strong>Documentation (20%)</strong>: Are the process and results documented?</li>
<li><strong>Analysis (20%)</strong>: Is there a thoughtful analysis of results and performance?</li>
</ol>
<p>The final project will be evaluated based on:</p>
<ol type="1">
<li><strong>Integration (30%)</strong>: How well different components are integrated</li>
<li><strong>Innovation (20%)</strong>: Novel approaches or applications</li>
<li><strong>Implementation (30%)</strong>: Overall quality and functionality</li>
<li><strong>Presentation (20%)</strong>: Clear explanation and demonstration</li>
</ol>
<hr>
</section>
<section id="tips-for-success" class="level2">
<h2 class="anchored" data-anchor-id="tips-for-success">Tips for Success</h2>
<ol type="1">
<li><strong>Start Early</strong>: These labs build on each other. Falling behind makes later labs more difficult.</li>
<li><strong>Document As You Go</strong>: Take notes, screenshots, and document issues/solutions.</li>
<li><strong>Optimize Resources</strong>: SLMs and VLMs require careful resource management.</li>
<li><strong>Collaborate</strong>: Discuss approaches with classmates while ensuring individual work.</li>
<li><strong>Backup Regularly</strong>: Create backups of your SD card after significant progress.</li>
<li><strong>Measure Performance</strong>: Always benchmark and optimize your implementations.</li>
<li><strong>Ask Questions</strong>: If youre stuck, ask for help early rather than falling behind.</li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Written and edited by Prof.&nbsp;Marcelo Rovai (UNIFEI University)</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">This book was built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>



</body></html>